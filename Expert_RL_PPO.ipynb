{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/gym/envs/registration.py:216: UserWarning: \u001b[33mWARN: Overriding environment forex-v0\u001b[0m\n",
      "  logger.warn(\"Overriding environment {}\".format(id))\n",
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/gym/envs/registration.py:216: UserWarning: \u001b[33mWARN: Overriding environment stocks-v0\u001b[0m\n",
      "  logger.warn(\"Overriding environment {}\".format(id))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "#from gym_trade.gym_anytrading.envs.stocks_env import StocksEnv\n",
    "#from env.ExpertEnv import StockTradingEnv\n",
    "import pandas as pd\n",
    "from FinMind.data import DataLoader\n",
    "#from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "#from stable_baselines3.common.evaluation import evaluate_policy\n",
    "#from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "import statistics\n",
    "from gym import spaces\n",
    "#from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import A2C,PPO,DQN\n",
    "#from stable_baselines import TRPO\n",
    "import gym_anytrading\n",
    "#from stable_baselines3 import PPO,DDPG\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "from sb3_contrib.ppo_recurrent.ppo_recurrent import RecurrentPPO\n",
    "from sb3_contrib.trpo.trpo import TRPO\n",
    "from sb3_contrib.qrdqn.qrdqn import QRDQN\n",
    "\n",
    "import talib\n",
    "import torch\n",
    "\n",
    "from gym_anytrading.envs import StocksEnv\n",
    "from gym_trade.gym_anytrading.envs import StocksEnv as StocksEnv2\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "api_token = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkYXRlIjoiMjAyMS0xMi0yNyAxNDo1OTowOSIsInVzZXJfaWQiOiJkdXJhbnQ3MTA5MTYiLCJpcCI6IjE0MC4xMjAuMTMuMjMwIn0.8-KIC3-OA4D6JcOtQ_fJBOVkyugx60t1Gy82c57TLz4\"\n",
    "\n",
    "api = DataLoader()\n",
    "api.login_by_token(api_token = api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_A2C(env_train, model_name, timesteps=50000):\n",
    "    \"\"\"A2C model\"\"\"\n",
    "    stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=5, min_evals=5, verbose=0)\n",
    "    eval_callback = EvalCallback(env_train, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=0)\n",
    "\n",
    "    start = time.time()\n",
    "    #model = A2C('MlpPolicy', env_train, verbose=0)\n",
    "    model = A2C('MlpPolicy', env_train, verbose=0, ent_coef=0.1)\n",
    "    model.learn(total_timesteps=timesteps, callback=eval_callback)\n",
    "    end = time.time()\n",
    "\n",
    "    #model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name}\")\n",
    "    #model.save(\"./expert_model/\" + model_name)\n",
    "    print('Training time (A2C): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "'''\n",
    "def train_DDPG(env_train, model_name, timesteps=200000):\n",
    "    \"\"\"DDPG model\"\"\"\n",
    "\n",
    "    # add the noise objects for DDPG\n",
    "    n_actions = env_train.action_space.shape[-1]\n",
    "    param_noise = None\n",
    "    action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "\n",
    "    start = time.time()\n",
    "    #model = DDPG('MlpPolicy', env_train, param_noise=param_noise, action_noise=action_noise)\n",
    "    model = DDPG('MlpPolicy', env_train, verbose=0)\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(\"./expert_model/\" + model_name)\n",
    "    print('Training time (DDPG): ', (end-start)/60,' minutes')\n",
    "    return model\n",
    "'''\n",
    "def train_PPO(env_train, model_name, timesteps=200000):\n",
    "    \"\"\"PPO model\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=20, min_evals=5, verbose=0)\n",
    "    eval_callback = EvalCallback(env_train, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=0)\n",
    "\n",
    "    model = PPO('MlpPolicy', env_train, verbose=0, ent_coef=0.2,batch_size=64)\n",
    "    model.learn(total_timesteps=timesteps, callback=eval_callback)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(\"./expert_model/\" + model_name)\n",
    "    print('Training time (PPO): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "def train_DQN(env_train, model_name, timesteps=50000):\n",
    "    \"\"\"DQN model\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    #model = A2C('MlpPolicy', env_train, verbose=0)\n",
    "    stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=20, min_evals=5, verbose=0)\n",
    "    eval_callback = EvalCallback(env_train, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=0)\n",
    "\n",
    "    model = DQN('MlpPolicy', env_train, verbose=0)\n",
    "    model.learn(total_timesteps=timesteps, callback=eval_callback)\n",
    "    end = time.time()\n",
    "\n",
    "    #model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name}\")\n",
    "    #model.save(\"./expert_model/\" + model_name)\n",
    "    print('Training time (DQN): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_DRQN(env_train, model_name, timesteps=50000):\n",
    "    \"\"\"TRPO model\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=10, min_evals=5, verbose=0)\n",
    "    eval_callback = EvalCallback(env_train, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=0)\n",
    "\n",
    "    model = RecurrentPPO('MlpLstmPolicy', env_train, verbose=0, ent_coef=0.1)\n",
    "    model.learn(total_timesteps=timesteps, callback=eval_callback)\n",
    "    end = time.time()\n",
    "\n",
    "    #model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name}\")\n",
    "    #model.save(\"./expert_model/\" + model_name)\n",
    "    print('Training time (DRQN): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_TRPO(env_train, model_name, timesteps=50000):\n",
    "    \"\"\"TRPO model\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=10, min_evals=5, verbose=0)\n",
    "    eval_callback = EvalCallback(env_train, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=0)\n",
    "    \n",
    "    #model = A2C('MlpPolicy', env_train, verbose=0)\n",
    "    model = TRPO('MlpPolicy', env_train, verbose=0)\n",
    "    model.learn(total_timesteps=timesteps, callback=eval_callback)\n",
    "    end = time.time()\n",
    "\n",
    "    #model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name}\")\n",
    "    #model.save(\"./expert_model/\" + model_name)\n",
    "    print('Training time (TRPO): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "def sharpeRatio(Ret):\n",
    "    T = len(Ret)\n",
    "    if T == 0:\n",
    "        return 0\n",
    "    mean_ret = float(sum(Ret))/T\n",
    "    mean_sq_ret = float(sum(Ret**2))/T\n",
    "    if (mean_ret == 0.0) & (mean_sq_ret == 0.0):\n",
    "        return 0\n",
    "    if mean_sq_ret - mean_ret*mean_ret == 0:\n",
    "        return 0\n",
    "    sharpe = mean_ret/sqrt(mean_sq_ret - mean_ret*mean_ret)\n",
    "    return sharpe\n",
    "def DRL_validation(df ,model, test_env, test_obs) -> None:\n",
    "    ###validation process###\n",
    "    #env_val2 = MyCustomEnv(df=df, frame_bound=(val_start_idx,val_end_idx), window_size=20)\n",
    "    #obs_val2 = env_val2.reset()\n",
    "    \n",
    "    action_list = []\n",
    "        \n",
    "    final_action = []\n",
    "    hold = 0\n",
    "    temp = []\n",
    "    buy_price = 0\n",
    "    #prices = []\n",
    "    return_list = []\n",
    "    Rf = 0.02   # 假設無風險利率為2%\n",
    "    downside_deviation = []\n",
    "    action_count=0\n",
    "    while True: \n",
    "        test_obs = test_obs[np.newaxis, ...]\n",
    "        #print(test_obs)\n",
    "        price = test_obs[0][-1][3]\n",
    "        #print(price)\n",
    "        #print(obs.shape)\n",
    "        action, _states = model.predict(test_obs, deterministic=True)\n",
    "        #print(action[0])\n",
    "        action_count+=1\n",
    "        if action[0] == 1:\n",
    "            if hold == 0:\n",
    "                #print('buy ',price)\n",
    "                #buy\n",
    "                buy_price = price\n",
    "                hold = 1\n",
    "           \n",
    "                #print('hold')\n",
    "        elif action[0] == 0:\n",
    "            if hold == 1:\n",
    "                #sell\n",
    "                #print('sell ',price)\n",
    "                return_list.append((price-buy_price)/buy_price)\n",
    "                hold = 0\n",
    "            \n",
    "                #print('hold')\n",
    "        \n",
    "        #action_list.append(action[0])\n",
    "        #obs, rewards, dones, info = env.step(action)\n",
    "        test_obs, rewards, done, info = test_env.step(action)\n",
    "        if done:\n",
    "            print(\"info\", info)\n",
    "            break\n",
    "    #print(return_list)\n",
    "    #print(len(return_list))\n",
    "    #print(action_count)\n",
    "    \n",
    "    for r in return_list:\n",
    "        if r-Rf<=0:\n",
    "            downside_deviation.append(0)\n",
    "        else:\n",
    "            downside_deviation.append(r-Rf)\n",
    "    \n",
    "    #Sharpe Ratio\n",
    "    #Rp = (1 + np.mean(return_list)) ** (action_count / len(return_list)) - 1\n",
    "    Rp = np.mean(return_list)\n",
    "    #print(Rp)\n",
    "    #print(Rp)\n",
    "    # 確定無風險利率\n",
    "    \n",
    "    # 計算標準差\n",
    "    sigma_p = np.std(return_list)\n",
    "    #print(sigma_p)\n",
    "    \n",
    "    # 計算Sharpe Ratio\n",
    "    Sharpe_ratio = (Rp - Rf) / sigma_p\n",
    "    Sortino_ratio = (Rp - Rf) / np.std(downside_deviation)\n",
    "    Sharpe_ratio = sharpeRatio(np.array(return_list))\n",
    "    return Sharpe_ratio, Sortino_ratio\n",
    "def DRL_prediction(df,\n",
    "                   model,\n",
    "                   #name,\n",
    "                   #last_state,\n",
    "                   start_date,\n",
    "                   end_date,\n",
    "                   action_list\n",
    "                  ):\n",
    "    ### make a prediction based on trained model###\n",
    "\n",
    "    ## trading env\n",
    "    #trade_data = df[start_date:end_date+1]\n",
    "    #env_trade = MyCustomEnv(df=df, frame_bound=(start_date,end_date+1), window_size=20)\n",
    "    env_trade = StocksEnv2(df=df, frame_bound=(start_date,end_date+2), window_size=40)\n",
    "    \n",
    "    obs = env_trade.reset()\n",
    "    while True: \n",
    "        #obs = obs[np.newaxis, ...]\n",
    "        #print(obs[-1])\n",
    "        action, _states = model.predict(obs)\n",
    "        action_list.append(action)\n",
    "        #print(action)\n",
    "        obs, rewards, done, info = env_trade.step(action)\n",
    "        if done:\n",
    "            print(\"info\", info)\n",
    "            break\n",
    "\n",
    "    return action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date stock_id  Trading_Volume  Trading_money  open    max    min  \\\n",
      "0     2004-01-02     2603        18474000      559709600  29.2  30.70  29.20   \n",
      "1     2004-01-05     2603        22464641      696260749  30.2  31.40  30.20   \n",
      "2     2004-01-06     2603        25271748      796775135  30.8  32.50  30.70   \n",
      "3     2004-01-07     2603        20119723      641040515  32.0  32.20  31.50   \n",
      "4     2004-01-08     2603        10439161      336599989  32.6  32.80  31.90   \n",
      "...          ...      ...             ...            ...   ...    ...    ...   \n",
      "1738  2010-12-27     2603        15094633      430216283  28.6  28.80  28.10   \n",
      "1739  2010-12-28     2603        14143260      405876268  28.7  29.00  28.40   \n",
      "1740  2010-12-29     2603        46878734     1376864085  28.7  30.05  28.70   \n",
      "1741  2010-12-30     2603        58590440     1814322745  30.4  31.80  30.05   \n",
      "1742  2010-12-31     2603        24005648      740570934  31.0  31.50  30.20   \n",
      "\n",
      "      close  spread  Trading_turnover  \n",
      "0     30.20    0.60              3262  \n",
      "1     30.70    0.50              3727  \n",
      "2     31.70    1.00              4267  \n",
      "3     32.20    0.50              3181  \n",
      "4     32.00   -0.20              2097  \n",
      "...     ...     ...               ...  \n",
      "1738  28.55   -0.10              3356  \n",
      "1739  28.45   -0.10              2674  \n",
      "1740  30.00    1.55              9854  \n",
      "1741  30.80    0.80             12273  \n",
      "1742  30.30   -0.50              5057  \n",
      "\n",
      "[1743 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df = api.taiwan_stock_daily(\n",
    "                    stock_id = '2603',\n",
    "                    start_date = '2004-1-1',\n",
    "                    end_date = '2010-12-31'\n",
    "        )\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################2395#########################################\n",
      "pretrain 0\n",
      "pretrain 1\n",
      "info {'total_reward': 55.416129044584544, 'total_profit': 0.006993595411793351, 'position': 1}\n",
      "action len :4202\n",
      "action len :4202\n",
      "==================Trading===================\n",
      "action len :4202\n",
      "============Trading Done============\n",
      "2395 final action len :4202\n",
      "0.00330396475770922\n",
      "#########################################2882#########################################\n",
      "pretrain 0\n",
      "pretrain 1\n",
      "info {'total_reward': 78.17848191009676, 'total_profit': 0.004238973893167086, 'position': 0}\n",
      "action len :4202\n",
      "action len :4202\n",
      "==================Trading===================\n",
      "action len :4202\n",
      "============Trading Done============\n",
      "2882 final action len :4202\n",
      "0.0\n",
      "#########################################2207#########################################\n",
      "pretrain 0\n",
      "pretrain 1\n",
      "info {'total_reward': 35.29374699144568, 'total_profit': 0.0015700241032654463, 'position': 1}\n",
      "action len :4202\n",
      "action len :4202\n",
      "==================Trading===================\n",
      "action len :4202\n",
      "============Trading Done============\n",
      "2207 final action len :4202\n",
      "0.00228310502283105\n",
      "#########################################3008#########################################\n",
      "pretrain 0\n",
      "pretrain 1\n",
      "info {'total_reward': 44.12044314026803, 'total_profit': 0.004107325739835086, 'position': 0}\n",
      "action len :4202\n",
      "action len :4202\n",
      "==================Trading===================\n",
      "action len :4202\n",
      "============Trading Done============\n",
      "3008 final action len :4202\n",
      "0.0037546933667083854\n",
      "#########################################1722#########################################\n",
      "pretrain 0\n",
      "pretrain 1\n",
      "info {'total_reward': 97.7917691743481, 'total_profit': 0.001289424456309024, 'position': 1}\n",
      "action len :4202\n",
      "action len :4202\n",
      "==================Trading===================\n",
      "action len :4202\n",
      "============Trading Done============\n",
      "1722 final action len :4202\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "stock_list = ['2395','2882','2207','3008','1722']\n",
    "\n",
    "for stock_id in stock_list:\n",
    "        print('#########################################'+stock_id+'#########################################')\n",
    "        start_date='1998-9-18'\n",
    "        end_date='2022-12-31'\n",
    "        df = api.taiwan_stock_daily(\n",
    "                    stock_id = stock_id,\n",
    "                    start_date = start_date,\n",
    "                    end_date = end_date\n",
    "        )\n",
    "\n",
    "        df = df.iloc[:][['date','open', 'max', 'min', 'close','Trading_Volume']]\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "        df.rename(columns = {'date':'Date', 'open':'Open','max':'High','min':'Low', 'close':'Close','Trading_Volume':'Volume'}, inplace = True)\n",
    "        dateArray = df['Date']\n",
    "        df.set_index('Date', inplace=True)\n",
    "\n",
    "        max_value = 0.8\n",
    "        min_value = 0.2\n",
    "\n",
    "        Max_Volume = df['Volume'].max()\n",
    "        Min_Volume = df['Volume'].min()\n",
    "        Max_Price = df['High'].max()\n",
    "        Min_Price = df['Low'].min()\n",
    "\n",
    "        df['EMA5'] = talib.EMA(df['Close'], timeperiod=5)\n",
    "        df['EMA20'] = talib.EMA(df['Close'], timeperiod=20)\n",
    "        df['EMA100'] = talib.EMA(df['Close'], timeperiod=100)\n",
    "        \n",
    "        df['K'], df['D'] = talib.STOCH(df['High'], df['Low'], df['Close'], fastk_period=14, slowk_period=2, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "        \n",
    "        df['TP'] = (df['Close'] + df['High'] + df['Low']) / 3\n",
    "        df['std'] = df['TP'].rolling(20).std(ddof=0)\n",
    "\n",
    "        df['RSI'] = talib.RSI(df.iloc[:]['Close'], timeperiod=14)/100\n",
    "        #df['EMA'] = talib.EMA(df.iloc[:]['Close'], timeperiod=10)\n",
    "        df['OBV'] = talib.OBV(df.iloc[:]['Close'], df.iloc[:]['Volume'])\n",
    "        Max_OBV = df['OBV'].max()\n",
    "        Min_OBV = df['OBV'].min()\n",
    "\n",
    "        df['High'] = min_value + (max_value - min_value) * (df['High'] - Min_Price) / (Max_Price - Min_Price)\n",
    "        df['Low'] = min_value + (max_value - min_value) * (df['Low'] - Min_Price) / (Max_Price - Min_Price)\n",
    "        df['Open'] = min_value + (max_value - min_value) * (df['Open'] - Min_Price) / (Max_Price - Min_Price)\n",
    "        df['Close'] = min_value + (max_value - min_value) * (df['Close'] - Min_Price) / (Max_Price - Min_Price)\n",
    "        df['Volume'] = min_value + (max_value - min_value) * (df['Volume'] - Min_Volume) / (Max_Volume - Min_Volume)\n",
    "\n",
    "        #df['EMA'] = min_value + (max_value - min_value) * (df['EMA'] - Min_Price) / (Max_Price - Min_Price)\n",
    "        df['EMA5'] = min_value + (max_value - min_value) * (df['EMA5'] - Min_Price) / (Max_Price - Min_Price)\n",
    "        df['EMA20'] = min_value + (max_value - min_value) * (df['EMA20'] - Min_Price) / (Max_Price - Min_Price)\n",
    "        df['EMA100'] = min_value + (max_value - min_value) * (df['EMA100'] - Min_Price) / (Max_Price - Min_Price)\n",
    "\n",
    "        df['OBV'] = min_value + (max_value - min_value) * (df['OBV'] - Min_OBV) / (Max_OBV - Min_OBV)\n",
    "        df['K'] /= 100\n",
    "        df['D'] /= 100\n",
    "\n",
    "\n",
    "\n",
    "        train_start = '2004-01-01'\n",
    "        train_start = datetime.strptime(train_start, '%Y-%m-%d')\n",
    "        train_start_idx = df.index.get_loc(dateArray[dateArray>=train_start].iloc[0])\n",
    "        train_end = '2014-01-01'\n",
    "        train_end = datetime.strptime(train_end, '%Y-%m-%d')\n",
    "        train_end_idx = df.index.get_loc(dateArray[dateArray<train_end].iloc[-1])\n",
    "        '''\n",
    "        test_start = '2021-01-01'\n",
    "        test_start = datetime.strptime(test_start, '%Y-%m-%d')\n",
    "        test_start_idx = df.index.get_loc(dateArray[dateArray>=test_start].iloc[0])\n",
    "        test_end = '2022-01-01'\n",
    "        test_end = datetime.strptime(test_end, '%Y-%m-%d')\n",
    "        test_end_idx = df.index.get_loc(dateArray[dateArray<test_end].iloc[-1])\n",
    "        '''\n",
    "\n",
    "\n",
    "        action_list = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        env_train = DummyVecEnv([lambda: StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=40)])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print('train start :',train_start_idx)\n",
    "        #print('train end :',train_end_idx)\n",
    "        \n",
    "        #env_val = StocksEnv2(df=df, frame_bound=(val_start_idx,val_end_idx), window_size=50)\n",
    "        #obs_val = env_val.reset()\n",
    "        \n",
    "        ############## Environment Setup ends ##############\n",
    "        \n",
    "        print(\"pretrain 0\")\n",
    "        #model_ppo = train_PPO(env_train, model_name=\"DQN_\"+stock_id+'_'+str(i), timesteps=2000000)\n",
    "        pretrained_model0 = PPO('MlpPolicy', env_train, verbose=0, ent_coef=0.01)\n",
    "        #pretrained_model0 = DQN('MlpPolicy', env_train, verbose=0)\n",
    "        pretrained_model0.learn(total_timesteps=1000000, callback=None)\n",
    "        env_val = StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=40)\n",
    "        obs_val = env_val.reset()\n",
    "        #action_list = DRL_prediction(df=df, model=pretrained_model0,start_date = train_start_idx,end_date = train_end_idx,action_list = action_list)\n",
    "        #print('action len :'+str(len(action_list)))\n",
    "        #sharpe_ppo = DRL_validation(df=df,model=pretrained_model0,test_env=env_val, test_obs=obs_val)\n",
    "        \n",
    "        \n",
    "        pretrained_model0.save('pretrained_model2.zip')\n",
    "        train_start = '2004-01-01'\n",
    "        train_start = datetime.strptime(train_start, '%Y-%m-%d')\n",
    "        train_start_idx = df.index.get_loc(dateArray[dateArray>=train_start].iloc[0])\n",
    "        train_end = '2021-01-01'\n",
    "        train_end = datetime.strptime(train_end, '%Y-%m-%d')\n",
    "        train_end_idx = df.index.get_loc(dateArray[dateArray<train_end].iloc[-1])\n",
    "        env = DummyVecEnv([lambda: StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=40)])\n",
    "        #pretrained_model = DQN.load(\"pretrained_model.zip\", env=env)\n",
    "        pretrained_model1 = PPO.load(\"pretrained_model2.zip\", env=env)\n",
    "        #pretrained_model1 = DQN.load(\"pretrained_model2.zip\", env=env)\n",
    "        print(\"pretrain 1\")\n",
    "        pretrained_model1.learn(total_timesteps=2000000, callback=None)\n",
    "        env_val = StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=40)\n",
    "        #env_val = StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=50)\n",
    "        obs_val = env_val.reset()\n",
    "        \n",
    "        action_list = DRL_prediction(df=df, model=pretrained_model1,start_date = train_start_idx,end_date = train_end_idx,action_list = action_list)\n",
    "        print('action len :'+str(len(action_list)))\n",
    "        #sharpe_ppo = DRL_validation(df=df,model=pretrained_model1,test_env=env_val, test_obs=obs_val)\n",
    "        '''\n",
    "        pretrained_model1.save('pretrained_model2.zip')\n",
    "        train_start = '2016-01-01'\n",
    "        train_start = datetime.strptime(train_start, '%Y-%m-%d')\n",
    "        train_start_idx = df.index.get_loc(dateArray[dateArray>=train_start].iloc[0])\n",
    "        train_end = '2021-01-01'\n",
    "        train_end = datetime.strptime(train_end, '%Y-%m-%d')\n",
    "        train_end_idx = df.index.get_loc(dateArray[dateArray<train_end].iloc[-1])\n",
    "        env = DummyVecEnv([lambda: StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=40)])\n",
    "        #pretrained_model = DQN.load(\"pretrained_model.zip\", env=env)\n",
    "        pretrained_model2 = PPO.load(\"pretrained_model2.zip\", env=env)\n",
    "        print(\"pretrain 2\")\n",
    "        pretrained_model2.learn(total_timesteps=2000000, callback=None)\n",
    "        env_val = StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=40)\n",
    "        obs_val = env_val.reset()\n",
    "        action_list = DRL_prediction(df=df, model=pretrained_model2,start_date = train_start_idx,end_date = train_end_idx,action_list = action_list)\n",
    "        #sharpe_ppo = DRL_validation(df=df,model=pretrained_model2,test_env=env_val, test_obs=obs_val)\n",
    "        '''\n",
    "        #action_list = DRL_prediction(df=df, model=pretrained_model2,start_date = train_start_idx,end_date = train_end_idx,action_list = action_list)\n",
    "        print('action len :'+str(len(action_list)))\n",
    "        \n",
    "        pretrained_model1.save(\"./model_final/RL/\" + stock_id + \"_RL.zip\")\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        pretrained_model2.save('pretrained_model2.zip')\n",
    "        train_start = '2004-01-01'\n",
    "        train_start = datetime.strptime(train_start, '%Y-%m-%d')\n",
    "        train_start_idx = df.index.get_loc(dateArray[dateArray>=train_start].iloc[0])\n",
    "        train_end = '2021-01-01'\n",
    "        train_end = datetime.strptime(train_end, '%Y-%m-%d')\n",
    "        train_end_idx = df.index.get_loc(dateArray[dateArray<train_end].iloc[-1])\n",
    "        env = DummyVecEnv([lambda: StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=50)]*4)\n",
    "        #pretrained_model = DQN.load(\"pretrained_model.zip\", env=env)\n",
    "        model_ppo = PPO.load(\"pretrained_model2.zip\", env=env)\n",
    "        print(\"pretrain 3\")\n",
    "        model_ppo.learn(total_timesteps=2000000, callback=None)\n",
    "        env_val = StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=50)\n",
    "        obs_val = env_val.reset()\n",
    "        sharpe_ppo = DRL_validation(df=df,model=model_ppo,test_env=env_val, test_obs=obs_val)'''\n",
    "        \n",
    "        \n",
    "        print(\"==================Trading===================\")\n",
    "        #print(\"Used Model: \", model_ensemble)\n",
    "        #action_list = DRL_prediction(df=df, model=model_ppo,start_date = train_start_idx,end_date = train_end_idx,action_list = action_list)\n",
    "        print('action len :'+str(len(action_list)))\n",
    "        \n",
    "        \n",
    "        print(\"============Trading Done============\")\n",
    "        ############## Trading ends ##############\n",
    "        \n",
    "        \n",
    "        print(str(stock_id)+' final action len :'+str(len(action_list)))\n",
    "    \n",
    "        #==============================save trajectory==========================================\n",
    "        trading_info = []\n",
    "        buy_sell_tuple = []\n",
    "        hold = 0\n",
    "        temp = []\n",
    "        trading_dic = {}\n",
    "        return_list = []\n",
    "\n",
    "        TaiwanStockPriceDay = api.taiwan_stock_daily(\n",
    "            stock_id = stock_id,\n",
    "            start_date = '2004-1-1',\n",
    "            end_date = '2020-12-31'\n",
    "            )\n",
    "\n",
    "        for i in range(len(action_list)):\n",
    "            if action_list[i] == 1:\n",
    "                if hold == 0:\n",
    "                    trading_info.append([i,'buy',TaiwanStockPriceDay['close'][i]])\n",
    "                    temp.append([i,TaiwanStockPriceDay['close'][i]])\n",
    "                    trading_dic[i] = ['buy', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "                    hold = 1\n",
    "                else:\n",
    "                    trading_info.append([i,'hold',TaiwanStockPriceDay['close'][i]])\n",
    "                    trading_dic[i] = ['hold', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "            else:\n",
    "                if hold == 1:\n",
    "                    trading_info.append([i,'sell',TaiwanStockPriceDay['close'][i]])\n",
    "                    temp.append([i,TaiwanStockPriceDay['close'][i]])\n",
    "                    temp.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                    return_list.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                    buy_sell_tuple.append(temp)\n",
    "                    temp = []\n",
    "                    trading_dic[i] = ['sell', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "\n",
    "                    hold = 0\n",
    "                else:\n",
    "                    trading_info.append([i,'hold',TaiwanStockPriceDay['close'][i]])\n",
    "                    trading_dic[i] = ['hold', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "        if hold ==1:\n",
    "                trading_info[-1][1] = 'sell'\n",
    "                trading_dic[len(trading_dic)-1][0] = 'sell'\n",
    "                temp.append([i, TaiwanStockPriceDay['close'][i]])\n",
    "                temp.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                return_list.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                buy_sell_tuple.append(temp)\n",
    "                temp = []\n",
    "        #print(trading_info)\n",
    "\n",
    "        with open(\"./data_new/Trajectory/Train/\" + stock_id + \"_\" + \"RL_trajectory_all_train.csv\",  'w', encoding='utf8', newline='') as csvFile:\n",
    "                writer = csv.writer(csvFile)\n",
    "                for trade in trading_info:\n",
    "                    writer.writerow(trade)\n",
    "\n",
    "        \n",
    "        median = statistics.median(return_list)\n",
    "        #median = 0\n",
    "\n",
    "        print(median)\n",
    "\n",
    "        for trade in buy_sell_tuple:\n",
    "            #total_sum += trade[2]\n",
    "\n",
    "\n",
    "            if trade[2] <median:\n",
    "\n",
    "                trading_dic[trade[0][0]][0] = 'hold'\n",
    "                trading_dic[trade[1][0]][0] = 'hold'\n",
    "        #print(trading_dic)\n",
    "\n",
    "\n",
    "        with open(\"./data_new/Trajectory/Train/\" + stock_id + \"_\" + \"RL_trajectory_50_train.csv\",  'w', encoding='utf8', newline='') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            for key in trading_dic.keys():\n",
    "                writer.writerow([key, trading_dic[key][0], trading_dic[key][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info {'total_reward': 19.95769781991071, 'total_profit': 0.8780982268706737, 'position': 1}\n",
      "action len :4673\n"
     ]
    }
   ],
   "source": [
    "action_list = DRL_prediction(df=df, model=pretrained_model2,start_date = train_start_idx,end_date = train_end_idx,action_list = action_list)\n",
    "print('action len :'+str(len(action_list)))\n",
    "        \n",
    "pretrained_model2.save(\"./model_final/RL/\" + stock_id + \"_RL.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4673"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "4202",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 4202 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b0473c96768a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mhold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtrading_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hold'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTaiwanStockPriceDay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mtrading_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'hold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaiwanStockPriceDay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 4202"
     ]
    }
   ],
   "source": [
    "        trading_info = []\n",
    "        buy_sell_tuple = []\n",
    "        hold = 0\n",
    "        temp = []\n",
    "        trading_dic = {}\n",
    "        return_list = []\n",
    "\n",
    "        TaiwanStockPriceDay = api.taiwan_stock_daily(\n",
    "            stock_id = '2603',\n",
    "            start_date = '2004-1-1',\n",
    "            end_date = '2020-12-31'\n",
    "            )\n",
    "\n",
    "        for i in range(len(action_list)):\n",
    "            if action_list[i] == 1:\n",
    "                if hold == 0:\n",
    "                    trading_info.append([i,'buy',TaiwanStockPriceDay['close'][i]])\n",
    "                    temp.append([i,TaiwanStockPriceDay['close'][i]])\n",
    "                    trading_dic[i] = ['buy', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "                    hold = 1\n",
    "                else:\n",
    "                    trading_info.append([i,'hold',TaiwanStockPriceDay['close'][i]])\n",
    "                    trading_dic[i] = ['hold', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "            else:\n",
    "                if hold == 1:\n",
    "                    trading_info.append([i,'sell',TaiwanStockPriceDay['close'][i]])\n",
    "                    temp.append([i,TaiwanStockPriceDay['close'][i]])\n",
    "                    temp.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                    return_list.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                    buy_sell_tuple.append(temp)\n",
    "                    temp = []\n",
    "                    trading_dic[i] = ['sell', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "\n",
    "                    hold = 0\n",
    "                else:\n",
    "                    trading_info.append([i,'hold',TaiwanStockPriceDay['close'][i]])\n",
    "                    trading_dic[i] = ['hold', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "        if hold ==1:\n",
    "                trading_info[-1][1] = 'sell'\n",
    "                trading_dic[len(trading_dic)-1][0] = 'sell'\n",
    "                temp.append([i, TaiwanStockPriceDay['close'][i]])\n",
    "                temp.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                return_list.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                buy_sell_tuple.append(temp)\n",
    "                temp = []\n",
    "        #print(trading_info)\n",
    "\n",
    "        with open(\"./data_new/Trajectory/RL/\" + stock_id + \"_\" + \"RL_trajectory_all_train_3.csv\",  'w', encoding='utf8', newline='') as csvFile:\n",
    "                writer = csv.writer(csvFile)\n",
    "                for trade in trading_info:\n",
    "                    writer.writerow(trade)\n",
    "\n",
    "        median = statistics.median(return_list)\n",
    "        #median = 0\n",
    "\n",
    "        print(median)\n",
    "\n",
    "        for trade in buy_sell_tuple:\n",
    "            #total_sum += trade[2]\n",
    "\n",
    "\n",
    "            if trade[2] <median:\n",
    "\n",
    "                trading_dic[trade[0][0]][0] = 'hold'\n",
    "                trading_dic[trade[1][0]][0] = 'hold'\n",
    "        #print(trading_dic)\n",
    "\n",
    "\n",
    "        with open(\"./data_new/Trajectory/RL/\" + stock_id + \"_\" + \"RL_trajectory_50_train_3.csv\",  'w', encoding='utf8', newline='') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            for key in trading_dic.keys():\n",
    "                writer.writerow([key, trading_dic[key][0], trading_dic[key][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = ['2330', '2603', '2002','1301', '2801']\n",
    "def sharpeRatio(Ret):\n",
    "    T = len(Ret)\n",
    "    if T == 0:\n",
    "        return 0\n",
    "    mean_ret = float(sum(Ret))/T\n",
    "    mean_sq_ret = float(sum(Ret**2))/T\n",
    "    if (mean_ret == 0.0) & (mean_sq_ret == 0.0):\n",
    "        return 0\n",
    "    if mean_sq_ret - mean_ret*mean_ret == 0:\n",
    "        return 0\n",
    "    sharpe = mean_ret/sqrt(mean_sq_ret - mean_ret*mean_ret)\n",
    "    return sharpe\n",
    "def calculate_annualized_return(initial_value, final_value, years):\n",
    "    total_return = (final_value / initial_value) - 1\n",
    "    annualized_return = (pow(1 + total_return, 1 / years) - 1)# * 100\n",
    "    return annualized_return\n",
    "for stock_id in stock_list:\n",
    "    print('#########################################'+stock_id+'#########################################')\n",
    "    train_start = '2021-01-01'\n",
    "    train_start = datetime.strptime(train_start, '%Y-%m-%d')\n",
    "    train_start_idx = df.index.get_loc(dateArray[dateArray>=train_start].iloc[0])\n",
    "    train_end = '2022-01-01'\n",
    "    train_end = datetime.strptime(train_end, '%Y-%m-%d')\n",
    "    train_end_idx = df.index.get_loc(dateArray[dateArray<train_end].iloc[-1])\n",
    "    \n",
    "    env_val2 = StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=40)\n",
    "    #env_val2 = StocksEnv2(df=df, frame_bound=(val_start_idx,val_end_idx), window_size=30)\n",
    "    obs_val = env_val2.reset()\n",
    "    #obs_val = env_val2.reset()\n",
    "    #sharpe ,sortino = DRL_validation(df=df,model=model,test_env=env_val2, test_obs=obs_val)\n",
    "    \n",
    "    model = PPO.load(\"./model_final/RL/\" + stock_id + \"_RL_4.zip\", env=env)\n",
    "    action_list = []\n",
    "    action_list = DRL_prediction(df=df, model=model,start_date = train_start_idx,end_date = train_end_idx,action_list = action_list)\n",
    "    \n",
    "    trading_info = []\n",
    "    buy_sell_tuple = []\n",
    "    hold = 0\n",
    "    temp = []\n",
    "    trading_dic = {}\n",
    "    return_list = []\n",
    "\n",
    "    TaiwanStockPriceDay = api.taiwan_stock_daily(\n",
    "            stock_id = stock_id,\n",
    "            start_date = '2021-1-1',\n",
    "            end_date = '2021-12-31'\n",
    "        )\n",
    "\n",
    "    for i in range(len(action_list)):\n",
    "            if action_list[i] == 1:\n",
    "                if hold == 0:\n",
    "                    trading_info.append([i,'buy',TaiwanStockPriceDay['close'][i]])\n",
    "                    temp.append([i,TaiwanStockPriceDay['close'][i]])\n",
    "                    trading_dic[i] = ['buy', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "                    hold = 1\n",
    "                else:\n",
    "                    trading_info.append([i,'hold',TaiwanStockPriceDay['close'][i]])\n",
    "                    trading_dic[i] = ['hold', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "            else:\n",
    "                if hold == 1:\n",
    "                    trading_info.append([i,'sell',TaiwanStockPriceDay['close'][i]])\n",
    "                    temp.append([i,TaiwanStockPriceDay['close'][i]])\n",
    "                    temp.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                    return_list.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                    buy_sell_tuple.append(temp)\n",
    "                    temp = []\n",
    "                    trading_dic[i] = ['sell', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "\n",
    "                    hold = 0\n",
    "                else:\n",
    "                    trading_info.append([i,'hold',TaiwanStockPriceDay['close'][i]])\n",
    "                    trading_dic[i] = ['hold', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "        if hold ==1:\n",
    "                trading_info[-1][1] = 'sell'\n",
    "                trading_dic[len(trading_dic)-1][0] = 'sell'\n",
    "                temp.append([i, TaiwanStockPriceDay['close'][i]])\n",
    "                temp.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                return_list.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                buy_sell_tuple.append(temp)\n",
    "                temp = []\n",
    "                \n",
    "    trajectory_list = []\n",
    "    for trade in trading_info:\n",
    "        trajectory_list.append(trade)\n",
    "    \n",
    "    \n",
    "    MAX_ACCOUNT_BALANCE = 10000\n",
    "    balance = MAX_ACCOUNT_BALANCE\n",
    "    net_worth = MAX_ACCOUNT_BALANCE\n",
    "    stock_num = 0\n",
    "    stock_value = 0\n",
    "    return_list = []\n",
    "    buy_price = 0\n",
    "    balances = []\n",
    "    for trajectory in trajectory_list:\n",
    "                #print(trajectory)\n",
    "                price = float(trajectory[2])\n",
    "                if trajectory[1] == 'buy':\n",
    "                    stock_num = int(balance / float(trajectory[2]))\n",
    "                    stock_value = stock_num * float(trajectory[2])\n",
    "                    balance = balance - stock_value - stock_value * fee\n",
    "                    #print(\"Buy at\", trajectory[2])\n",
    "                    #print(balance+stock_value)\n",
    "                    #print()\n",
    "                    \n",
    "                    buy_price = price\n",
    "                elif trajectory[1] == 'sell':\n",
    "                    stock_value = stock_num * float(trajectory[2])\n",
    "                    balance = balance + stock_value - stock_value * (fee + tax)\n",
    "                    stock_num = 0\n",
    "                    stock_value = 0\n",
    "                    #print(\"Sell at\", trajectory[2])\n",
    "                    #print(balance+stock_value)\n",
    "                    #print()\n",
    "                    \n",
    "                    return_list.append((price-buy_price)/buy_price)\n",
    "                    buy_price = 0\n",
    "                balances.append(balance+stock_value)\n",
    "    total.append(balances)\n",
    "                    \n",
    "    print(sid, s, t, balance+stock_value)\n",
    "    print('平均報酬率：',sum(return_list)/len(return_list))\n",
    "    print('年化報酬率：', calculate_annualized_return(MAX_ACCOUNT_BALANCE, balance+stock_value, 1))\n",
    "    print('sharpe ratio：',sharpeRatio(np.array(return_list)))\n",
    "            \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock",
   "language": "python",
   "name": "stock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
