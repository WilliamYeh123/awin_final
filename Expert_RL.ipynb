{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/gym/envs/registration.py:216: UserWarning: \u001b[33mWARN: Overriding environment forex-v0\u001b[0m\n",
      "  logger.warn(\"Overriding environment {}\".format(id))\n",
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/gym/envs/registration.py:216: UserWarning: \u001b[33mWARN: Overriding environment stocks-v0\u001b[0m\n",
      "  logger.warn(\"Overriding environment {}\".format(id))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "#from gym_trade.gym_anytrading.envs.stocks_env import StocksEnv\n",
    "#from env.ExpertEnv import StockTradingEnv\n",
    "import pandas as pd\n",
    "from FinMind.data import DataLoader\n",
    "#from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "#from stable_baselines3.common.evaluation import evaluate_policy\n",
    "#from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "import statistics\n",
    "from gym import spaces\n",
    "#from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import A2C,PPO,DQN\n",
    "#from stable_baselines import TRPO\n",
    "import gym_anytrading\n",
    "#from stable_baselines3 import PPO,DDPG\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "from sb3_contrib.ppo_recurrent.ppo_recurrent import RecurrentPPO\n",
    "from sb3_contrib.trpo.trpo import TRPO\n",
    "from sb3_contrib.qrdqn.qrdqn import QRDQN\n",
    "\n",
    "import talib\n",
    "import torch\n",
    "\n",
    "from gym_anytrading.envs import StocksEnv\n",
    "from gym_trade.gym_anytrading.envs import StocksEnv as StocksEnv2\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "api_token = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkYXRlIjoiMjAyMS0xMi0yNyAxNDo1OTowOSIsInVzZXJfaWQiOiJkdXJhbnQ3MTA5MTYiLCJpcCI6IjE0MC4xMjAuMTMuMjMwIn0.8-KIC3-OA4D6JcOtQ_fJBOVkyugx60t1Gy82c57TLz4\"\n",
    "\n",
    "api = DataLoader()\n",
    "api.login_by_token(api_token = api_token)\n",
    "\n",
    "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_A2C(env_train, model_name, timesteps=50000):\n",
    "    \"\"\"A2C model\"\"\"\n",
    "    stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=5, min_evals=5, verbose=0)\n",
    "    eval_callback = EvalCallback(env_train, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=0)\n",
    "\n",
    "    start = time.time()\n",
    "    #model = A2C('MlpPolicy', env_train, verbose=0)\n",
    "    #model = A2C('MlpPolicy', env_train, verbose=0, ent_coef=0.1)\n",
    "    #model.learn(total_timesteps=timesteps, callback=eval_callback)\n",
    "    model = A2C('MlpPolicy', env_train, verbose=0, ent_coef=0.01,n_steps=10)\n",
    "    model.learn(total_timesteps=timesteps, callback=None)\n",
    "    end = time.time()\n",
    "\n",
    "    #model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name}\")\n",
    "    #model.save(\"./expert_model/\" + model_name)\n",
    "    print('Training time (A2C): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_PPO(env_train, model_name, timesteps=200000):\n",
    "    \"\"\"PPO model\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=20, min_evals=5, verbose=0)\n",
    "    eval_callback = EvalCallback(env_train, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=0)\n",
    "\n",
    "    model = PPO('MlpPolicy', env_train, verbose=0, ent_coef=0.01)\n",
    "    model.learn(total_timesteps=timesteps, callback=None)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(\"./expert_model/\" + model_name)\n",
    "    print('Training time (PPO): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "def train_DQN(env_train, model_name, timesteps=50000):\n",
    "    \"\"\"DQN model\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    #model = A2C('MlpPolicy', env_train, verbose=0)\n",
    "    stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=20, min_evals=5, verbose=0)\n",
    "    eval_callback = EvalCallback(env_train, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=0)\n",
    "\n",
    "    model = DQN('MlpPolicy', env_train, verbose=0)\n",
    "    model.learn(total_timesteps=timesteps, callback=None)\n",
    "    end = time.time()\n",
    "\n",
    "    #model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name}\")\n",
    "    #model.save(\"./expert_model/\" + model_name)\n",
    "    print('Training time (DQN): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_RPPO(env_train, model_name, timesteps=50000):\n",
    "    \"\"\"TRPO model\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=10, min_evals=5, verbose=0)\n",
    "    eval_callback = EvalCallback(env_train, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=0)\n",
    "\n",
    "    model = RecurrentPPO('MlpLstmPolicy', env_train, verbose=0)\n",
    "    model.learn(total_timesteps=timesteps, callback=None)\n",
    "    end = time.time()\n",
    "\n",
    "    #model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name}\")\n",
    "    #model.save(\"./expert_model/\" + model_name)\n",
    "    print('Training time (RPPO): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_TRPO(env_train, model_name, timesteps=50000):\n",
    "    \"\"\"TRPO model\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=10, min_evals=5, verbose=0)\n",
    "    eval_callback = EvalCallback(env_train, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=0)\n",
    "    \n",
    "    #model = A2C('MlpPolicy', env_train, verbose=0)\n",
    "    model = TRPO('MlpPolicy', env_train, verbose=0, cg_max_steps=30)\n",
    "\n",
    "    model.learn(total_timesteps=timesteps, callback=None)\n",
    "    end = time.time()\n",
    "\n",
    "    #model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name}\")\n",
    "    #model.save(\"./expert_model/\" + model_name)\n",
    "    print('Training time (TRPO): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "def sharpeRatio(Ret):\n",
    "    T = len(Ret)\n",
    "    if T == 0:\n",
    "        return 0\n",
    "    mean_ret = float(sum(Ret))/T\n",
    "    mean_sq_ret = float(sum(Ret**2))/T\n",
    "    if (mean_ret == 0.0) & (mean_sq_ret == 0.0):\n",
    "        return 0\n",
    "    if mean_sq_ret - mean_ret*mean_ret == 0:\n",
    "        return 0\n",
    "    sharpe = mean_ret/sqrt(mean_sq_ret - mean_ret*mean_ret)\n",
    "    return sharpe\n",
    "def DRL_validation(df ,model, test_env, test_obs) -> None:\n",
    "    ###validation process###\n",
    "    #env_val2 = MyCustomEnv(df=df, frame_bound=(val_start_idx,val_end_idx), window_size=20)\n",
    "    #obs_val2 = env_val2.reset()\n",
    "    \n",
    "    action_list = []\n",
    "        \n",
    "    final_action = []\n",
    "    hold = 0\n",
    "    temp = []\n",
    "    buy_price = 0\n",
    "    #prices = []\n",
    "    return_list = []\n",
    "    Rf = 0.02   # 假設無風險利率為2%\n",
    "    downside_deviation = []\n",
    "    action_count=0\n",
    "    while True: \n",
    "        test_obs = test_obs[np.newaxis, ...]\n",
    "        #print(test_obs)\n",
    "        price = test_obs[0][-1][3]\n",
    "        #print(price)\n",
    "        #print(obs.shape)\n",
    "        action, _states = model.predict(test_obs)\n",
    "        #print(action[0])\n",
    "        action_count+=1\n",
    "        if action[0] == 1:\n",
    "            if hold == 0:\n",
    "                #print('buy ',price)\n",
    "                #buy\n",
    "                buy_price = price\n",
    "                hold = 1\n",
    "           \n",
    "                #print('hold')\n",
    "        elif action[0] == 0:\n",
    "            if hold == 1:\n",
    "                #sell\n",
    "                #print('sell ',price)\n",
    "                return_list.append((price-buy_price)/buy_price)\n",
    "                hold = 0\n",
    "            \n",
    "                #print('hold')\n",
    "        \n",
    "        #action_list.append(action[0])\n",
    "        #obs, rewards, dones, info = env.step(action)\n",
    "        test_obs, rewards, done, info = test_env.step(action)\n",
    "        if done:\n",
    "            print(\"info\", info)\n",
    "            break\n",
    "    #print(return_list)\n",
    "    #print(len(return_list))\n",
    "    #print(action_count)\n",
    "    \n",
    "    for r in return_list:\n",
    "        if r-Rf<=0:\n",
    "            downside_deviation.append(0)\n",
    "        else:\n",
    "            downside_deviation.append(r-Rf)\n",
    "    \n",
    "    #Sharpe Ratio\n",
    "    #Rp = (1 + np.mean(return_list)) ** (action_count / len(return_list)) - 1\n",
    "    Rp = np.mean(return_list)\n",
    "    #print(Rp)\n",
    "    #print(Rp)\n",
    "    # 確定無風險利率\n",
    "    \n",
    "    # 計算標準差\n",
    "    sigma_p = np.std(return_list)\n",
    "    #print(sigma_p)\n",
    "    \n",
    "    # 計算Sharpe Ratio\n",
    "    Sharpe_ratio = (Rp - Rf) / sigma_p\n",
    "    Sortino_ratio = (Rp - Rf) / np.std(downside_deviation)\n",
    "    Sharpe_ratio = sharpeRatio(np.array(return_list))\n",
    "    return Sharpe_ratio\n",
    "def DRL_prediction(df,\n",
    "                   model,\n",
    "                   #name,\n",
    "                   #last_state,\n",
    "                   start_date,\n",
    "                   end_date,\n",
    "                   action_list\n",
    "                  ):\n",
    "    ### make a prediction based on trained model###\n",
    "\n",
    "    ## trading env\n",
    "    #trade_data = df[start_date:end_date+1]\n",
    "    #env_trade = MyCustomEnv(df=df, frame_bound=(start_date,end_date+1), window_size=20)\n",
    "    env_trade = StocksEnv2(df=df, frame_bound=(start_date,end_date+2), window_size=50)\n",
    "    \n",
    "    obs = env_trade.reset()\n",
    "    while True: \n",
    "        #obs = obs[np.newaxis, ...]\n",
    "        #print(obs[-1])\n",
    "        action, _states = model.predict(obs)\n",
    "        action_list.append(action)\n",
    "        #print(action)\n",
    "        obs, rewards, done, info = env_trade.step(action)\n",
    "        if done:\n",
    "            print(\"info\", info)\n",
    "            break\n",
    "\n",
    "    return action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.9\n",
      "26.0\n",
      "26.3\n",
      "28.5\n",
      "29.1\n",
      "28.9\n",
      "29.3\n",
      "29.5\n",
      "29.6\n",
      "27.8\n",
      "27.7\n",
      "28.9\n",
      "29.5\n",
      "28.5\n",
      "28.4\n",
      "28.1\n",
      "28.0\n",
      "28.3\n",
      "28.7\n",
      "29.5\n",
      "29.5\n",
      "29.8\n",
      "29.6\n",
      "30.8\n",
      "31.4\n",
      "30.1\n",
      "29.0\n",
      "29.2\n",
      "28.9\n",
      "29.1\n",
      "29.1\n",
      "28.1\n",
      "28.2\n",
      "28.0\n",
      "28.2\n",
      "28.8\n",
      "28.7\n",
      "27.9\n",
      "28.1\n",
      "28.0\n",
      "27.5\n",
      "27.4\n",
      "27.3\n",
      "26.6\n",
      "26.5\n",
      "26.7\n",
      "26.7\n",
      "26.7\n",
      "27.0\n",
      "27.8\n",
      "28.4\n",
      "29.7\n",
      "29.0\n",
      "29.5\n",
      "28.0\n",
      "28.2\n",
      "28.4\n",
      "28.9\n",
      "29.1\n",
      "29.6\n",
      "29.1\n",
      "29.2\n",
      "29.0\n",
      "29.0\n",
      "info {'total_reward': 1.20000000000001, 'total_profit': 0.8071818386308788, 'position': 0}\n"
     ]
    }
   ],
   "source": [
    "env_val = MyCustomEnv(df=df, frame_bound=(val_start_idx,val_end_idx+1), window_size=20)\n",
    "obs_val = env_val.reset()\n",
    "\n",
    "sharpe_ppo = DRL_validation(df=df,model=model_ppo,test_env=env_val, test_obs=obs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>EMA</th>\n",
       "      <th>OBV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-02</th>\n",
       "      <td>29.2</td>\n",
       "      <td>30.7</td>\n",
       "      <td>29.2</td>\n",
       "      <td>30.2</td>\n",
       "      <td>18474000</td>\n",
       "      <td>59.353708</td>\n",
       "      <td>29.506064</td>\n",
       "      <td>1.884618e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-05</th>\n",
       "      <td>30.2</td>\n",
       "      <td>31.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>30.7</td>\n",
       "      <td>22464641</td>\n",
       "      <td>62.492911</td>\n",
       "      <td>29.723144</td>\n",
       "      <td>1.907082e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-06</th>\n",
       "      <td>30.8</td>\n",
       "      <td>32.5</td>\n",
       "      <td>30.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>25271748</td>\n",
       "      <td>67.842236</td>\n",
       "      <td>30.082572</td>\n",
       "      <td>1.932354e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-07</th>\n",
       "      <td>32.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>32.2</td>\n",
       "      <td>20119723</td>\n",
       "      <td>70.135703</td>\n",
       "      <td>30.467559</td>\n",
       "      <td>1.952474e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>32.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>31.9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10439161</td>\n",
       "      <td>68.045209</td>\n",
       "      <td>30.746185</td>\n",
       "      <td>1.942035e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-09</th>\n",
       "      <td>32.3</td>\n",
       "      <td>32.4</td>\n",
       "      <td>31.6</td>\n",
       "      <td>32.2</td>\n",
       "      <td>16689753</td>\n",
       "      <td>69.039032</td>\n",
       "      <td>31.010515</td>\n",
       "      <td>1.958725e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-12</th>\n",
       "      <td>32.2</td>\n",
       "      <td>32.3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8024314</td>\n",
       "      <td>57.486552</td>\n",
       "      <td>31.008603</td>\n",
       "      <td>1.950700e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-13</th>\n",
       "      <td>31.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.7</td>\n",
       "      <td>9626198</td>\n",
       "      <td>55.008365</td>\n",
       "      <td>30.952493</td>\n",
       "      <td>1.941074e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-14</th>\n",
       "      <td>30.7</td>\n",
       "      <td>32.3</td>\n",
       "      <td>30.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>16150432</td>\n",
       "      <td>61.553011</td>\n",
       "      <td>31.106585</td>\n",
       "      <td>1.957224e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-15</th>\n",
       "      <td>32.1</td>\n",
       "      <td>32.2</td>\n",
       "      <td>31.3</td>\n",
       "      <td>31.5</td>\n",
       "      <td>4547393</td>\n",
       "      <td>59.030996</td>\n",
       "      <td>31.178115</td>\n",
       "      <td>1.952677e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-16</th>\n",
       "      <td>31.6</td>\n",
       "      <td>32.9</td>\n",
       "      <td>31.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>20514081</td>\n",
       "      <td>65.607168</td>\n",
       "      <td>31.473003</td>\n",
       "      <td>1.973191e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-27</th>\n",
       "      <td>33.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>23691000</td>\n",
       "      <td>72.543857</td>\n",
       "      <td>32.059730</td>\n",
       "      <td>1.996882e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-28</th>\n",
       "      <td>34.7</td>\n",
       "      <td>34.7</td>\n",
       "      <td>33.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11694300</td>\n",
       "      <td>67.168824</td>\n",
       "      <td>32.412506</td>\n",
       "      <td>1.985188e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-29</th>\n",
       "      <td>33.9</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.9</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24359790</td>\n",
       "      <td>67.168824</td>\n",
       "      <td>32.701142</td>\n",
       "      <td>1.985188e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-30</th>\n",
       "      <td>34.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>33.7</td>\n",
       "      <td>34.6</td>\n",
       "      <td>13490292</td>\n",
       "      <td>69.421116</td>\n",
       "      <td>33.046389</td>\n",
       "      <td>1.998678e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-02</th>\n",
       "      <td>34.6</td>\n",
       "      <td>34.9</td>\n",
       "      <td>34.1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>8508249</td>\n",
       "      <td>68.576715</td>\n",
       "      <td>33.310682</td>\n",
       "      <td>1.990170e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-03</th>\n",
       "      <td>34.0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>33.7</td>\n",
       "      <td>10515230</td>\n",
       "      <td>62.072015</td>\n",
       "      <td>33.381467</td>\n",
       "      <td>1.979655e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-04</th>\n",
       "      <td>34.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>33.8</td>\n",
       "      <td>34.9</td>\n",
       "      <td>26240545</td>\n",
       "      <td>67.111344</td>\n",
       "      <td>33.657564</td>\n",
       "      <td>2.005895e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-05</th>\n",
       "      <td>34.9</td>\n",
       "      <td>35.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>34.6</td>\n",
       "      <td>10116658</td>\n",
       "      <td>64.793578</td>\n",
       "      <td>33.828916</td>\n",
       "      <td>1.995779e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-06</th>\n",
       "      <td>34.6</td>\n",
       "      <td>34.8</td>\n",
       "      <td>34.1</td>\n",
       "      <td>34.6</td>\n",
       "      <td>10282120</td>\n",
       "      <td>64.793578</td>\n",
       "      <td>33.969113</td>\n",
       "      <td>1.995779e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-09</th>\n",
       "      <td>34.9</td>\n",
       "      <td>35.8</td>\n",
       "      <td>34.7</td>\n",
       "      <td>35.1</td>\n",
       "      <td>16864600</td>\n",
       "      <td>66.996750</td>\n",
       "      <td>34.174729</td>\n",
       "      <td>2.012643e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-10</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>34.4</td>\n",
       "      <td>35.1</td>\n",
       "      <td>11259383</td>\n",
       "      <td>66.996750</td>\n",
       "      <td>34.342960</td>\n",
       "      <td>2.012643e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-11</th>\n",
       "      <td>35.5</td>\n",
       "      <td>36.3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.7</td>\n",
       "      <td>15527792</td>\n",
       "      <td>69.640788</td>\n",
       "      <td>34.589694</td>\n",
       "      <td>2.028171e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12</th>\n",
       "      <td>35.7</td>\n",
       "      <td>35.9</td>\n",
       "      <td>34.7</td>\n",
       "      <td>34.7</td>\n",
       "      <td>8331471</td>\n",
       "      <td>60.885714</td>\n",
       "      <td>34.609750</td>\n",
       "      <td>2.019839e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-13</th>\n",
       "      <td>34.7</td>\n",
       "      <td>34.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.4</td>\n",
       "      <td>9454696</td>\n",
       "      <td>58.509274</td>\n",
       "      <td>34.571614</td>\n",
       "      <td>2.010385e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-16</th>\n",
       "      <td>34.4</td>\n",
       "      <td>34.8</td>\n",
       "      <td>34.4</td>\n",
       "      <td>34.4</td>\n",
       "      <td>5299651</td>\n",
       "      <td>58.509274</td>\n",
       "      <td>34.540411</td>\n",
       "      <td>2.010385e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-17</th>\n",
       "      <td>34.4</td>\n",
       "      <td>35.2</td>\n",
       "      <td>34.1</td>\n",
       "      <td>34.8</td>\n",
       "      <td>15428822</td>\n",
       "      <td>60.870943</td>\n",
       "      <td>34.587609</td>\n",
       "      <td>2.025814e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-18</th>\n",
       "      <td>35.1</td>\n",
       "      <td>35.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9745667</td>\n",
       "      <td>62.034562</td>\n",
       "      <td>34.662589</td>\n",
       "      <td>2.035559e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>34.5</td>\n",
       "      <td>35.4</td>\n",
       "      <td>11532506</td>\n",
       "      <td>64.319909</td>\n",
       "      <td>34.796664</td>\n",
       "      <td>2.047092e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-20</th>\n",
       "      <td>35.6</td>\n",
       "      <td>36.2</td>\n",
       "      <td>34.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10636955</td>\n",
       "      <td>60.404156</td>\n",
       "      <td>34.833634</td>\n",
       "      <td>2.036455e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-23</th>\n",
       "      <td>34.9</td>\n",
       "      <td>35.8</td>\n",
       "      <td>34.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9678899</td>\n",
       "      <td>60.404156</td>\n",
       "      <td>34.863882</td>\n",
       "      <td>2.036455e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-24</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>34.7</td>\n",
       "      <td>34.7</td>\n",
       "      <td>6552395</td>\n",
       "      <td>57.366366</td>\n",
       "      <td>34.834086</td>\n",
       "      <td>2.029902e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-25</th>\n",
       "      <td>34.7</td>\n",
       "      <td>35.4</td>\n",
       "      <td>34.4</td>\n",
       "      <td>35.1</td>\n",
       "      <td>6650045</td>\n",
       "      <td>60.237713</td>\n",
       "      <td>34.882434</td>\n",
       "      <td>2.036552e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-26</th>\n",
       "      <td>35.3</td>\n",
       "      <td>35.7</td>\n",
       "      <td>34.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10721519</td>\n",
       "      <td>59.164905</td>\n",
       "      <td>34.903809</td>\n",
       "      <td>2.025831e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-27</th>\n",
       "      <td>35.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>33625226</td>\n",
       "      <td>67.808709</td>\n",
       "      <td>35.175844</td>\n",
       "      <td>2.059456e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-01</th>\n",
       "      <td>36.6</td>\n",
       "      <td>37.8</td>\n",
       "      <td>36.6</td>\n",
       "      <td>37.5</td>\n",
       "      <td>34229345</td>\n",
       "      <td>72.698661</td>\n",
       "      <td>35.598418</td>\n",
       "      <td>2.093686e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-02</th>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>37.4</td>\n",
       "      <td>11839977</td>\n",
       "      <td>71.633357</td>\n",
       "      <td>35.925978</td>\n",
       "      <td>2.081846e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-03</th>\n",
       "      <td>37.4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>37.5</td>\n",
       "      <td>16984597</td>\n",
       "      <td>72.074054</td>\n",
       "      <td>36.212164</td>\n",
       "      <td>2.098830e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-04</th>\n",
       "      <td>37.5</td>\n",
       "      <td>38.2</td>\n",
       "      <td>37.1</td>\n",
       "      <td>37.3</td>\n",
       "      <td>9858220</td>\n",
       "      <td>69.740429</td>\n",
       "      <td>36.409952</td>\n",
       "      <td>2.088972e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-05</th>\n",
       "      <td>37.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>14343633</td>\n",
       "      <td>63.136002</td>\n",
       "      <td>36.462688</td>\n",
       "      <td>2.074628e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-08</th>\n",
       "      <td>36.7</td>\n",
       "      <td>37.1</td>\n",
       "      <td>36.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>8178644</td>\n",
       "      <td>64.347989</td>\n",
       "      <td>36.542200</td>\n",
       "      <td>2.082807e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-09</th>\n",
       "      <td>36.9</td>\n",
       "      <td>37.9</td>\n",
       "      <td>36.9</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12136541</td>\n",
       "      <td>69.247699</td>\n",
       "      <td>36.770891</td>\n",
       "      <td>2.094943e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10</th>\n",
       "      <td>37.6</td>\n",
       "      <td>38.7</td>\n",
       "      <td>37.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>18044791</td>\n",
       "      <td>69.247699</td>\n",
       "      <td>36.958001</td>\n",
       "      <td>2.094943e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-11</th>\n",
       "      <td>37.3</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.1</td>\n",
       "      <td>37.5</td>\n",
       "      <td>9128124</td>\n",
       "      <td>65.754221</td>\n",
       "      <td>37.056547</td>\n",
       "      <td>2.085815e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-12</th>\n",
       "      <td>36.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>7013231</td>\n",
       "      <td>58.356417</td>\n",
       "      <td>37.009902</td>\n",
       "      <td>2.078802e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-15</th>\n",
       "      <td>36.5</td>\n",
       "      <td>38.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>37.3</td>\n",
       "      <td>34814673</td>\n",
       "      <td>61.673350</td>\n",
       "      <td>37.062647</td>\n",
       "      <td>2.113617e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-16</th>\n",
       "      <td>37.3</td>\n",
       "      <td>37.4</td>\n",
       "      <td>36.6</td>\n",
       "      <td>36.8</td>\n",
       "      <td>18322903</td>\n",
       "      <td>56.801095</td>\n",
       "      <td>37.014893</td>\n",
       "      <td>2.095294e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-17</th>\n",
       "      <td>37.0</td>\n",
       "      <td>37.9</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>15264533</td>\n",
       "      <td>61.976971</td>\n",
       "      <td>37.121276</td>\n",
       "      <td>2.110558e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-18</th>\n",
       "      <td>37.8</td>\n",
       "      <td>40.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>39.7</td>\n",
       "      <td>33785117</td>\n",
       "      <td>71.597213</td>\n",
       "      <td>37.590135</td>\n",
       "      <td>2.144344e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-19</th>\n",
       "      <td>39.8</td>\n",
       "      <td>40.7</td>\n",
       "      <td>39.5</td>\n",
       "      <td>40.2</td>\n",
       "      <td>40270357</td>\n",
       "      <td>73.327576</td>\n",
       "      <td>38.064656</td>\n",
       "      <td>2.184614e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-22</th>\n",
       "      <td>37.4</td>\n",
       "      <td>37.4</td>\n",
       "      <td>37.4</td>\n",
       "      <td>37.4</td>\n",
       "      <td>1703633</td>\n",
       "      <td>53.625224</td>\n",
       "      <td>37.943809</td>\n",
       "      <td>2.182910e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-23</th>\n",
       "      <td>34.8</td>\n",
       "      <td>34.8</td>\n",
       "      <td>34.8</td>\n",
       "      <td>34.8</td>\n",
       "      <td>5949478</td>\n",
       "      <td>42.268201</td>\n",
       "      <td>37.372208</td>\n",
       "      <td>2.176961e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-24</th>\n",
       "      <td>33.8</td>\n",
       "      <td>34.8</td>\n",
       "      <td>32.4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>48693456</td>\n",
       "      <td>36.504223</td>\n",
       "      <td>36.577261</td>\n",
       "      <td>2.128267e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-25</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.7</td>\n",
       "      <td>31.5</td>\n",
       "      <td>32.5</td>\n",
       "      <td>23726028</td>\n",
       "      <td>35.073455</td>\n",
       "      <td>35.835941</td>\n",
       "      <td>2.104541e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-26</th>\n",
       "      <td>32.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.3</td>\n",
       "      <td>30.5</td>\n",
       "      <td>20230145</td>\n",
       "      <td>30.007107</td>\n",
       "      <td>34.865770</td>\n",
       "      <td>2.084311e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-29</th>\n",
       "      <td>32.5</td>\n",
       "      <td>32.6</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>9481951</td>\n",
       "      <td>39.834493</td>\n",
       "      <td>34.453812</td>\n",
       "      <td>2.093793e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-30</th>\n",
       "      <td>33.3</td>\n",
       "      <td>33.4</td>\n",
       "      <td>32.5</td>\n",
       "      <td>33.3</td>\n",
       "      <td>20752490</td>\n",
       "      <td>42.721445</td>\n",
       "      <td>34.244028</td>\n",
       "      <td>2.114546e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-31</th>\n",
       "      <td>33.4</td>\n",
       "      <td>33.7</td>\n",
       "      <td>32.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>20958403</td>\n",
       "      <td>42.721445</td>\n",
       "      <td>34.072386</td>\n",
       "      <td>2.114546e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-01</th>\n",
       "      <td>33.2</td>\n",
       "      <td>33.3</td>\n",
       "      <td>32.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>7323285</td>\n",
       "      <td>39.000801</td>\n",
       "      <td>33.713771</td>\n",
       "      <td>2.107222e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open  High   Low  Close    Volume        RSI        EMA  \\\n",
       "Date                                                                  \n",
       "2004-01-02  29.2  30.7  29.2   30.2  18474000  59.353708  29.506064   \n",
       "2004-01-05  30.2  31.4  30.2   30.7  22464641  62.492911  29.723144   \n",
       "2004-01-06  30.8  32.5  30.7   31.7  25271748  67.842236  30.082572   \n",
       "2004-01-07  32.0  32.2  31.5   32.2  20119723  70.135703  30.467559   \n",
       "2004-01-08  32.6  32.8  31.9   32.0  10439161  68.045209  30.746185   \n",
       "2004-01-09  32.3  32.4  31.6   32.2  16689753  69.039032  31.010515   \n",
       "2004-01-12  32.2  32.3  31.0   31.0   8024314  57.486552  31.008603   \n",
       "2004-01-13  31.0  31.3  30.5   30.7   9626198  55.008365  30.952493   \n",
       "2004-01-14  30.7  32.3  30.6   31.8  16150432  61.553011  31.106585   \n",
       "2004-01-15  32.1  32.2  31.3   31.5   4547393  59.030996  31.178115   \n",
       "2004-01-16  31.6  32.9  31.6   32.8  20514081  65.607168  31.473003   \n",
       "2004-01-27  33.5  35.0  33.3   34.7  23691000  72.543857  32.059730   \n",
       "2004-01-28  34.7  34.7  33.8   34.0  11694300  67.168824  32.412506   \n",
       "2004-01-29  33.9  35.0  33.9   34.0  24359790  67.168824  32.701142   \n",
       "2004-01-30  34.0  34.9  33.7   34.6  13490292  69.421116  33.046389   \n",
       "2004-02-02  34.6  34.9  34.1   34.5   8508249  68.576715  33.310682   \n",
       "2004-02-03  34.0  34.2  33.2   33.7  10515230  62.072015  33.381467   \n",
       "2004-02-04  34.0  35.5  33.8   34.9  26240545  67.111344  33.657564   \n",
       "2004-02-05  34.9  35.2  34.3   34.6  10116658  64.793578  33.828916   \n",
       "2004-02-06  34.6  34.8  34.1   34.6  10282120  64.793578  33.969113   \n",
       "2004-02-09  34.9  35.8  34.7   35.1  16864600  66.996750  34.174729   \n",
       "2004-02-10  35.0  35.1  34.4   35.1  11259383  66.996750  34.342960   \n",
       "2004-02-11  35.5  36.3  35.0   35.7  15527792  69.640788  34.589694   \n",
       "2004-02-12  35.7  35.9  34.7   34.7   8331471  60.885714  34.609750   \n",
       "2004-02-13  34.7  34.8  34.0   34.4   9454696  58.509274  34.571614   \n",
       "2004-02-16  34.4  34.8  34.4   34.4   5299651  58.509274  34.540411   \n",
       "2004-02-17  34.4  35.2  34.1   34.8  15428822  60.870943  34.587609   \n",
       "2004-02-18  35.1  35.6  34.7   35.0   9745667  62.034562  34.662589   \n",
       "2004-02-19  35.0  35.6  34.5   35.4  11532506  64.319909  34.796664   \n",
       "2004-02-20  35.6  36.2  34.8   35.0  10636955  60.404156  34.833634   \n",
       "2004-02-23  34.9  35.8  34.6   35.0   9678899  60.404156  34.863882   \n",
       "2004-02-24  35.0  35.5  34.7   34.7   6552395  57.366366  34.834086   \n",
       "2004-02-25  34.7  35.4  34.4   35.1   6650045  60.237713  34.882434   \n",
       "2004-02-26  35.3  35.7  34.8   35.0  10721519  59.164905  34.903809   \n",
       "2004-02-27  35.0  37.2  35.0   36.4  33625226  67.808709  35.175844   \n",
       "2004-03-01  36.6  37.8  36.6   37.5  34229345  72.698661  35.598418   \n",
       "2004-03-02  38.0  38.0  36.7   37.4  11839977  71.633357  35.925978   \n",
       "2004-03-03  37.4  39.0  37.4   37.5  16984597  72.074054  36.212164   \n",
       "2004-03-04  37.5  38.2  37.1   37.3   9858220  69.740429  36.409952   \n",
       "2004-03-05  37.3  38.0  36.6   36.7  14343633  63.136002  36.462688   \n",
       "2004-03-08  36.7  37.1  36.4   36.9   8178644  64.347989  36.542200   \n",
       "2004-03-09  36.9  37.9  36.9   37.8  12136541  69.247699  36.770891   \n",
       "2004-03-10  37.6  38.7  37.1   37.8  18044791  69.247699  36.958001   \n",
       "2004-03-11  37.3  37.7  37.1   37.5   9128124  65.754221  37.056547   \n",
       "2004-03-12  36.5  37.0  36.5   36.8   7013231  58.356417  37.009902   \n",
       "2004-03-15  36.5  38.5  36.5   37.3  34814673  61.673350  37.062647   \n",
       "2004-03-16  37.3  37.4  36.6   36.8  18322903  56.801095  37.014893   \n",
       "2004-03-17  37.0  37.9  37.0   37.6  15264533  61.976971  37.121276   \n",
       "2004-03-18  37.8  40.0  36.8   39.7  33785117  71.597213  37.590135   \n",
       "2004-03-19  39.8  40.7  39.5   40.2  40270357  73.327576  38.064656   \n",
       "2004-03-22  37.4  37.4  37.4   37.4   1703633  53.625224  37.943809   \n",
       "2004-03-23  34.8  34.8  34.8   34.8   5949478  42.268201  37.372208   \n",
       "2004-03-24  33.8  34.8  32.4   33.0  48693456  36.504223  36.577261   \n",
       "2004-03-25  33.0  33.7  31.5   32.5  23726028  35.073455  35.835941   \n",
       "2004-03-26  32.5  33.0  30.3   30.5  20230145  30.007107  34.865770   \n",
       "2004-03-29  32.5  32.6  32.0   32.6   9481951  39.834493  34.453812   \n",
       "2004-03-30  33.3  33.4  32.5   33.3  20752490  42.721445  34.244028   \n",
       "2004-03-31  33.4  33.7  32.7   33.3  20958403  42.721445  34.072386   \n",
       "2004-04-01  33.2  33.3  32.1   32.1   7323285  39.000801  33.713771   \n",
       "\n",
       "                     OBV  \n",
       "Date                      \n",
       "2004-01-02  1.884618e+09  \n",
       "2004-01-05  1.907082e+09  \n",
       "2004-01-06  1.932354e+09  \n",
       "2004-01-07  1.952474e+09  \n",
       "2004-01-08  1.942035e+09  \n",
       "2004-01-09  1.958725e+09  \n",
       "2004-01-12  1.950700e+09  \n",
       "2004-01-13  1.941074e+09  \n",
       "2004-01-14  1.957224e+09  \n",
       "2004-01-15  1.952677e+09  \n",
       "2004-01-16  1.973191e+09  \n",
       "2004-01-27  1.996882e+09  \n",
       "2004-01-28  1.985188e+09  \n",
       "2004-01-29  1.985188e+09  \n",
       "2004-01-30  1.998678e+09  \n",
       "2004-02-02  1.990170e+09  \n",
       "2004-02-03  1.979655e+09  \n",
       "2004-02-04  2.005895e+09  \n",
       "2004-02-05  1.995779e+09  \n",
       "2004-02-06  1.995779e+09  \n",
       "2004-02-09  2.012643e+09  \n",
       "2004-02-10  2.012643e+09  \n",
       "2004-02-11  2.028171e+09  \n",
       "2004-02-12  2.019839e+09  \n",
       "2004-02-13  2.010385e+09  \n",
       "2004-02-16  2.010385e+09  \n",
       "2004-02-17  2.025814e+09  \n",
       "2004-02-18  2.035559e+09  \n",
       "2004-02-19  2.047092e+09  \n",
       "2004-02-20  2.036455e+09  \n",
       "2004-02-23  2.036455e+09  \n",
       "2004-02-24  2.029902e+09  \n",
       "2004-02-25  2.036552e+09  \n",
       "2004-02-26  2.025831e+09  \n",
       "2004-02-27  2.059456e+09  \n",
       "2004-03-01  2.093686e+09  \n",
       "2004-03-02  2.081846e+09  \n",
       "2004-03-03  2.098830e+09  \n",
       "2004-03-04  2.088972e+09  \n",
       "2004-03-05  2.074628e+09  \n",
       "2004-03-08  2.082807e+09  \n",
       "2004-03-09  2.094943e+09  \n",
       "2004-03-10  2.094943e+09  \n",
       "2004-03-11  2.085815e+09  \n",
       "2004-03-12  2.078802e+09  \n",
       "2004-03-15  2.113617e+09  \n",
       "2004-03-16  2.095294e+09  \n",
       "2004-03-17  2.110558e+09  \n",
       "2004-03-18  2.144344e+09  \n",
       "2004-03-19  2.184614e+09  \n",
       "2004-03-22  2.182910e+09  \n",
       "2004-03-23  2.176961e+09  \n",
       "2004-03-24  2.128267e+09  \n",
       "2004-03-25  2.104541e+09  \n",
       "2004-03-26  2.084311e+09  \n",
       "2004-03-29  2.093793e+09  \n",
       "2004-03-30  2.114546e+09  \n",
       "2004-03-31  2.114546e+09  \n",
       "2004-04-01  2.107222e+09  "
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[test_start_idx:test_end_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Open  High   Low  Close    Volume        RSI        EMA  \\\n",
      "Date                                                                  \n",
      "2003-01-02  43.0  43.4  42.4   42.5  20354000  31.701033  44.672939   \n",
      "2003-01-03  44.0  45.0  43.6   44.8  35762662  43.234992  44.696041   \n",
      "2003-01-06  44.8  45.7  44.4   44.8  33415747  43.234992  44.714943   \n",
      "2003-01-07  45.7  46.9  45.4   45.4  41964939  45.994279  44.839499   \n",
      "2003-01-08  45.5  47.4  45.4   46.5  45846144  50.723426  45.141408   \n",
      "...          ...   ...   ...    ...       ...        ...        ...   \n",
      "2003-12-25  61.5  62.0  61.0   62.0   5296856  45.141543  61.717553   \n",
      "2003-12-26  62.0  62.5  61.5   62.0  10799103  45.141543  61.768907   \n",
      "2003-12-29  62.0  62.5  61.5   62.0  15688013  45.141543  61.810924   \n",
      "2003-12-30  62.5  63.5  62.0   63.0  68086562  49.911962  62.027120   \n",
      "2003-12-31  63.0  63.5  62.5   63.5  14588859  52.152375  62.294916   \n",
      "\n",
      "                     OBV  \n",
      "Date                      \n",
      "2003-01-02  4.563337e+08  \n",
      "2003-01-03  4.920964e+08  \n",
      "2003-01-06  4.920964e+08  \n",
      "2003-01-07  5.340613e+08  \n",
      "2003-01-08  5.799074e+08  \n",
      "...                  ...  \n",
      "2003-12-25  1.951637e+09  \n",
      "2003-12-26  1.951637e+09  \n",
      "2003-12-29  1.951637e+09  \n",
      "2003-12-30  2.019724e+09  \n",
      "2003-12-31  2.034312e+09  \n",
      "\n",
      "[249 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "train_start = '2001-01-01'\n",
    "train_start = datetime.strptime(train_start, '%Y-%m-%d')\n",
    "train_start_idx = df.index.get_loc(dateArray[dateArray>=train_start].iloc[0])\n",
    "train_end = '2002-12-31'\n",
    "train_end = datetime.strptime(train_end, '%Y-%m-%d')\n",
    "train_end_idx = df.index.get_loc(dateArray[dateArray<=train_end].iloc[-1])\n",
    "\n",
    "print(df[val_start_idx:val_end_idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4], [5, 6]]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2]\n",
    "b = [3,4]\n",
    "c = [5,6]\n",
    "d = [a,b,c]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################2603#########################################\n",
      "++++++++++++++++++++++2603 2003 to 2004++++++++++++++++++++++\n",
      "from  2003-01-01 00:00:00  to  2005-01-01 00:00:00\n",
      "train start : 1085\n",
      "train end : 1583\n",
      "val start : 1085\n",
      "val end : 1583\n",
      "trade start : 1085\n",
      "trade end : 1583\n",
      "======A2C Training========\n",
      "Training time (A2C):  7.999377588431041  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 1.201702219533103, 'total_profit': 0.7059674082672972, 'position': 1}\n",
      "A2C Sharpe Ratio:  0.018069346496318407\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  19.423597280184428  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 7.707834371964189, 'total_profit': 0.7837226726165903, 'position': 1}\n",
      "PPO Sharpe Ratio:  0.48823413874493776\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.873505568504333  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 1.1189846705852091, 'total_profit': 0.49164354463708765, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.1124391983839996\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  9.28334135611852  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 8.548620122592174, 'total_profit': 0.9625152869917754, 'position': 1}\n",
      "TRPO Sharpe Ratio:  0.6110662613702569\n",
      "\n",
      "==================Trading=================== 2004\n",
      "Used Model:  <sb3_contrib.trpo.trpo.TRPO object at 0x7fc4c2adf1d0>\n",
      "info {'total_reward': 8.332843756332503, 'total_profit': 0.9297880736206509, 'position': 1}\n",
      "action len :499\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2603 2005 to 2006++++++++++++++++++++++\n",
      "from  2005-01-01 00:00:00  to  2007-01-01 00:00:00\n",
      "train start : 1584\n",
      "train end : 2078\n",
      "val start : 1584\n",
      "val end : 2078\n",
      "trade start : 1584\n",
      "trade end : 2078\n",
      "======A2C Training========\n",
      "Training time (A2C):  7.659478934605916  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 31.706807483914666, 'total_profit': 1.0, 'position': 0}\n",
      "A2C Sharpe Ratio:  0\n",
      "\n",
      "======PPO Training========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/numpy/core/_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in true_divide\n",
      "  subok=False)\n",
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (PPO):  18.744206098715463  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 31.706807483914666, 'total_profit': 1.0, 'position': 0}\n",
      "PPO Sharpe Ratio:  0\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  6.030464045206705  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': -1.0003581652636642, 'total_profit': 0.44642059864726436, 'position': 0}\n",
      "DQN Sharpe Ratio:  -0.24636322586934273\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  8.430445563793182  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 31.706807483914666, 'total_profit': 1.0, 'position': 0}\n",
      "TRPO Sharpe Ratio:  0\n",
      "\n",
      "==================Trading=================== 2005\n",
      "Used Model:  <stable_baselines3.ppo.ppo.PPO object at 0x7fc4c1fbd690>\n",
      "info {'total_reward': 31.878385438537084, 'total_profit': 1.0, 'position': 0}\n",
      "action len :994\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2603 2007 to 2008++++++++++++++++++++++\n",
      "from  2007-01-01 00:00:00  to  2009-01-01 00:00:00\n",
      "train start : 2079\n",
      "train end : 2574\n",
      "val start : 2079\n",
      "val end : 2574\n",
      "trade start : 2079\n",
      "trade end : 2574\n",
      "======A2C Training========\n",
      "Training time (A2C):  8.300744899113973  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 8.029692262678678, 'total_profit': 0.7868430607558058, 'position': 0}\n",
      "A2C Sharpe Ratio:  0.16099238500801724\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  20.292794994513194  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 13.744799136277265, 'total_profit': 0.6844881926792012, 'position': 0}\n",
      "PPO Sharpe Ratio:  0.05675211146313933\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  5.442360989252726  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 2.903543938088189, 'total_profit': 0.5402766539677253, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.08921204791296958\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  8.23862729469935  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 28.31440215491061, 'total_profit': 1.0323742992175546, 'position': 0}\n",
      "TRPO Sharpe Ratio:  0.6478912797356378\n",
      "\n",
      "==================Trading=================== 2006\n",
      "Used Model:  <sb3_contrib.trpo.trpo.TRPO object at 0x7fc4c1ece190>\n",
      "info {'total_reward': 27.096353085331714, 'total_profit': 1.0364765246073473, 'position': 0}\n",
      "action len :1490\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2603 2009 to 2010++++++++++++++++++++++\n",
      "from  2009-01-01 00:00:00  to  2011-01-01 00:00:00\n",
      "train start : 2575\n",
      "train end : 3076\n",
      "val start : 2575\n",
      "val end : 3076\n",
      "trade start : 2575\n",
      "trade end : 3076\n",
      "======A2C Training========\n",
      "Training time (A2C):  8.471757439772288  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 1.0171879318968087, 'total_profit': 0.8264728226514294, 'position': 1}\n",
      "A2C Sharpe Ratio:  0.02393246009033401\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  23.136988576253255  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 3.4070595718459282, 'total_profit': 0.8116533695468764, 'position': 1}\n",
      "PPO Sharpe Ratio:  0.32967640112898733\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.380651422341665  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 2.649000972391326, 'total_profit': 0.6989668912602048, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.11615780868654103\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  8.297132746378582  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 4.0996106259025185, 'total_profit': 0.9302396926890382, 'position': 1}\n",
      "TRPO Sharpe Ratio:  0.3812147453493948\n",
      "\n",
      "==================Trading=================== 2007\n",
      "Used Model:  <sb3_contrib.trpo.trpo.TRPO object at 0x7fc4c1fc5990>\n",
      "info {'total_reward': 4.297387720011701, 'total_profit': 0.9522539013875182, 'position': 1}\n",
      "action len :1992\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2603 2011 to 2012++++++++++++++++++++++\n",
      "from  2011-01-01 00:00:00  to  2013-01-01 00:00:00\n",
      "train start : 3077\n",
      "train end : 3573\n",
      "val start : 3077\n",
      "val end : 3573\n",
      "trade start : 3077\n",
      "trade end : 3573\n",
      "======A2C Training========\n",
      "Training time (A2C):  7.92294739484787  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 45.50438516729915, 'total_profit': 1.0, 'position': 0}\n",
      "A2C Sharpe Ratio:  0\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  23.006950827439628  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 16.59604815520517, 'total_profit': 0.7473114431303809, 'position': 0}\n",
      "PPO Sharpe Ratio:  0.057340878731025925\n",
      "\n",
      "======DQN Training========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/ipykernel_launcher.py:167: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (DQN):  5.6801520427068075  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 5.832090623868226, 'total_profit': 0.6430400103616563, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.20947487060373501\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  9.088321959972381  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 45.50438516729915, 'total_profit': 1.0, 'position': 0}\n",
      "TRPO Sharpe Ratio:  0\n",
      "\n",
      "==================Trading=================== 2008\n",
      "Used Model:  <stable_baselines3.dqn.dqn.DQN object at 0x7fc4c2b38950>\n",
      "info {'total_reward': 2.00586773457895, 'total_profit': 0.6240664898596094, 'position': 1}\n",
      "action len :2489\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2603 2013 to 2014++++++++++++++++++++++\n",
      "from  2013-01-01 00:00:00  to  2015-01-01 00:00:00\n",
      "train start : 3574\n",
      "train end : 4067\n",
      "val start : 3574\n",
      "val end : 4067\n",
      "trade start : 3574\n",
      "trade end : 4067\n",
      "======A2C Training========\n",
      "Training time (A2C):  8.367557032903035  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 0.5384675654898032, 'total_profit': 0.6695649799402205, 'position': 0}\n",
      "A2C Sharpe Ratio:  -0.04599508460965334\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  21.116599694887796  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 2.746004292276166, 'total_profit': 0.8505845025213051, 'position': 0}\n",
      "PPO Sharpe Ratio:  0.2578329493292016\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.401594905058543  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': -0.8714556798653685, 'total_profit': 0.633418874686904, 'position': 1}\n",
      "DQN Sharpe Ratio:  -0.2998249361375473\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  7.915552604198456  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 0.8551105997066734, 'total_profit': 0.7373742415184753, 'position': 1}\n",
      "TRPO Sharpe Ratio:  0.01596226598002643\n",
      "\n",
      "==================Trading=================== 2009\n",
      "Used Model:  <stable_baselines3.ppo.ppo.PPO object at 0x7fc4c1fc57d0>\n",
      "info {'total_reward': 2.883296555385547, 'total_profit': 0.8672642803770475, 'position': 0}\n",
      "action len :2983\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2603 2015 to 2016++++++++++++++++++++++\n",
      "from  2015-01-01 00:00:00  to  2017-01-01 00:00:00\n",
      "train start : 4068\n",
      "train end : 4555\n",
      "val start : 4068\n",
      "val end : 4555\n",
      "trade start : 4068\n",
      "trade end : 4555\n",
      "======A2C Training========\n",
      "Training time (A2C):  7.020901687939962  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 30.55784988730279, 'total_profit': 1.0, 'position': 0}\n",
      "A2C Sharpe Ratio:  0\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  18.254883273442587  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 30.55784988730279, 'total_profit': 1.0, 'position': 0}\n",
      "PPO Sharpe Ratio:  0\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.433122030893961  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 0.4196007156979336, 'total_profit': 0.6664123317730506, 'position': 0}\n",
      "DQN Sharpe Ratio:  -0.20080814057344323\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  7.736060321331024  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 30.55784988730279, 'total_profit': 1.0, 'position': 0}\n",
      "TRPO Sharpe Ratio:  0\n",
      "\n",
      "==================Trading=================== 2010\n",
      "Used Model:  <stable_baselines3.ppo.ppo.PPO object at 0x7fc4c1f4ced0>\n",
      "info {'total_reward': 30.713210743801664, 'total_profit': 1.0, 'position': 0}\n",
      "action len :3471\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2603 2017 to 2018++++++++++++++++++++++\n",
      "from  2017-01-01 00:00:00  to  2019-01-01 00:00:00\n",
      "train start : 4556\n",
      "train end : 5048\n",
      "val start : 4556\n",
      "val end : 5048\n",
      "trade start : 4556\n",
      "trade end : 5048\n",
      "======A2C Training========\n",
      "Training time (A2C):  7.005595231056214  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 4.181672790390812, 'total_profit': 0.7935940408753358, 'position': 1}\n",
      "A2C Sharpe Ratio:  0.2301216939292636\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  18.221114401022593  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 4.146611681485356, 'total_profit': 0.7511091359289669, 'position': 0}\n",
      "PPO Sharpe Ratio:  0.26473217339560035\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.41617218653361  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 3.812951399319389, 'total_profit': 0.6607195832621139, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.23612062894680233\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  7.81567808787028  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 4.232430088751877, 'total_profit': 0.9658616807924031, 'position': 0}\n",
      "TRPO Sharpe Ratio:  0.5057788715680702\n",
      "\n",
      "==================Trading=================== 2011\n",
      "Used Model:  <sb3_contrib.trpo.trpo.TRPO object at 0x7fc4c2adfd90>\n",
      "info {'total_reward': 4.214963648713985, 'total_profit': 0.9652657151316918, 'position': 0}\n",
      "action len :3964\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2603 2019 to 2020++++++++++++++++++++++\n",
      "from  2019-01-01 00:00:00  to  2021-01-01 00:00:00\n",
      "train start : 5049\n",
      "train end : 5535\n",
      "val start : 5049\n",
      "val end : 5535\n",
      "trade start : 5049\n",
      "trade end : 5535\n",
      "======A2C Training========\n",
      "Training time (A2C):  6.976966734727224  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 3.7430397776843827, 'total_profit': 1.0286664958903733, 'position': 1}\n",
      "A2C Sharpe Ratio:  0.15005994194071492\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  18.025458697477976  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 4.430964713986317, 'total_profit': 0.9629683370836221, 'position': 1}\n",
      "PPO Sharpe Ratio:  0.3058117861148621\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.3117020924886065  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 0.929953779456996, 'total_profit': 0.757320936350595, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.28194649971138114\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  7.796074748039246  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 5.272388928838859, 'total_profit': 1.1309871588948233, 'position': 1}\n",
      "TRPO Sharpe Ratio:  0.3919394943232676\n",
      "\n",
      "==================Trading=================== 2012\n",
      "Used Model:  <sb3_contrib.trpo.trpo.TRPO object at 0x7fc4c2ab0550>\n",
      "info {'total_reward': 5.580731887556768, 'total_profit': 1.2018507562413605, 'position': 1}\n",
      "action len :4451\n",
      "============Trading Done============\n",
      "2603 final action len :4451\n",
      "0.009022024182506014\n",
      "#########################################2002#########################################\n",
      "++++++++++++++++++++++2002 2003 to 2004++++++++++++++++++++++\n",
      "from  2003-01-01 00:00:00  to  2005-01-01 00:00:00\n",
      "train start : 1085\n",
      "train end : 1583\n",
      "val start : 1085\n",
      "val end : 1583\n",
      "trade start : 1085\n",
      "trade end : 1583\n",
      "======A2C Training========\n",
      "Training time (A2C):  4.704789650440216  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 5.560948369088091, 'total_profit': 0.8433495025469829, 'position': 1}\n",
      "A2C Sharpe Ratio:  0.291246445680139\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  12.671762816111247  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 18.320861449451325, 'total_profit': 1.685916650369011, 'position': 1}\n",
      "PPO Sharpe Ratio:  0.6662569704571453\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  3.528487726052602  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 9.512890122679314, 'total_profit': 0.918273252569237, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.21698489157558887\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  5.095928370952606  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 31.205659743964198, 'total_profit': 1.7671329798600073, 'position': 1}\n",
      "TRPO Sharpe Ratio:  0.8118764880111461\n",
      "\n",
      "==================Trading=================== 2004\n",
      "Used Model:  <sb3_contrib.trpo.trpo.TRPO object at 0x7fc4c2ab6cd0>\n",
      "info {'total_reward': 31.262162271770062, 'total_profit': 1.736104725196914, 'position': 1}\n",
      "action len :499\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2002 2005 to 2006++++++++++++++++++++++\n",
      "from  2005-01-01 00:00:00  to  2007-01-01 00:00:00\n",
      "train start : 1584\n",
      "train end : 2078\n",
      "val start : 1584\n",
      "val end : 2078\n",
      "trade start : 1584\n",
      "trade end : 2078\n",
      "======A2C Training========\n",
      "Training time (A2C):  4.688470200697581  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 58.61983446519527, 'total_profit': 1.0, 'position': 0}\n",
      "A2C Sharpe Ratio:  0\n",
      "\n",
      "======PPO Training========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (PPO):  12.448268349965414  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 14.328179626751925, 'total_profit': 0.5946242253328619, 'position': 0}\n",
      "PPO Sharpe Ratio:  0.24084523633288674\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  3.6228116591771444  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 7.335431964411045, 'total_profit': 0.8521042541925758, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.15526044991396437\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  4.997365077336629  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 48.85165508720181, 'total_profit': 1.3947239485933622, 'position': 1}\n",
      "TRPO Sharpe Ratio:  8.7061909758657\n",
      "\n",
      "==================Trading=================== 2005\n",
      "Used Model:  <sb3_contrib.trpo.trpo.TRPO object at 0x7fc4b81b3610>\n",
      "info {'total_reward': 48.86355460240675, 'total_profit': 1.392037737314583, 'position': 1}\n",
      "action len :994\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2002 2007 to 2008++++++++++++++++++++++\n",
      "from  2007-01-01 00:00:00  to  2009-01-01 00:00:00\n",
      "train start : 2079\n",
      "train end : 2574\n",
      "val start : 2079\n",
      "val end : 2574\n",
      "trade start : 2079\n",
      "trade end : 2574\n",
      "======A2C Training========\n",
      "Training time (A2C):  4.8007989207903545  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 33.859383549852446, 'total_profit': 1.0177775676342646, 'position': 0}\n",
      "A2C Sharpe Ratio:  0.21543318413204038\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  15.26132953564326  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 29.120035427413796, 'total_profit': 0.5761224601637168, 'position': 1}\n",
      "PPO Sharpe Ratio:  0.2719613054341326\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.716280416647593  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 16.583549848874952, 'total_profit': 0.831139563976068, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.19152379321695742\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  7.65012221733729  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 68.92424980327803, 'total_profit': 1.028823293963544, 'position': 0}\n",
      "TRPO Sharpe Ratio:  0.704445813089437\n",
      "\n",
      "==================Trading=================== 2006\n",
      "Used Model:  <sb3_contrib.trpo.trpo.TRPO object at 0x7fc4b816d590>\n",
      "info {'total_reward': 70.33964355340274, 'total_profit': 1.0245728467674118, 'position': 0}\n",
      "action len :1490\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2002 2009 to 2010++++++++++++++++++++++\n",
      "from  2009-01-01 00:00:00  to  2011-01-01 00:00:00\n",
      "train start : 2575\n",
      "train end : 3076\n",
      "val start : 2575\n",
      "val end : 3076\n",
      "trade start : 2575\n",
      "trade end : 3076\n",
      "======A2C Training========\n",
      "Training time (A2C):  6.990821886062622  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': -53.85669636905294, 'total_profit': 0.9342058963723837, 'position': 0}\n",
      "A2C Sharpe Ratio:  -0.17917952064881093\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  16.7928645213445  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': -0.9693055754257541, 'total_profit': 0.920755996864392, 'position': 1}\n",
      "PPO Sharpe Ratio:  0.3481098758275018\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.688982101281484  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': -2.114950747244228, 'total_profit': 0.4526778073171213, 'position': 0}\n",
      "DQN Sharpe Ratio:  -0.06894616393865499\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  7.6091832955678305  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 24.53653966228304, 'total_profit': 1.1763617984187067, 'position': 0}\n",
      "TRPO Sharpe Ratio:  0.3189771229464761\n",
      "\n",
      "==================Trading=================== 2007\n",
      "Used Model:  <stable_baselines3.ppo.ppo.PPO object at 0x7fc4b81b3d90>\n",
      "info {'total_reward': 0.7903240127413764, 'total_profit': 0.7384164730593099, 'position': 1}\n",
      "action len :1992\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2002 2011 to 2012++++++++++++++++++++++\n",
      "from  2011-01-01 00:00:00  to  2013-01-01 00:00:00\n",
      "train start : 3077\n",
      "train end : 3573\n",
      "val start : 3077\n",
      "val end : 3573\n",
      "trade start : 3077\n",
      "trade end : 3573\n",
      "======A2C Training========\n",
      "Training time (A2C):  6.984768994649252  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 36.283829215509414, 'total_profit': 1.0, 'position': 0}\n",
      "A2C Sharpe Ratio:  0\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  16.90107121070226  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 19.07507862674366, 'total_profit': 0.6647498307546442, 'position': 0}\n",
      "PPO Sharpe Ratio:  0.12844331792927297\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.6749623894691466  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': -2.2919122778859182, 'total_profit': 0.5511069666457249, 'position': 1}\n",
      "DQN Sharpe Ratio:  -0.39760520514543224\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  7.597178649902344  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 36.283829215509414, 'total_profit': 1.0, 'position': 0}\n",
      "TRPO Sharpe Ratio:  0\n",
      "\n",
      "==================Trading=================== 2008\n",
      "Used Model:  <stable_baselines3.ppo.ppo.PPO object at 0x7fc4b816d690>\n",
      "info {'total_reward': 18.45556600648426, 'total_profit': 0.6677350772886875, 'position': 0}\n",
      "action len :2489\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2002 2013 to 2014++++++++++++++++++++++\n",
      "from  2013-01-01 00:00:00  to  2015-01-01 00:00:00\n",
      "train start : 3574\n",
      "train end : 4067\n",
      "val start : 3574\n",
      "val end : 4067\n",
      "trade start : 3574\n",
      "trade end : 4067\n",
      "======A2C Training========\n",
      "Training time (A2C):  6.970529341697693  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 14.59503500563214, 'total_profit': 0.8540255859724087, 'position': 0}\n",
      "A2C Sharpe Ratio:  0.2853427675442732\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  16.72620765765508  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 13.52915900398826, 'total_profit': 0.7904572465237637, 'position': 1}\n",
      "PPO Sharpe Ratio:  -0.22013857671924983\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.704470495382945  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 0.42196716696504744, 'total_profit': 0.6744585887152139, 'position': 1}\n",
      "DQN Sharpe Ratio:  -0.1758592991913044\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  7.595064123471578  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 27.225236961018837, 'total_profit': 0.9928761387711864, 'position': 0}\n",
      "TRPO Sharpe Ratio:  0\n",
      "\n",
      "==================Trading=================== 2009\n",
      "Used Model:  <stable_baselines3.a2c.a2c.A2C object at 0x7fc4c2ab6410>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/ipykernel_launcher.py:166: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info {'total_reward': 3.345350181254093, 'total_profit': 0.8259450305292915, 'position': 0}\n",
      "action len :2983\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2002 2015 to 2016++++++++++++++++++++++\n",
      "from  2015-01-01 00:00:00  to  2017-01-01 00:00:00\n",
      "train start : 4068\n",
      "train end : 4555\n",
      "val start : 4068\n",
      "val end : 4555\n",
      "trade start : 4068\n",
      "trade end : 4555\n",
      "======A2C Training========\n",
      "Training time (A2C):  6.974093270301819  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 54.74095699888018, 'total_profit': 1.0, 'position': 0}\n",
      "A2C Sharpe Ratio:  0\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  16.837872103850046  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 31.087081943853043, 'total_profit': 0.6144524582400184, 'position': 0}\n",
      "PPO Sharpe Ratio:  -0.3634493828454215\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.685294564565023  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 4.980623995798617, 'total_profit': 0.5913285930503996, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.051556168226627556\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  7.6341618975003565  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 27.840461708705252, 'total_profit': 1.2043561309401218, 'position': 0}\n",
      "TRPO Sharpe Ratio:  0.43336969220087224\n",
      "\n",
      "==================Trading=================== 2010\n",
      "Used Model:  <sb3_contrib.trpo.trpo.TRPO object at 0x7fc48a472250>\n",
      "info {'total_reward': 28.008513553123727, 'total_profit': 1.2202166703453223, 'position': 0}\n",
      "action len :3471\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2002 2017 to 2018++++++++++++++++++++++\n",
      "from  2017-01-01 00:00:00  to  2019-01-01 00:00:00\n",
      "train start : 4556\n",
      "train end : 5048\n",
      "val start : 4556\n",
      "val end : 5048\n",
      "trade start : 4556\n",
      "trade end : 5048\n",
      "======A2C Training========\n",
      "Training time (A2C):  7.037500933806101  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': -5.665435824566194, 'total_profit': 0.2597107261264853, 'position': 0}\n",
      "A2C Sharpe Ratio:  -0.12299192949719674\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  16.845334315299986  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 2.5529912172880356, 'total_profit': 0.6599700302648863, 'position': 0}\n",
      "PPO Sharpe Ratio:  0.098868893516638\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.7012373884518945  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 4.233501179155245, 'total_profit': 0.6114147707152782, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.04848043877383515\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  7.67146155834198  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 16.318786191034487, 'total_profit': 0.9361333775743766, 'position': 0}\n",
      "TRPO Sharpe Ratio:  -0.12700010004185902\n",
      "\n",
      "==================Trading=================== 2011\n",
      "Used Model:  <stable_baselines3.ppo.ppo.PPO object at 0x7fc4b81b3a90>\n",
      "info {'total_reward': 4.127254058737722, 'total_profit': 0.679773224059016, 'position': 0}\n",
      "action len :3964\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2002 2019 to 2020++++++++++++++++++++++\n",
      "from  2019-01-01 00:00:00  to  2021-01-01 00:00:00\n",
      "train start : 5049\n",
      "train end : 5535\n",
      "val start : 5049\n",
      "val end : 5535\n",
      "trade start : 5049\n",
      "trade end : 5535\n",
      "======A2C Training========\n",
      "Training time (A2C):  6.996908990542094  minutes\n",
      "======A2C Validation=======\n",
      "info {'total_reward': 18.236600048422403, 'total_profit': 1.008211763249836, 'position': 1}\n",
      "A2C Sharpe Ratio:  0.007841767381961313\n",
      "\n",
      "======PPO Training========\n",
      "Training time (PPO):  16.76766683657964  minutes\n",
      "======PPO Validation========\n",
      "info {'total_reward': 8.805429315755084, 'total_profit': 0.5565729971886868, 'position': 1}\n",
      "PPO Sharpe Ratio:  0.11246625552367256\n",
      "\n",
      "======DQN Training========\n",
      "Training time (DQN):  4.00283960501353  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': -1.275653698619871, 'total_profit': 0.543644136780707, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.0706569311728861\n",
      "\n",
      "======TRPO Training========\n",
      "Training time (TRPO):  5.10982281366984  minutes\n",
      "======TRPO Validation========\n",
      "info {'total_reward': 23.175657920364543, 'total_profit': 1.0677386313285284, 'position': 1}\n",
      "TRPO Sharpe Ratio:  1.1987380923505468\n",
      "\n",
      "==================Trading=================== 2012\n",
      "Used Model:  <sb3_contrib.trpo.trpo.TRPO object at 0x7fc4b81b3610>\n",
      "info {'total_reward': 23.53726070262153, 'total_profit': 1.0756070383191503, 'position': 1}\n",
      "action len :4451\n",
      "============Trading Done============\n",
      "2002 final action len :4451\n",
      "0.0032154340836012176\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "stock_list = ['2330']  \n",
    "    \n",
    "\n",
    "for stock_id in stock_list:\n",
    "    print('#########################################'+stock_id+'#########################################')\n",
    "    start_date='1998-10-18'\n",
    "    end_date='2021-12-31'\n",
    "    df = api.taiwan_stock_daily(\n",
    "                stock_id = stock_id,\n",
    "                start_date = start_date,\n",
    "                end_date = end_date\n",
    "    )\n",
    "\n",
    "    df = df.iloc[:][['date','open', 'max', 'min', 'close','Trading_Volume']]\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    df.rename(columns = {'date':'Date', 'open':'Open','max':'High','min':'Low', 'close':'Close','Trading_Volume':'Volume'}, inplace = True)\n",
    "    dateArray = df['Date']\n",
    "    df.set_index('Date', inplace=True)\n",
    "\n",
    "    max_value = 0.8\n",
    "    min_value = 0.2\n",
    "\n",
    "    Max_Volume = df['Volume'].max()\n",
    "    Min_Volume = df['Volume'].min()\n",
    "    Max_Price = df['High'].max()\n",
    "    Min_Price = df['Low'].min()\n",
    "\n",
    "    df['RSI'] = talib.RSI(df.iloc[:]['Close'], timeperiod=14)/100\n",
    "    df['EMA'] = talib.EMA(df.iloc[:]['Close'], timeperiod=10)\n",
    "    df['OBV'] = talib.OBV(df.iloc[:]['Close'], df.iloc[:]['Volume'])\n",
    "    Max_OBV = df['OBV'].max()\n",
    "    Min_OBV = df['OBV'].min()\n",
    "\n",
    "    df['High'] = min_value + (max_value - min_value) * (df['High'] - Min_Price) / (Max_Price - Min_Price)\n",
    "    df['Low'] = min_value + (max_value - min_value) * (df['Low'] - Min_Price) / (Max_Price - Min_Price)\n",
    "    df['Open'] = min_value + (max_value - min_value) * (df['Open'] - Min_Price) / (Max_Price - Min_Price)\n",
    "    df['Close'] = min_value + (max_value - min_value) * (df['Close'] - Min_Price) / (Max_Price - Min_Price)\n",
    "    df['Volume'] = min_value + (max_value - min_value) * (df['Volume'] - Min_Volume) / (Max_Volume - Min_Volume)\n",
    "\n",
    "    df['EMA'] = min_value + (max_value - min_value) * (df['EMA'] - Min_Price) / (Max_Price - Min_Price)\n",
    "    df['OBV'] = min_value + (max_value - min_value) * (df['OBV'] - Min_OBV) / (Max_OBV - Min_OBV)\n",
    "\n",
    "\n",
    "\n",
    "    train_start = '2001-01-01'\n",
    "    train_start = datetime.strptime(train_start, '%Y-%m-%d')\n",
    "    train_start_idx = df.index.get_loc(dateArray[dateArray>=train_start].iloc[0])\n",
    "    train_end = '2005-01-01'\n",
    "    train_end = datetime.strptime(train_end, '%Y-%m-%d')\n",
    "    train_end_idx = df.index.get_loc(dateArray[dateArray<train_end].iloc[-1])\n",
    "    val_start = '2003-01-01'\n",
    "    val_start = datetime.strptime(val_start, '%Y-%m-%d')\n",
    "    val_start_idx = df.index.get_loc(dateArray[dateArray>=val_start].iloc[0])\n",
    "    val_end = '2005-1-1'\n",
    "    val_end = datetime.strptime(val_end, '%Y-%m-%d')\n",
    "    val_end_idx = df.index.get_loc(dateArray[dateArray<val_end].iloc[-1])\n",
    "    test_start = '2003-01-01'\n",
    "    test_start = datetime.strptime(test_start, '%Y-%m-%d')\n",
    "    test_start_idx = df.index.get_loc(dateArray[dateArray>=test_start].iloc[0])\n",
    "    test_end = '2005-1-1'\n",
    "    test_end = datetime.strptime(test_end, '%Y-%m-%d')\n",
    "    test_end_idx = df.index.get_loc(dateArray[dateArray<test_end].iloc[-1])\n",
    "\n",
    "    action_list = []\n",
    "    \n",
    "    ppo_sharpe_list = []\n",
    "    #rppo_sharpe_list = []\n",
    "    a2c_sharpe_list = []\n",
    "    dqn_sharpe_list = []\n",
    "    trpo_sharpe_list = []\n",
    "\n",
    "    model_use = []\n",
    "\n",
    "    for i in range(9):\n",
    "        print('++++++++++++++++++++++'+stock_id+' '+str(i*2+2003)+' to '+str(i*2+2004)+'++++++++++++++++++++++')\n",
    "        ############## Environment Setup starts ##############\n",
    "        ## training env\n",
    "        #env_maker = lambda: gym.make('stocks-v0', df=df, frame_bound=(train_start_idx,train_end_idx+1), window_size=20)\n",
    "        #env_train = DummyVecEnv([env_maker])\n",
    "        \n",
    "        #cus_env = MyCustomEnv(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=20)\n",
    "        #env_maker = lambda: cus_env\n",
    "        #env_train = DummyVecEnv([env_maker])\n",
    "        \n",
    "        env_train = DummyVecEnv([lambda: StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=25)]*4)\n",
    "        print('from ',test_start,' to ',test_end)\n",
    "        print('train start :',train_start_idx)\n",
    "        print('train end :',train_end_idx)\n",
    "\n",
    "\n",
    "        ## validation env\n",
    "        validation = df[val_start_idx:val_end_idx+1]\n",
    "        print('val start :',val_start_idx)\n",
    "        print('val end :',val_end_idx)\n",
    "        #env_maker = lambda: gym.make('stocks-v0', df=df, frame_bound=(val_start_idx,val_end_idx+1), window_size=20)\n",
    "        #env_val = gym.make('stocks-v0', df=df, frame_bound=(val_start_idx,val_end_idx+1), window_size=20)\n",
    "        #env_val = MyCustomEnv(df=df, frame_bound=(val_start_idx,val_end_idx+1), window_size=20)\n",
    "        #env_val2 = MyCustomEnv(df=df, frame_bound=(val_start_idx,val_end_idx+2), window_size=20)\n",
    "        #obs_val = env_val.reset()\n",
    "        #print(obs_val[np.newaxis, ...].shape)\n",
    "        \n",
    "        env_val = StocksEnv2(df=df, frame_bound=(val_start_idx,val_end_idx), window_size=25)\n",
    "        obs_val = env_val.reset()\n",
    "        \n",
    "        ############## Environment Setup ends ##############\n",
    "        print('trade start :',test_start_idx)\n",
    "        print('trade end :',test_end_idx)\n",
    "\n",
    "        ############## Training and Validation starts ##############\n",
    "        #print(\"======Model training from: \", 20090000, \"to \",\n",
    "        #        unique_trade_date[i - rebalance_window - validation_window])\n",
    "        # print(\"training: \",len(data_split(df, start=20090000, end=test.datadate.unique()[i-rebalance_window]) ))\n",
    "        # print(\"==============Model Training===========\")\n",
    "        print(\"======A2C Training========\")\n",
    "        model_a2c = train_A2C(env_train, model_name=\"A2C_\"+stock_id+'_'+str(i), timesteps=1000000)\n",
    "        #model_a2c = A2C('MlpPolicy', env_train, verbose=0)\n",
    "        #model_a2c.learn(total_timesteps=40000)\n",
    "        print(\"======A2C Validation=======\")\n",
    "        #env_val = MyCustomEnv(df=df, frame_bound=(val_start_idx,val_end_idx+1), window_size=20)\n",
    "        #obs_val = env_val.reset()\n",
    "        sharpe_a2c = DRL_validation(df=df,model=model_a2c, test_env=env_val, test_obs=obs_val)\n",
    "        #sharpe_a2c = get_validation_sharpe(i)\n",
    "        print(\"A2C Sharpe Ratio: \", sharpe_a2c)\n",
    "        print()\n",
    "\n",
    "        print(\"======PPO Training========\")\n",
    "        model_ppo = train_PPO(env_train, model_name=\"PPO_\"+stock_id+'_'+str(i), timesteps=1000000)\n",
    "        #model_ppo = PPO('MlpPolicy', env_train, verbose=0)\n",
    "        #model_ppo.learn(total_timesteps=400000)\n",
    "        print(\"======PPO Validation========\")\n",
    "        env_val = StocksEnv2(df=df, frame_bound=(val_start_idx,val_end_idx), window_size=25)\n",
    "        obs_val = env_val.reset()\n",
    "        sharpe_ppo = DRL_validation(df=df,model=model_ppo,test_env=env_val, test_obs=obs_val)\n",
    "        #sharpe_ppo = get_validation_sharpe(i)\n",
    "        print(\"PPO Sharpe Ratio: \", sharpe_ppo)\n",
    "        print()\n",
    "        \n",
    "        print(\"======DQN Training========\")\n",
    "        model_dqn = train_DQN(env_train, model_name=\"DQN_\"+stock_id+'_'+str(i), timesteps=1000000)\n",
    "        #model_dqn = DQN('MlpPolicy', env_train, verbose=0)\n",
    "        #model_dqn.learn(total_timesteps=400000)\n",
    "        print(\"======DQN Validation========\")\n",
    "        env_val = StocksEnv2(df=df, frame_bound=(val_start_idx,val_end_idx), window_size=25)\n",
    "        obs_val = env_val.reset()\n",
    "        sharpe_dqn = DRL_validation(df=df,model=model_dqn,test_env=env_val, test_obs=obs_val)\n",
    "        #sharpe_ppo = get_validation_sharpe(i)\n",
    "        print(\"DQN Sharpe Ratio: \", sharpe_dqn)\n",
    "        print()\n",
    "\n",
    "        print(\"======TRPO Training========\")\n",
    "        model_trpo = train_TRPO(env_train, model_name=\"TRPO_\"+stock_id+'_'+str(i), timesteps=1000000)\n",
    "        #model_ddpg = train_TD3(env_train, model_name=\"DDPG_10k_dow_{}\".format(i), timesteps=20000)\n",
    "        print(\"======TRPO Validation========\")\n",
    "        env_val = StocksEnv2(df=df, frame_bound=(val_start_idx,val_end_idx), window_size=25)\n",
    "        obs_val = env_val.reset()\n",
    "        sharpe_trpo = DRL_validation(df=df,model=model_trpo,test_env=env_val, test_obs=obs_val)\n",
    "        #sharpe_ddpg = get_validation_sharpe(i)\n",
    "        print(\"TRPO Sharpe Ratio: \", sharpe_trpo)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        ppo_sharpe_list.append(sharpe_ppo)\n",
    "        a2c_sharpe_list.append(sharpe_a2c)\n",
    "        dqn_sharpe_list.append(sharpe_dqn)\n",
    "        #rppo_sharpe_list.append(sharpe_rppo)\n",
    "        trpo_sharpe_list.append(sharpe_trpo)\n",
    "        \n",
    "        \n",
    "        sharpe_list = [sharpe_ppo,sharpe_a2c,sharpe_dqn,sharpe_trpo]\n",
    "        \n",
    "        # Model Selection based on sharpe ratio\n",
    "        #if (sharpe_ppo >= sharpe_a2c) & (sharpe_ppo >= sharpe_ddpg):\n",
    "        if max(sharpe_list) == sharpe_ppo:\n",
    "            model_ensemble = model_ppo\n",
    "            model_use.append('PPO')\n",
    "        #elif (sharpe_a2c > sharpe_ppo) & (sharpe_a2c > sharpe_ddpg):\n",
    "        elif max(sharpe_list) == sharpe_a2c:\n",
    "            model_ensemble = model_a2c\n",
    "            model_use.append('A2C')\n",
    "        \n",
    "        elif max(sharpe_list) == sharpe_trpo:\n",
    "            model_ensemble = model_trpo\n",
    "            model_use.append('TRPO')\n",
    "        else:\n",
    "            model_ensemble = model_dqn\n",
    "            model_use.append('DQN')\n",
    "        \n",
    "        ############## Training and Validation ends ##############\n",
    "        ############## Trading starts ##############\n",
    "        print(\"==================Trading===================\",str(i+2004))\n",
    "        print(\"Used Model: \", model_ensemble)\n",
    "        action_list = DRL_prediction(df=df, model=model_ensemble,start_date = test_start_idx,end_date = test_end_idx,action_list = action_list)\n",
    "        print('action len :'+str(len(action_list)))\n",
    "        \n",
    "        \n",
    "        print(\"============Trading Done============\")\n",
    "        ############## Trading ends ##############\n",
    "        if i == 16:break\n",
    "        else:\n",
    "            train_start = train_start + relativedelta(years=2)\n",
    "            train_start_idx = df.index.get_loc(dateArray[dateArray>=train_start].iloc[0])\n",
    "            train_end = train_end + relativedelta(years=2)\n",
    "            train_end_idx = df.index.get_loc(dateArray[dateArray<train_end].iloc[-1])\n",
    "            val_start = val_start + relativedelta(years=2)\n",
    "            val_start_idx = df.index.get_loc(dateArray[dateArray>=val_start].iloc[0])\n",
    "            val_end = val_end + relativedelta(years=2)\n",
    "            val_end_idx = df.index.get_loc(dateArray[dateArray<val_end].iloc[-1])\n",
    "            test_start = test_start + relativedelta(years=2)\n",
    "            test_start_idx = df.index.get_loc(dateArray[dateArray>=test_start].iloc[0])\n",
    "            test_end = test_end + relativedelta(years=2)\n",
    "            test_end_idx = df.index.get_loc(dateArray[dateArray<test_end].iloc[-1])\n",
    "            \n",
    "    print(str(stock_id)+' final action len :'+str(len(action_list)))\n",
    "    #total.append(action_list)\n",
    "    #action_output = np.array(action_list)\n",
    "    #np.savetxt('data_new/Trajectory/RL/' + stock_id + '_RL_expert.csv', action_list, delimiter=\",\")\n",
    "    '''==============================save sharpe ratio=========================================='''\n",
    "    total_sharpe = np.array([a2c_sharpe_list,ppo_sharpe_list,dqn_sharpe_list,trpo_sharpe_list])\n",
    "    np.savetxt('data_new/Trajectory/RL/' + stock_id + '_RL_sharpe.csv', total_sharpe, delimiter=\",\")                                                      \n",
    "    \n",
    "    '''==============================save trajectory=========================================='''\n",
    "    trading_info = []\n",
    "    buy_sell_tuple = []\n",
    "    hold = 0\n",
    "    temp = []\n",
    "    trading_dic = {}\n",
    "    return_list = []\n",
    "\n",
    "    TaiwanStockPriceDay = api.taiwan_stock_daily(\n",
    "        stock_id = '2330',\n",
    "        start_date = '2003-1-1',\n",
    "        end_date = '2020-12-31'\n",
    "        )\n",
    "    \n",
    "    for i in range(len(action_list)):\n",
    "        if action_list[i] == 1:\n",
    "            if hold == 0:\n",
    "                trading_info.append([i,'buy',TaiwanStockPriceDay['close'][i]])\n",
    "                temp.append([i,TaiwanStockPriceDay['close'][i]])\n",
    "                trading_dic[i] = ['buy', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "                hold = 1\n",
    "            else:\n",
    "                trading_info.append([i,'hold',TaiwanStockPriceDay['close'][i]])\n",
    "                trading_dic[i] = ['hold', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "        else:\n",
    "            if hold == 1:\n",
    "                trading_info.append([i,'sell',TaiwanStockPriceDay['close'][i]])\n",
    "                temp.append([i,TaiwanStockPriceDay['close'][i]])\n",
    "                temp.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                return_list.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                buy_sell_tuple.append(temp)\n",
    "                temp = []\n",
    "                trading_dic[i] = ['sell', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "\n",
    "                hold = 0\n",
    "            else:\n",
    "                trading_info.append([i,'hold',TaiwanStockPriceDay['close'][i]])\n",
    "                trading_dic[i] = ['hold', TaiwanStockPriceDay['close'][i]]\n",
    "            \n",
    "    if hold ==1:\n",
    "            trading_info[-1][1] = 'sell'\n",
    "            trading_dic[len(trading_dic)-1][0] = 'sell'\n",
    "            temp.append([i, TaiwanStockPriceDay['close'][i]])\n",
    "            temp.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "            return_list.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "            buy_sell_tuple.append(temp)\n",
    "            temp = []\n",
    "    #print(trading_info)\n",
    "    \n",
    "    with open(\"./data_new/Trajectory/RL/\" + stock_id + \"_\" + \"RL_trajectory_all_train2.csv\",  'w', encoding='utf8', newline='') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            for trade in trading_info:\n",
    "                writer.writerow(trade)\n",
    "    \n",
    "    median = statistics.median(return_list)\n",
    "    print(median)\n",
    "    \n",
    "    for trade in buy_sell_tuple:\n",
    "        #total_sum += trade[2]\n",
    "\n",
    "        \n",
    "        if trade[2] <median:\n",
    "            \n",
    "            trading_dic[trade[0][0]][0] = 'hold'\n",
    "            trading_dic[trade[1][0]][0] = 'hold'\n",
    "    #print(trading_dic)\n",
    "\n",
    "\n",
    "    with open(\"./data_new/Trajectory/RL/\" + stock_id + \"_\" + \"RL_trajectory_50_train2.csv\",  'w', encoding='utf8', newline='') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        for key in trading_dic.keys():\n",
    "            writer.writerow([key, trading_dic[key][0], trading_dic[key][1]])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sharpe = np.array([a2c_sharpe_list,ppo_sharpe_list,dqn_sharpe_list,trpo_sharpe_list])\n",
    "np.savetxt('data_new/Trajectory/RL/' + stock_id + '_RL_sharpe.csv', total_sharpe, delimiter=\",\")                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DQN',\n",
       " 'TRPO',\n",
       " 'TRPO',\n",
       " 'DQN',\n",
       " 'DQN',\n",
       " 'PPO',\n",
       " 'A2C',\n",
       " 'TRPO',\n",
       " 'PPO',\n",
       " 'DQN',\n",
       " 'TRPO',\n",
       " 'TRPO',\n",
       " 'A2C',\n",
       " 'DQN',\n",
       " 'TRPO',\n",
       " 'DQN',\n",
       " 'TRPO']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################2330#########################################\n",
      "++++++++++++++++++++++2330 2001 to 2005++++++++++++++++++++++\n",
      "from  2001-01-01 00:00:00  to  2005-01-01 00:00:00\n",
      "train start : 593\n",
      "train end : 1583\n",
      "val start : 593\n",
      "val end : 1583\n",
      "trade start : 593\n",
      "trade end : 1583\n",
      "======DQN Training========\n",
      "Training time (DQN):  8.687969915072124  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 12.833141235701268, 'total_profit': 0.683002429409066, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.31260977993551864\n",
      "\n",
      "==================Trading=================== 2004\n",
      "info {'total_reward': 6.4399136799327295, 'total_profit': 0.7252894791023186, 'position': 1}\n",
      "action len :991\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2330 2005 to 2009++++++++++++++++++++++\n",
      "from  2005-01-01 00:00:00  to  2009-01-01 00:00:00\n",
      "train start : 1584\n",
      "train end : 2574\n",
      "val start : 1584\n",
      "val end : 2574\n",
      "trade start : 1584\n",
      "trade end : 2574\n",
      "======DQN Training========\n",
      "Training time (DQN):  8.855524758497873  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 0.6844073606072311, 'total_profit': 0.3434722617995807, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.02619624745752296\n",
      "\n",
      "==================Trading=================== 2005\n",
      "info {'total_reward': 2.621095646639945, 'total_profit': 0.4093033730806499, 'position': 0}\n",
      "action len :1982\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2330 2009 to 2013++++++++++++++++++++++\n",
      "from  2009-01-01 00:00:00  to  2013-01-01 00:00:00\n",
      "train start : 2575\n",
      "train end : 3573\n",
      "val start : 2575\n",
      "val end : 3573\n",
      "trade start : 2575\n",
      "trade end : 3573\n",
      "======DQN Training========\n",
      "Training time (DQN):  8.15622000694275  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 0.1886576942917674, 'total_profit': 0.3934358990759413, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.04550167182851809\n",
      "\n",
      "==================Trading=================== 2006\n",
      "info {'total_reward': -0.12222306098443374, 'total_profit': 0.376260346811809, 'position': 1}\n",
      "action len :2981\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2330 2013 to 2017++++++++++++++++++++++\n",
      "from  2013-01-01 00:00:00  to  2017-01-01 00:00:00\n",
      "train start : 3574\n",
      "train end : 4555\n",
      "val start : 3574\n",
      "val end : 4555\n",
      "trade start : 3574\n",
      "trade end : 4555\n",
      "======DQN Training========\n",
      "Training time (DQN):  9.526224744319915  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': -1.1947638726753094, 'total_profit': 0.34925104974899135, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.2253864338850876\n",
      "\n",
      "==================Trading=================== 2007\n",
      "info {'total_reward': 1.4059542430807104, 'total_profit': 0.4010221542358753, 'position': 0}\n",
      "action len :3963\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2330 2017 to 2021++++++++++++++++++++++\n",
      "from  2017-01-01 00:00:00  to  2021-01-01 00:00:00\n",
      "train start : 4556\n",
      "train end : 5535\n",
      "val start : 4556\n",
      "val end : 5535\n",
      "trade start : 4556\n",
      "trade end : 5535\n",
      "======DQN Training========\n",
      "Training time (DQN):  10.686936589082082  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 5.893660174392244, 'total_profit': 0.8004165425190665, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.24537538694580605\n",
      "\n",
      "==================Trading=================== 2008\n",
      "info {'total_reward': 3.9387460043005253, 'total_profit': 0.8167683167966822, 'position': 1}\n",
      "action len :4943\n",
      "============Trading Done============\n",
      "2330 final action len :4943\n",
      "#########################################2603#########################################\n",
      "++++++++++++++++++++++2603 2001 to 2005++++++++++++++++++++++\n",
      "from  2001-01-01 00:00:00  to  2005-01-01 00:00:00\n",
      "train start : 593\n",
      "train end : 1583\n",
      "val start : 593\n",
      "val end : 1583\n",
      "trade start : 593\n",
      "trade end : 1583\n",
      "======DQN Training========\n",
      "Training time (DQN):  10.188916432857514  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 4.3015392234671594, 'total_profit': 0.4761331593666825, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.2199814900293433\n",
      "\n",
      "==================Trading=================== 2004\n",
      "info {'total_reward': 0.010178697544049672, 'total_profit': 0.3799554213831732, 'position': 1}\n",
      "action len :991\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2603 2005 to 2009++++++++++++++++++++++\n",
      "from  2005-01-01 00:00:00  to  2009-01-01 00:00:00\n",
      "train start : 1584\n",
      "train end : 2574\n",
      "val start : 1584\n",
      "val end : 2574\n",
      "trade start : 1584\n",
      "trade end : 2574\n",
      "======DQN Training========\n",
      "Training time (DQN):  9.30344979763031  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 5.1875354098709785, 'total_profit': 0.5220935806313212, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.26409440517910654\n",
      "\n",
      "==================Trading=================== 2005\n",
      "info {'total_reward': 0.9080919993710899, 'total_profit': 0.46321421571813975, 'position': 1}\n",
      "action len :1982\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2603 2009 to 2013++++++++++++++++++++++\n",
      "from  2009-01-01 00:00:00  to  2013-01-01 00:00:00\n",
      "train start : 2575\n",
      "train end : 3573\n",
      "val start : 2575\n",
      "val end : 3573\n",
      "trade start : 2575\n",
      "trade end : 3573\n",
      "======DQN Training========\n",
      "Training time (DQN):  8.111028591791788  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 0.08706233253894301, 'total_profit': 0.5052512687899277, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.1540843698394803\n",
      "\n",
      "==================Trading=================== 2006\n",
      "info {'total_reward': 0.2776284648352977, 'total_profit': 0.48238148385013496, 'position': 1}\n",
      "action len :2981\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2603 2013 to 2017++++++++++++++++++++++\n",
      "from  2013-01-01 00:00:00  to  2017-01-01 00:00:00\n",
      "train start : 3574\n",
      "train end : 4555\n",
      "val start : 3574\n",
      "val end : 4555\n",
      "trade start : 3574\n",
      "trade end : 4555\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.441339381535848  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 0.8833527988441053, 'total_profit': 0.42078534536870504, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.006517937336553905\n",
      "\n",
      "==================Trading=================== 2007\n",
      "info {'total_reward': 6.979987761843993, 'total_profit': 0.48022817721585453, 'position': 0}\n",
      "action len :3963\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2603 2017 to 2021++++++++++++++++++++++\n",
      "from  2017-01-01 00:00:00  to  2021-01-01 00:00:00\n",
      "train start : 4556\n",
      "train end : 5535\n",
      "val start : 4556\n",
      "val end : 5535\n",
      "trade start : 4556\n",
      "trade end : 5535\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.539802932739258  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 2.851435890487423, 'total_profit': 0.6042480379965038, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.2180039808099\n",
      "\n",
      "==================Trading=================== 2008\n",
      "info {'total_reward': 0.08792567480240476, 'total_profit': 0.5238884458090427, 'position': 1}\n",
      "action len :4943\n",
      "============Trading Done============\n",
      "2603 final action len :4943\n",
      "#########################################1301#########################################\n",
      "++++++++++++++++++++++1301 2001 to 2005++++++++++++++++++++++\n",
      "from  2001-01-01 00:00:00  to  2005-01-01 00:00:00\n",
      "train start : 593\n",
      "train end : 1583\n",
      "val start : 593\n",
      "val end : 1583\n",
      "trade start : 593\n",
      "trade end : 1583\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.569000720977783  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 11.486638070812335, 'total_profit': 0.8934164988744556, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.26875439814936775\n",
      "\n",
      "==================Trading=================== 2004\n",
      "info {'total_reward': 12.265670595984613, 'total_profit': 0.5135418046370428, 'position': 1}\n",
      "action len :991\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++1301 2005 to 2009++++++++++++++++++++++\n",
      "from  2005-01-01 00:00:00  to  2009-01-01 00:00:00\n",
      "train start : 1584\n",
      "train end : 2574\n",
      "val start : 1584\n",
      "val end : 2574\n",
      "trade start : 1584\n",
      "trade end : 2574\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.574355840682983  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 18.0824725446067, 'total_profit': 0.6203039601866688, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.2648149603003025\n",
      "\n",
      "==================Trading=================== 2005\n",
      "info {'total_reward': 37.85742763470911, 'total_profit': 0.6228641989930158, 'position': 0}\n",
      "action len :1982\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++1301 2009 to 2013++++++++++++++++++++++\n",
      "from  2009-01-01 00:00:00  to  2013-01-01 00:00:00\n",
      "train start : 2575\n",
      "train end : 3573\n",
      "val start : 2575\n",
      "val end : 3573\n",
      "trade start : 2575\n",
      "trade end : 3573\n",
      "======DQN Training========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (DQN):  7.377106793721517  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 7.295310994469129, 'total_profit': 0.4068340946681183, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.24928340717068884\n",
      "\n",
      "==================Trading=================== 2006\n",
      "info {'total_reward': 1.4879090906672778, 'total_profit': 0.570783960087642, 'position': 1}\n",
      "action len :2981\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++1301 2013 to 2017++++++++++++++++++++++\n",
      "from  2013-01-01 00:00:00  to  2017-01-01 00:00:00\n",
      "train start : 3574\n",
      "train end : 4555\n",
      "val start : 3574\n",
      "val end : 4555\n",
      "trade start : 3574\n",
      "trade end : 4555\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.546417733033498  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 2.3818433371717576, 'total_profit': 0.31482640215398655, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.11931021673086893\n",
      "\n",
      "==================Trading=================== 2007\n",
      "info {'total_reward': 3.3096243724897043, 'total_profit': 0.3427559572847891, 'position': 0}\n",
      "action len :3963\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++1301 2017 to 2021++++++++++++++++++++++\n",
      "from  2017-01-01 00:00:00  to  2021-01-01 00:00:00\n",
      "train start : 4556\n",
      "train end : 5535\n",
      "val start : 4556\n",
      "val end : 5535\n",
      "trade start : 4556\n",
      "trade end : 5535\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.521425282955169  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 2.637305681375716, 'total_profit': 0.44009492114108206, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.019133528991640492\n",
      "\n",
      "==================Trading=================== 2008\n",
      "info {'total_reward': 7.43333912926709, 'total_profit': 0.513654677562086, 'position': 1}\n",
      "action len :4943\n",
      "============Trading Done============\n",
      "1301 final action len :4943\n",
      "#########################################2002#########################################\n",
      "++++++++++++++++++++++2002 2001 to 2005++++++++++++++++++++++\n",
      "from  2001-01-01 00:00:00  to  2005-01-01 00:00:00\n",
      "train start : 593\n",
      "train end : 1583\n",
      "val start : 593\n",
      "val end : 1583\n",
      "trade start : 593\n",
      "trade end : 1583\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.486310676733653  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 3.170420658905843, 'total_profit': 0.7144078637737352, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.17405601151764513\n",
      "\n",
      "==================Trading=================== 2004\n",
      "info {'total_reward': 10.294313594258748, 'total_profit': 0.8325379427762294, 'position': 1}\n",
      "action len :991\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2002 2005 to 2009++++++++++++++++++++++\n",
      "from  2005-01-01 00:00:00  to  2009-01-01 00:00:00\n",
      "train start : 1584\n",
      "train end : 2574\n",
      "val start : 1584\n",
      "val end : 2574\n",
      "trade start : 1584\n",
      "trade end : 2574\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.387061679363251  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 26.219808853820236, 'total_profit': 0.811012422752182, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.2513275477666104\n",
      "\n",
      "==================Trading=================== 2005\n",
      "info {'total_reward': 12.73117007505617, 'total_profit': 0.7850118532172212, 'position': 0}\n",
      "action len :1982\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2002 2009 to 2013++++++++++++++++++++++\n",
      "from  2009-01-01 00:00:00  to  2013-01-01 00:00:00\n",
      "train start : 2575\n",
      "train end : 3573\n",
      "val start : 2575\n",
      "val end : 3573\n",
      "trade start : 2575\n",
      "trade end : 3573\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.545055548350017  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 0.456661699051553, 'total_profit': 0.5861192177904428, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.2636306825742611\n",
      "\n",
      "==================Trading=================== 2006\n",
      "info {'total_reward': 0.17292947204900375, 'total_profit': 0.49664294689361643, 'position': 1}\n",
      "action len :2981\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2002 2013 to 2017++++++++++++++++++++++\n",
      "from  2013-01-01 00:00:00  to  2017-01-01 00:00:00\n",
      "train start : 3574\n",
      "train end : 4555\n",
      "val start : 3574\n",
      "val end : 4555\n",
      "trade start : 3574\n",
      "trade end : 4555\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.567618294556936  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 11.725381103368367, 'total_profit': 0.3889098406165855, 'position': 1}\n",
      "DQN Sharpe Ratio:  -0.07612721183123974\n",
      "\n",
      "==================Trading=================== 2007\n",
      "info {'total_reward': 10.67642692449973, 'total_profit': 0.45240414164887277, 'position': 1}\n",
      "action len :3963\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2002 2017 to 2021++++++++++++++++++++++\n",
      "from  2017-01-01 00:00:00  to  2021-01-01 00:00:00\n",
      "train start : 4556\n",
      "train end : 5535\n",
      "val start : 4556\n",
      "val end : 5535\n",
      "trade start : 4556\n",
      "trade end : 5535\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.592736756801605  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 3.086524336185629, 'total_profit': 0.3859394948703316, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.1199461973840234\n",
      "\n",
      "==================Trading=================== 2008\n",
      "info {'total_reward': 0.7709482268119531, 'total_profit': 0.3393080096733569, 'position': 1}\n",
      "action len :4943\n",
      "============Trading Done============\n",
      "2002 final action len :4943\n",
      "#########################################2801#########################################\n",
      "++++++++++++++++++++++2801 2001 to 2005++++++++++++++++++++++\n",
      "from  2001-01-01 00:00:00  to  2005-01-01 00:00:00\n",
      "train start : 593\n",
      "train end : 1583\n",
      "val start : 593\n",
      "val end : 1583\n",
      "trade start : 593\n",
      "trade end : 1583\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.540832054615021  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 18.45443042273511, 'total_profit': 0.8952040111800735, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.2342632172117595\n",
      "\n",
      "==================Trading=================== 2004\n",
      "info {'total_reward': 21.69802458931979, 'total_profit': 0.9798123180893101, 'position': 0}\n",
      "action len :991\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2801 2005 to 2009++++++++++++++++++++++\n",
      "from  2005-01-01 00:00:00  to  2009-01-01 00:00:00\n",
      "train start : 1584\n",
      "train end : 2574\n",
      "val start : 1584\n",
      "val end : 2574\n",
      "trade start : 1584\n",
      "trade end : 2574\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.392375349998474  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 18.418938169265232, 'total_profit': 0.658221698547046, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.23639300716935088\n",
      "\n",
      "==================Trading=================== 2005\n",
      "info {'total_reward': 24.58530316182074, 'total_profit': 0.6807615183915336, 'position': 0}\n",
      "action len :1982\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2801 2009 to 2013++++++++++++++++++++++\n",
      "from  2009-01-01 00:00:00  to  2013-01-01 00:00:00\n",
      "train start : 2575\n",
      "train end : 3573\n",
      "val start : 2575\n",
      "val end : 3573\n",
      "trade start : 2575\n",
      "trade end : 3573\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.509197441736857  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 1.7924235562876656, 'total_profit': 0.5187576681332169, 'position': 0}\n",
      "DQN Sharpe Ratio:  0.07926405203627816\n",
      "\n",
      "==================Trading=================== 2006\n",
      "info {'total_reward': 9.510345462459288, 'total_profit': 0.4324038058297938, 'position': 0}\n",
      "action len :2981\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2801 2013 to 2017++++++++++++++++++++++\n",
      "from  2013-01-01 00:00:00  to  2017-01-01 00:00:00\n",
      "train start : 3574\n",
      "train end : 4555\n",
      "val start : 3574\n",
      "val end : 4555\n",
      "trade start : 3574\n",
      "trade end : 4555\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.607877123355865  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 3.7061508597813417, 'total_profit': 0.38638432876943485, 'position': 1}\n",
      "DQN Sharpe Ratio:  -0.048296258537588614\n",
      "\n",
      "==================Trading=================== 2007\n",
      "info {'total_reward': 0.8818490908128578, 'total_profit': 0.35647829062744424, 'position': 1}\n",
      "action len :3963\n",
      "============Trading Done============\n",
      "++++++++++++++++++++++2801 2017 to 2021++++++++++++++++++++++\n",
      "from  2017-01-01 00:00:00  to  2021-01-01 00:00:00\n",
      "train start : 4556\n",
      "train end : 5535\n",
      "val start : 4556\n",
      "val end : 5535\n",
      "trade start : 4556\n",
      "trade end : 5535\n",
      "======DQN Training========\n",
      "Training time (DQN):  7.586909087498983  minutes\n",
      "======DQN Validation========\n",
      "info {'total_reward': 3.874324697818945, 'total_profit': 0.4296189536369409, 'position': 1}\n",
      "DQN Sharpe Ratio:  0.13910744340920833\n",
      "\n",
      "==================Trading=================== 2008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info {'total_reward': 2.1251510621645586, 'total_profit': 0.39035261596204035, 'position': 1}\n",
      "action len :4943\n",
      "============Trading Done============\n",
      "2801 final action len :4943\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "stock_list = ['2330','2603','1301','2002','2801']  \n",
    "    \n",
    "\n",
    "for stock_id in stock_list:\n",
    "    print('#########################################'+stock_id+'#########################################')\n",
    "    start_date='1998-10-18'\n",
    "    end_date='2021-12-31'\n",
    "    df = api.taiwan_stock_daily(\n",
    "                stock_id = stock_id,\n",
    "                start_date = start_date,\n",
    "                end_date = end_date\n",
    "    )\n",
    "\n",
    "    df = df.iloc[:][['date','open', 'max', 'min', 'close','Trading_Volume']]\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    df.rename(columns = {'date':'Date', 'open':'Open','max':'High','min':'Low', 'close':'Close','Trading_Volume':'Volume'}, inplace = True)\n",
    "    dateArray = df['Date']\n",
    "    df.set_index('Date', inplace=True)\n",
    "\n",
    "    max_value = 0.8\n",
    "    min_value = 0.2\n",
    "\n",
    "    Max_Volume = df['Volume'].max()\n",
    "    Min_Volume = df['Volume'].min()\n",
    "    Max_Price = df['High'].max()\n",
    "    Min_Price = df['Low'].min()\n",
    "\n",
    "    df['RSI'] = talib.RSI(df.iloc[:]['Close'], timeperiod=14)/100\n",
    "    df['EMA'] = talib.EMA(df.iloc[:]['Close'], timeperiod=10)\n",
    "    df['OBV'] = talib.OBV(df.iloc[:]['Close'], df.iloc[:]['Volume'])\n",
    "    Max_OBV = df['OBV'].max()\n",
    "    Min_OBV = df['OBV'].min()\n",
    "\n",
    "    df['High'] = min_value + (max_value - min_value) * (df['High'] - Min_Price) / (Max_Price - Min_Price)\n",
    "    df['Low'] = min_value + (max_value - min_value) * (df['Low'] - Min_Price) / (Max_Price - Min_Price)\n",
    "    df['Open'] = min_value + (max_value - min_value) * (df['Open'] - Min_Price) / (Max_Price - Min_Price)\n",
    "    df['Close'] = min_value + (max_value - min_value) * (df['Close'] - Min_Price) / (Max_Price - Min_Price)\n",
    "    df['Volume'] = min_value + (max_value - min_value) * (df['Volume'] - Min_Volume) / (Max_Volume - Min_Volume)\n",
    "\n",
    "    df['EMA'] = min_value + (max_value - min_value) * (df['EMA'] - Min_Price) / (Max_Price - Min_Price)\n",
    "    df['OBV'] = min_value + (max_value - min_value) * (df['OBV'] - Min_OBV) / (Max_OBV - Min_OBV)\n",
    "\n",
    "\n",
    "\n",
    "    train_start = '2001-01-01'\n",
    "    train_start = datetime.strptime(train_start, '%Y-%m-%d')\n",
    "    train_start_idx = df.index.get_loc(dateArray[dateArray>=train_start].iloc[0])\n",
    "    train_end = '2005-01-01'\n",
    "    train_end = datetime.strptime(train_end, '%Y-%m-%d')\n",
    "    train_end_idx = df.index.get_loc(dateArray[dateArray<train_end].iloc[-1])\n",
    "    val_start = '2001-01-01'\n",
    "    val_start = datetime.strptime(val_start, '%Y-%m-%d')\n",
    "    val_start_idx = df.index.get_loc(dateArray[dateArray>=val_start].iloc[0])\n",
    "    val_end = '2005-1-1'\n",
    "    val_end = datetime.strptime(val_end, '%Y-%m-%d')\n",
    "    val_end_idx = df.index.get_loc(dateArray[dateArray<val_end].iloc[-1])\n",
    "    test_start = '2001-01-01'\n",
    "    test_start = datetime.strptime(test_start, '%Y-%m-%d')\n",
    "    test_start_idx = df.index.get_loc(dateArray[dateArray>=test_start].iloc[0])\n",
    "    test_end = '2005-1-1'\n",
    "    test_end = datetime.strptime(test_end, '%Y-%m-%d')\n",
    "    test_end_idx = df.index.get_loc(dateArray[dateArray<test_end].iloc[-1])\n",
    "\n",
    "    action_list = []\n",
    "    \n",
    "    ppo_sharpe_list = []\n",
    "    #rppo_sharpe_list = []\n",
    "    a2c_sharpe_list = []\n",
    "    dqn_sharpe_list = []\n",
    "    trpo_sharpe_list = []\n",
    "\n",
    "    model_use = []\n",
    "\n",
    "    for i in range(5):\n",
    "        print('++++++++++++++++++++++'+stock_id+' '+str(i*4+2001)+' to '+str(i*4+2005)+'++++++++++++++++++++++')\n",
    "        ############## Environment Setup starts ##############\n",
    "        ## training env\n",
    "        #env_maker = lambda: gym.make('stocks-v0', df=df, frame_bound=(train_start_idx,train_end_idx+1), window_size=20)\n",
    "        #env_train = DummyVecEnv([env_maker])\n",
    "        \n",
    "        #cus_env = MyCustomEnv(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=20)\n",
    "        #env_maker = lambda: cus_env\n",
    "        #env_train = DummyVecEnv([env_maker])\n",
    "        \n",
    "        env_train = DummyVecEnv([lambda: StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=50)]*4)\n",
    "        print('from ',test_start,' to ',test_end)\n",
    "        print('train start :',train_start_idx)\n",
    "        print('train end :',train_end_idx)\n",
    "\n",
    "\n",
    "        ## validation env\n",
    "        validation = df[val_start_idx:val_end_idx+1]\n",
    "        print('val start :',val_start_idx)\n",
    "        print('val end :',val_end_idx)\n",
    "        #env_maker = lambda: gym.make('stocks-v0', df=df, frame_bound=(val_start_idx,val_end_idx+1), window_size=20)\n",
    "        #env_val = gym.make('stocks-v0', df=df, frame_bound=(val_start_idx,val_end_idx+1), window_size=20)\n",
    "        #env_val = MyCustomEnv(df=df, frame_bound=(val_start_idx,val_end_idx+1), window_size=20)\n",
    "        #env_val2 = MyCustomEnv(df=df, frame_bound=(val_start_idx,val_end_idx+2), window_size=20)\n",
    "        #obs_val = env_val.reset()\n",
    "        #print(obs_val[np.newaxis, ...].shape)\n",
    "        \n",
    "        env_val = StocksEnv2(df=df, frame_bound=(val_start_idx,val_end_idx), window_size=50)\n",
    "        obs_val = env_val.reset()\n",
    "        \n",
    "        ############## Environment Setup ends ##############\n",
    "        print('trade start :',test_start_idx)\n",
    "        print('trade end :',test_end_idx)\n",
    "\n",
    "        \n",
    "        print(\"======DQN Training========\")\n",
    "        model_dqn = train_DQN(env_train, model_name=\"DQN_\"+stock_id+'_'+str(i), timesteps=2000000)\n",
    "        #model_dqn = DQN('MlpPolicy', env_train, verbose=0)\n",
    "        #model_dqn.learn(total_timesteps=400000)\n",
    "        print(\"======DQN Validation========\")\n",
    "        env_val = StocksEnv2(df=df, frame_bound=(val_start_idx,val_end_idx), window_size=50)\n",
    "        obs_val = env_val.reset()\n",
    "        sharpe_dqn = DRL_validation(df=df,model=model_dqn,test_env=env_val, test_obs=obs_val)\n",
    "        #sharpe_ppo = get_validation_sharpe(i)\n",
    "        print(\"DQN Sharpe Ratio: \", sharpe_dqn)\n",
    "        print()\n",
    "\n",
    "        model_ensemble = model_dqn\n",
    "        \n",
    "        ############## Training and Validation ends ##############\n",
    "        ############## Trading starts ##############\n",
    "        print(\"==================Trading===================\",str(i+2004))\n",
    "        #print(\"Used Model: \", model_ensemble)\n",
    "        action_list = DRL_prediction(df=df, model=model_dqn,start_date = test_start_idx,end_date = test_end_idx,action_list = action_list)\n",
    "        print('action len :'+str(len(action_list)))\n",
    "        \n",
    "        \n",
    "        print(\"============Trading Done============\")\n",
    "        ############## Trading ends ##############\n",
    "        if i == 4:break\n",
    "        else:\n",
    "            train_start = train_start + relativedelta(years=4)\n",
    "            train_start_idx = df.index.get_loc(dateArray[dateArray>=train_start].iloc[0])\n",
    "            train_end = train_end + relativedelta(years=4)\n",
    "            train_end_idx = df.index.get_loc(dateArray[dateArray<train_end].iloc[-1])\n",
    "            val_start = val_start + relativedelta(years=4)\n",
    "            val_start_idx = df.index.get_loc(dateArray[dateArray>=val_start].iloc[0])\n",
    "            val_end = val_end + relativedelta(years=4)\n",
    "            val_end_idx = df.index.get_loc(dateArray[dateArray<val_end].iloc[-1])\n",
    "            test_start = test_start + relativedelta(years=4)\n",
    "            test_start_idx = df.index.get_loc(dateArray[dateArray>=test_start].iloc[0])\n",
    "            test_end = test_end + relativedelta(years=4)\n",
    "            test_end_idx = df.index.get_loc(dateArray[dateArray<test_end].iloc[-1])\n",
    "            \n",
    "    print(str(stock_id)+' final action len :'+str(len(action_list)))\n",
    "    #total.append(action_list)\n",
    "    #action_output = np.array(action_list)\n",
    "    #np.savetxt('data_new/Trajectory/RL/' + stock_id + '_RL_expert.csv', action_list, delimiter=\",\")\n",
    "    '''==============================save sharpe ratio=========================================='''\n",
    "    total_sharpe = np.array([a2c_sharpe_list,ppo_sharpe_list,dqn_sharpe_list,trpo_sharpe_list])\n",
    "    np.savetxt('data_new/Trajectory/RL/' + stock_id + '_RL_sharpe.csv', total_sharpe, delimiter=\",\")                                                      \n",
    "    \n",
    "    '''==============================save trajectory=========================================='''\n",
    "    trading_info = []\n",
    "    buy_sell_tuple = []\n",
    "    hold = 0\n",
    "    temp = []\n",
    "    trading_dic = {}\n",
    "    return_list = []\n",
    "\n",
    "    TaiwanStockPriceDay = api.taiwan_stock_daily(\n",
    "        stock_id = '2330',\n",
    "        start_date = '2001-1-1',\n",
    "        end_date = '2020-12-31'\n",
    "        )\n",
    "    \n",
    "    for i in range(len(action_list)):\n",
    "        if action_list[i] == 1:\n",
    "            if hold == 0:\n",
    "                trading_info.append([i,'buy',TaiwanStockPriceDay['close'][i]])\n",
    "                temp.append([i,TaiwanStockPriceDay['close'][i]])\n",
    "                trading_dic[i] = ['buy', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "                hold = 1\n",
    "            else:\n",
    "                trading_info.append([i,'hold',TaiwanStockPriceDay['close'][i]])\n",
    "                trading_dic[i] = ['hold', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "        else:\n",
    "            if hold == 1:\n",
    "                trading_info.append([i,'sell',TaiwanStockPriceDay['close'][i]])\n",
    "                temp.append([i,TaiwanStockPriceDay['close'][i]])\n",
    "                temp.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                return_list.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "                buy_sell_tuple.append(temp)\n",
    "                temp = []\n",
    "                trading_dic[i] = ['sell', TaiwanStockPriceDay['close'][i]]\n",
    "\n",
    "\n",
    "                hold = 0\n",
    "            else:\n",
    "                trading_info.append([i,'hold',TaiwanStockPriceDay['close'][i]])\n",
    "                trading_dic[i] = ['hold', TaiwanStockPriceDay['close'][i]]\n",
    "            \n",
    "    if hold ==1:\n",
    "            trading_info[-1][1] = 'sell'\n",
    "            trading_dic[len(trading_dic)-1][0] = 'sell'\n",
    "            temp.append([i, TaiwanStockPriceDay['close'][i]])\n",
    "            temp.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "            return_list.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "            buy_sell_tuple.append(temp)\n",
    "            temp = []\n",
    "    #print(trading_info)\n",
    "    \n",
    "    with open(\"./data_new/Trajectory/RL/\" + stock_id + \"_\" + \"RL_trajectory_all_train4.csv\",  'w', encoding='utf8', newline='') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            for trade in trading_info:\n",
    "                writer.writerow(trade)\n",
    "    \n",
    "    #median = statistics.median(return_list)\n",
    "    median = 0\n",
    "    \n",
    "    #print(median)\n",
    "    \n",
    "    for trade in buy_sell_tuple:\n",
    "        #total_sum += trade[2]\n",
    "\n",
    "        \n",
    "        if trade[2] <median:\n",
    "            \n",
    "            trading_dic[trade[0][0]][0] = 'hold'\n",
    "            trading_dic[trade[1][0]][0] = 'hold'\n",
    "    #print(trading_dic)\n",
    "\n",
    "\n",
    "    with open(\"./data_new/Trajectory/RL/\" + stock_id + \"_\" + \"RL_trajectory_50_train4.csv\",  'w', encoding='utf8', newline='') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        for key in trading_dic.keys():\n",
    "            writer.writerow([key, trading_dic[key][0], trading_dic[key][1]])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00657440044232497\n"
     ]
    }
   ],
   "source": [
    "trading_info = []\n",
    "buy_sell_tuple = []\n",
    "hold = 0\n",
    "temp = []\n",
    "trading_dic = {}\n",
    "return_list = []\n",
    "\n",
    "TaiwanStockPriceDay = api.taiwan_stock_daily(\n",
    "    stock_id = '2330',\n",
    "    start_date = '2003-1-1',\n",
    "    end_date = '2020-12-31'\n",
    "    )\n",
    "for i in range(len(action_list)):\n",
    "    if action_list[i] == 1:\n",
    "        if hold == 0:\n",
    "            trading_info.append([i,'buy',TaiwanStockPriceDay['close'][i]])\n",
    "            temp.append([i,TaiwanStockPriceDay['close'][i]])\n",
    "            trading_dic[i] = ['buy', TaiwanStockPriceDay['close'][i]]\n",
    "            \n",
    "            hold = 1\n",
    "        else:\n",
    "            trading_info.append([i,'hold',TaiwanStockPriceDay['close'][i]])\n",
    "            trading_dic[i] = ['hold', TaiwanStockPriceDay['close'][i]]\n",
    "            \n",
    "    else:\n",
    "        if hold == 1:\n",
    "            trading_info.append([i,'sell',TaiwanStockPriceDay['close'][i]])\n",
    "            temp.append([i,TaiwanStockPriceDay['close'][i]])\n",
    "            temp.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "            return_list.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "            buy_sell_tuple.append(temp)\n",
    "            temp = []\n",
    "            trading_dic[i] = ['sell', TaiwanStockPriceDay['close'][i]]\n",
    "            \n",
    "            \n",
    "            hold = 0\n",
    "        else:\n",
    "            trading_info.append([i,'hold',TaiwanStockPriceDay['close'][i]])\n",
    "            trading_dic[i] = ['hold', TaiwanStockPriceDay['close'][i]]\n",
    "#print(trading_dic[len(trading_dic)-1])            \n",
    "if hold ==1:\n",
    "        trading_info[-1][1] = 'sell'\n",
    "        \n",
    "        trading_dic[len(trading_dic)-1][0] = 'sell'\n",
    "        temp.append([i, TaiwanStockPriceDay['close'][i]])\n",
    "        temp.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "        return_list.append((temp[1][1] - temp[0][1])/temp[0][1])\n",
    "        buy_sell_tuple.append(temp)\n",
    "        temp = []\n",
    "with open(\"./data_new/Trajectory/RL/\" + stock_id + \"_\" + \"RL_trajectory_all_train2.csv\",  'w', encoding='utf8', newline='') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            for trade in trading_info:\n",
    "                writer.writerow(trade)\n",
    "#print(trading_info)\n",
    "median = statistics.median(return_list)\n",
    "print(median)\n",
    "for trade in buy_sell_tuple:\n",
    "        #total_sum += trade[2]\n",
    "\n",
    "        \n",
    "        if trade[2] <median:\n",
    "            \n",
    "            trading_dic[trade[0][0]][0] = 'hold'\n",
    "            trading_dic[trade[1][0]][0] = 'hold'\n",
    "#print(trading_dic)\n",
    "\n",
    "\n",
    "with open(\"./data_new/Trajectory/RL/\" + stock_id + \"_\" + \"RL_trajectory_50_train2.csv\",  'w', encoding='utf8', newline='') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    for key in trading_dic.keys():\n",
    "        writer.writerow([key, trading_dic[key][0], trading_dic[key][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003-01-01 00:00:00\n",
      "2003-05-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train_start = '2003-01-01'\n",
    "train_start = datetime.strptime(train_start, '%Y-%m-%d')\n",
    "print(train_start)\n",
    "train_start = train_start + relativedelta(months=4)\n",
    "print(train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "start_date='2000-10-18'\n",
    "end_date='2020-12-31'\n",
    "df = api.taiwan_stock_daily(\n",
    "            stock_id = '2603',\n",
    "            start_date = start_date,\n",
    "            end_date = end_date\n",
    ")\n",
    "\n",
    "df = df.iloc[:][['date','open', 'max', 'min', 'close','Trading_Volume']]\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df.rename(columns = {'date':'Date', 'open':'Open','max':'High','min':'Low', 'close':'Close','Trading_Volume':'Volume'}, inplace = True)\n",
    "dateArray = df['Date']\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "max_value = 0.8\n",
    "min_value = 0.2\n",
    "\n",
    "Max_Volume = df['Volume'].max()\n",
    "Min_Volume = df['Volume'].min()\n",
    "Max_Price = df['High'].max()\n",
    "Min_Price = df['Low'].min()\n",
    "\n",
    "df['RSI'] = talib.RSI(df.iloc[:]['Close'], timeperiod=14)/100\n",
    "df['EMA'] = talib.EMA(df.iloc[:]['Close'], timeperiod=10)\n",
    "df['OBV'] = talib.OBV(df.iloc[:]['Close'], df.iloc[:]['Volume'])\n",
    "Max_OBV = df['OBV'].max()\n",
    "Min_OBV = df['OBV'].min()\n",
    "\n",
    "df['High'] = min_value + (max_value - min_value) * (df['High'] - Min_Price) / (Max_Price - Min_Price)\n",
    "df['Low'] = min_value + (max_value - min_value) * (df['Low'] - Min_Price) / (Max_Price - Min_Price)\n",
    "df['Open'] = min_value + (max_value - min_value) * (df['Open'] - Min_Price) / (Max_Price - Min_Price)\n",
    "df['Close'] = min_value + (max_value - min_value) * (df['Close'] - Min_Price) / (Max_Price - Min_Price)\n",
    "df['Volume'] = min_value + (max_value - min_value) * (df['Volume'] - Min_Volume) / (Max_Volume - Min_Volume)\n",
    "\n",
    "df['EMA'] = min_value + (max_value - min_value) * (df['EMA'] - Min_Price) / (Max_Price - Min_Price)\n",
    "df['OBV'] = min_value + (max_value - min_value) * (df['OBV'] - Min_OBV) / (Max_OBV - Min_OBV)\n",
    "\n",
    "\n",
    "\n",
    "train_start = '2001-01-01'\n",
    "train_start = datetime.strptime(train_start, '%Y-%m-%d')\n",
    "train_start_idx = df.index.get_loc(dateArray[dateArray>=train_start].iloc[0])\n",
    "train_end = '2004-01-01'\n",
    "train_end = datetime.strptime(train_end, '%Y-%m-%d')\n",
    "train_end_idx = df.index.get_loc(dateArray[dateArray<train_end].iloc[-1])\n",
    "val_start = '2009-01-01'\n",
    "val_start = datetime.strptime(val_start, '%Y-%m-%d')\n",
    "val_start_idx = df.index.get_loc(dateArray[dateArray>=val_start].iloc[0])\n",
    "val_end = '2010-1-1'\n",
    "val_end = datetime.strptime(val_end, '%Y-%m-%d')\n",
    "val_end_idx = df.index.get_loc(dateArray[dateArray<val_end].iloc[-1])\n",
    "test_start = '2004-01-01'\n",
    "test_start = datetime.strptime(test_start, '%Y-%m-%d')\n",
    "test_start_idx = df.index.get_loc(dateArray[dateArray>=test_start].iloc[0])\n",
    "test_end = '2004-12-31'\n",
    "test_end = datetime.strptime(test_end, '%Y-%m-%d')\n",
    "test_end_idx = df.index.get_loc(dateArray[dateArray<=test_end].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_signals(env):\n",
    "    start = env.frame_bound[0] - env.window_size\n",
    "    end = env.frame_bound[1]\n",
    "    prices = env.df.loc[:, 'Close'].to_numpy()[start:end]\n",
    "    signal_features = env.df.loc[:, ['Open','High','Low','Close','Volume','EMA', 'RSI', 'OBV']].to_numpy()[start:end]\n",
    "    return prices, signal_features\n",
    "\n",
    "class MyCustomEnv(StocksEnv):\n",
    "    _process_data = add_signals\n",
    "    #_calculate_reward = new_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_end_idx-val_start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>EMA</th>\n",
       "      <th>OBV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-02</th>\n",
       "      <td>29.2</td>\n",
       "      <td>30.7</td>\n",
       "      <td>29.2</td>\n",
       "      <td>30.2</td>\n",
       "      <td>18474000</td>\n",
       "      <td>59.353708</td>\n",
       "      <td>29.506064</td>\n",
       "      <td>1.884618e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-05</th>\n",
       "      <td>30.2</td>\n",
       "      <td>31.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>30.7</td>\n",
       "      <td>22464641</td>\n",
       "      <td>62.492911</td>\n",
       "      <td>29.723144</td>\n",
       "      <td>1.907082e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-06</th>\n",
       "      <td>30.8</td>\n",
       "      <td>32.5</td>\n",
       "      <td>30.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>25271748</td>\n",
       "      <td>67.842236</td>\n",
       "      <td>30.082572</td>\n",
       "      <td>1.932354e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-07</th>\n",
       "      <td>32.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>32.2</td>\n",
       "      <td>20119723</td>\n",
       "      <td>70.135703</td>\n",
       "      <td>30.467559</td>\n",
       "      <td>1.952474e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>32.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>31.9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10439161</td>\n",
       "      <td>68.045209</td>\n",
       "      <td>30.746185</td>\n",
       "      <td>1.942035e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-09</th>\n",
       "      <td>32.3</td>\n",
       "      <td>32.4</td>\n",
       "      <td>31.6</td>\n",
       "      <td>32.2</td>\n",
       "      <td>16689753</td>\n",
       "      <td>69.039032</td>\n",
       "      <td>31.010515</td>\n",
       "      <td>1.958725e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-12</th>\n",
       "      <td>32.2</td>\n",
       "      <td>32.3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8024314</td>\n",
       "      <td>57.486552</td>\n",
       "      <td>31.008603</td>\n",
       "      <td>1.950700e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-13</th>\n",
       "      <td>31.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.7</td>\n",
       "      <td>9626198</td>\n",
       "      <td>55.008365</td>\n",
       "      <td>30.952493</td>\n",
       "      <td>1.941074e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-14</th>\n",
       "      <td>30.7</td>\n",
       "      <td>32.3</td>\n",
       "      <td>30.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>16150432</td>\n",
       "      <td>61.553011</td>\n",
       "      <td>31.106585</td>\n",
       "      <td>1.957224e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-15</th>\n",
       "      <td>32.1</td>\n",
       "      <td>32.2</td>\n",
       "      <td>31.3</td>\n",
       "      <td>31.5</td>\n",
       "      <td>4547393</td>\n",
       "      <td>59.030996</td>\n",
       "      <td>31.178115</td>\n",
       "      <td>1.952677e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-16</th>\n",
       "      <td>31.6</td>\n",
       "      <td>32.9</td>\n",
       "      <td>31.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>20514081</td>\n",
       "      <td>65.607168</td>\n",
       "      <td>31.473003</td>\n",
       "      <td>1.973191e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-27</th>\n",
       "      <td>33.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>23691000</td>\n",
       "      <td>72.543857</td>\n",
       "      <td>32.059730</td>\n",
       "      <td>1.996882e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-28</th>\n",
       "      <td>34.7</td>\n",
       "      <td>34.7</td>\n",
       "      <td>33.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11694300</td>\n",
       "      <td>67.168824</td>\n",
       "      <td>32.412506</td>\n",
       "      <td>1.985188e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-29</th>\n",
       "      <td>33.9</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.9</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24359790</td>\n",
       "      <td>67.168824</td>\n",
       "      <td>32.701142</td>\n",
       "      <td>1.985188e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-30</th>\n",
       "      <td>34.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>33.7</td>\n",
       "      <td>34.6</td>\n",
       "      <td>13490292</td>\n",
       "      <td>69.421116</td>\n",
       "      <td>33.046389</td>\n",
       "      <td>1.998678e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-02</th>\n",
       "      <td>34.6</td>\n",
       "      <td>34.9</td>\n",
       "      <td>34.1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>8508249</td>\n",
       "      <td>68.576715</td>\n",
       "      <td>33.310682</td>\n",
       "      <td>1.990170e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-03</th>\n",
       "      <td>34.0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>33.7</td>\n",
       "      <td>10515230</td>\n",
       "      <td>62.072015</td>\n",
       "      <td>33.381467</td>\n",
       "      <td>1.979655e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-04</th>\n",
       "      <td>34.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>33.8</td>\n",
       "      <td>34.9</td>\n",
       "      <td>26240545</td>\n",
       "      <td>67.111344</td>\n",
       "      <td>33.657564</td>\n",
       "      <td>2.005895e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-05</th>\n",
       "      <td>34.9</td>\n",
       "      <td>35.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>34.6</td>\n",
       "      <td>10116658</td>\n",
       "      <td>64.793578</td>\n",
       "      <td>33.828916</td>\n",
       "      <td>1.995779e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-06</th>\n",
       "      <td>34.6</td>\n",
       "      <td>34.8</td>\n",
       "      <td>34.1</td>\n",
       "      <td>34.6</td>\n",
       "      <td>10282120</td>\n",
       "      <td>64.793578</td>\n",
       "      <td>33.969113</td>\n",
       "      <td>1.995779e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-09</th>\n",
       "      <td>34.9</td>\n",
       "      <td>35.8</td>\n",
       "      <td>34.7</td>\n",
       "      <td>35.1</td>\n",
       "      <td>16864600</td>\n",
       "      <td>66.996750</td>\n",
       "      <td>34.174729</td>\n",
       "      <td>2.012643e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-10</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>34.4</td>\n",
       "      <td>35.1</td>\n",
       "      <td>11259383</td>\n",
       "      <td>66.996750</td>\n",
       "      <td>34.342960</td>\n",
       "      <td>2.012643e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-11</th>\n",
       "      <td>35.5</td>\n",
       "      <td>36.3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.7</td>\n",
       "      <td>15527792</td>\n",
       "      <td>69.640788</td>\n",
       "      <td>34.589694</td>\n",
       "      <td>2.028171e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-12</th>\n",
       "      <td>35.7</td>\n",
       "      <td>35.9</td>\n",
       "      <td>34.7</td>\n",
       "      <td>34.7</td>\n",
       "      <td>8331471</td>\n",
       "      <td>60.885714</td>\n",
       "      <td>34.609750</td>\n",
       "      <td>2.019839e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-13</th>\n",
       "      <td>34.7</td>\n",
       "      <td>34.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.4</td>\n",
       "      <td>9454696</td>\n",
       "      <td>58.509274</td>\n",
       "      <td>34.571614</td>\n",
       "      <td>2.010385e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-16</th>\n",
       "      <td>34.4</td>\n",
       "      <td>34.8</td>\n",
       "      <td>34.4</td>\n",
       "      <td>34.4</td>\n",
       "      <td>5299651</td>\n",
       "      <td>58.509274</td>\n",
       "      <td>34.540411</td>\n",
       "      <td>2.010385e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-17</th>\n",
       "      <td>34.4</td>\n",
       "      <td>35.2</td>\n",
       "      <td>34.1</td>\n",
       "      <td>34.8</td>\n",
       "      <td>15428822</td>\n",
       "      <td>60.870943</td>\n",
       "      <td>34.587609</td>\n",
       "      <td>2.025814e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-18</th>\n",
       "      <td>35.1</td>\n",
       "      <td>35.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9745667</td>\n",
       "      <td>62.034562</td>\n",
       "      <td>34.662589</td>\n",
       "      <td>2.035559e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-19</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>34.5</td>\n",
       "      <td>35.4</td>\n",
       "      <td>11532506</td>\n",
       "      <td>64.319909</td>\n",
       "      <td>34.796664</td>\n",
       "      <td>2.047092e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-20</th>\n",
       "      <td>35.6</td>\n",
       "      <td>36.2</td>\n",
       "      <td>34.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10636955</td>\n",
       "      <td>60.404156</td>\n",
       "      <td>34.833634</td>\n",
       "      <td>2.036455e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-23</th>\n",
       "      <td>34.9</td>\n",
       "      <td>35.8</td>\n",
       "      <td>34.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9678899</td>\n",
       "      <td>60.404156</td>\n",
       "      <td>34.863882</td>\n",
       "      <td>2.036455e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-24</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>34.7</td>\n",
       "      <td>34.7</td>\n",
       "      <td>6552395</td>\n",
       "      <td>57.366366</td>\n",
       "      <td>34.834086</td>\n",
       "      <td>2.029902e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-25</th>\n",
       "      <td>34.7</td>\n",
       "      <td>35.4</td>\n",
       "      <td>34.4</td>\n",
       "      <td>35.1</td>\n",
       "      <td>6650045</td>\n",
       "      <td>60.237713</td>\n",
       "      <td>34.882434</td>\n",
       "      <td>2.036552e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-26</th>\n",
       "      <td>35.3</td>\n",
       "      <td>35.7</td>\n",
       "      <td>34.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10721519</td>\n",
       "      <td>59.164905</td>\n",
       "      <td>34.903809</td>\n",
       "      <td>2.025831e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-27</th>\n",
       "      <td>35.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>33625226</td>\n",
       "      <td>67.808709</td>\n",
       "      <td>35.175844</td>\n",
       "      <td>2.059456e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-01</th>\n",
       "      <td>36.6</td>\n",
       "      <td>37.8</td>\n",
       "      <td>36.6</td>\n",
       "      <td>37.5</td>\n",
       "      <td>34229345</td>\n",
       "      <td>72.698661</td>\n",
       "      <td>35.598418</td>\n",
       "      <td>2.093686e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-02</th>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>37.4</td>\n",
       "      <td>11839977</td>\n",
       "      <td>71.633357</td>\n",
       "      <td>35.925978</td>\n",
       "      <td>2.081846e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-03</th>\n",
       "      <td>37.4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>37.5</td>\n",
       "      <td>16984597</td>\n",
       "      <td>72.074054</td>\n",
       "      <td>36.212164</td>\n",
       "      <td>2.098830e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-04</th>\n",
       "      <td>37.5</td>\n",
       "      <td>38.2</td>\n",
       "      <td>37.1</td>\n",
       "      <td>37.3</td>\n",
       "      <td>9858220</td>\n",
       "      <td>69.740429</td>\n",
       "      <td>36.409952</td>\n",
       "      <td>2.088972e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-05</th>\n",
       "      <td>37.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>14343633</td>\n",
       "      <td>63.136002</td>\n",
       "      <td>36.462688</td>\n",
       "      <td>2.074628e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-08</th>\n",
       "      <td>36.7</td>\n",
       "      <td>37.1</td>\n",
       "      <td>36.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>8178644</td>\n",
       "      <td>64.347989</td>\n",
       "      <td>36.542200</td>\n",
       "      <td>2.082807e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-09</th>\n",
       "      <td>36.9</td>\n",
       "      <td>37.9</td>\n",
       "      <td>36.9</td>\n",
       "      <td>37.8</td>\n",
       "      <td>12136541</td>\n",
       "      <td>69.247699</td>\n",
       "      <td>36.770891</td>\n",
       "      <td>2.094943e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-10</th>\n",
       "      <td>37.6</td>\n",
       "      <td>38.7</td>\n",
       "      <td>37.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>18044791</td>\n",
       "      <td>69.247699</td>\n",
       "      <td>36.958001</td>\n",
       "      <td>2.094943e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-11</th>\n",
       "      <td>37.3</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.1</td>\n",
       "      <td>37.5</td>\n",
       "      <td>9128124</td>\n",
       "      <td>65.754221</td>\n",
       "      <td>37.056547</td>\n",
       "      <td>2.085815e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-12</th>\n",
       "      <td>36.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>7013231</td>\n",
       "      <td>58.356417</td>\n",
       "      <td>37.009902</td>\n",
       "      <td>2.078802e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-15</th>\n",
       "      <td>36.5</td>\n",
       "      <td>38.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>37.3</td>\n",
       "      <td>34814673</td>\n",
       "      <td>61.673350</td>\n",
       "      <td>37.062647</td>\n",
       "      <td>2.113617e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-16</th>\n",
       "      <td>37.3</td>\n",
       "      <td>37.4</td>\n",
       "      <td>36.6</td>\n",
       "      <td>36.8</td>\n",
       "      <td>18322903</td>\n",
       "      <td>56.801095</td>\n",
       "      <td>37.014893</td>\n",
       "      <td>2.095294e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-17</th>\n",
       "      <td>37.0</td>\n",
       "      <td>37.9</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>15264533</td>\n",
       "      <td>61.976971</td>\n",
       "      <td>37.121276</td>\n",
       "      <td>2.110558e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-18</th>\n",
       "      <td>37.8</td>\n",
       "      <td>40.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>39.7</td>\n",
       "      <td>33785117</td>\n",
       "      <td>71.597213</td>\n",
       "      <td>37.590135</td>\n",
       "      <td>2.144344e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-19</th>\n",
       "      <td>39.8</td>\n",
       "      <td>40.7</td>\n",
       "      <td>39.5</td>\n",
       "      <td>40.2</td>\n",
       "      <td>40270357</td>\n",
       "      <td>73.327576</td>\n",
       "      <td>38.064656</td>\n",
       "      <td>2.184614e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-22</th>\n",
       "      <td>37.4</td>\n",
       "      <td>37.4</td>\n",
       "      <td>37.4</td>\n",
       "      <td>37.4</td>\n",
       "      <td>1703633</td>\n",
       "      <td>53.625224</td>\n",
       "      <td>37.943809</td>\n",
       "      <td>2.182910e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-23</th>\n",
       "      <td>34.8</td>\n",
       "      <td>34.8</td>\n",
       "      <td>34.8</td>\n",
       "      <td>34.8</td>\n",
       "      <td>5949478</td>\n",
       "      <td>42.268201</td>\n",
       "      <td>37.372208</td>\n",
       "      <td>2.176961e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-24</th>\n",
       "      <td>33.8</td>\n",
       "      <td>34.8</td>\n",
       "      <td>32.4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>48693456</td>\n",
       "      <td>36.504223</td>\n",
       "      <td>36.577261</td>\n",
       "      <td>2.128267e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-25</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.7</td>\n",
       "      <td>31.5</td>\n",
       "      <td>32.5</td>\n",
       "      <td>23726028</td>\n",
       "      <td>35.073455</td>\n",
       "      <td>35.835941</td>\n",
       "      <td>2.104541e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-26</th>\n",
       "      <td>32.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.3</td>\n",
       "      <td>30.5</td>\n",
       "      <td>20230145</td>\n",
       "      <td>30.007107</td>\n",
       "      <td>34.865770</td>\n",
       "      <td>2.084311e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-29</th>\n",
       "      <td>32.5</td>\n",
       "      <td>32.6</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>9481951</td>\n",
       "      <td>39.834493</td>\n",
       "      <td>34.453812</td>\n",
       "      <td>2.093793e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-30</th>\n",
       "      <td>33.3</td>\n",
       "      <td>33.4</td>\n",
       "      <td>32.5</td>\n",
       "      <td>33.3</td>\n",
       "      <td>20752490</td>\n",
       "      <td>42.721445</td>\n",
       "      <td>34.244028</td>\n",
       "      <td>2.114546e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-31</th>\n",
       "      <td>33.4</td>\n",
       "      <td>33.7</td>\n",
       "      <td>32.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>20958403</td>\n",
       "      <td>42.721445</td>\n",
       "      <td>34.072386</td>\n",
       "      <td>2.114546e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-01</th>\n",
       "      <td>33.2</td>\n",
       "      <td>33.3</td>\n",
       "      <td>32.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>7323285</td>\n",
       "      <td>39.000801</td>\n",
       "      <td>33.713771</td>\n",
       "      <td>2.107222e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open  High   Low  Close    Volume        RSI        EMA  \\\n",
       "Date                                                                  \n",
       "2004-01-02  29.2  30.7  29.2   30.2  18474000  59.353708  29.506064   \n",
       "2004-01-05  30.2  31.4  30.2   30.7  22464641  62.492911  29.723144   \n",
       "2004-01-06  30.8  32.5  30.7   31.7  25271748  67.842236  30.082572   \n",
       "2004-01-07  32.0  32.2  31.5   32.2  20119723  70.135703  30.467559   \n",
       "2004-01-08  32.6  32.8  31.9   32.0  10439161  68.045209  30.746185   \n",
       "2004-01-09  32.3  32.4  31.6   32.2  16689753  69.039032  31.010515   \n",
       "2004-01-12  32.2  32.3  31.0   31.0   8024314  57.486552  31.008603   \n",
       "2004-01-13  31.0  31.3  30.5   30.7   9626198  55.008365  30.952493   \n",
       "2004-01-14  30.7  32.3  30.6   31.8  16150432  61.553011  31.106585   \n",
       "2004-01-15  32.1  32.2  31.3   31.5   4547393  59.030996  31.178115   \n",
       "2004-01-16  31.6  32.9  31.6   32.8  20514081  65.607168  31.473003   \n",
       "2004-01-27  33.5  35.0  33.3   34.7  23691000  72.543857  32.059730   \n",
       "2004-01-28  34.7  34.7  33.8   34.0  11694300  67.168824  32.412506   \n",
       "2004-01-29  33.9  35.0  33.9   34.0  24359790  67.168824  32.701142   \n",
       "2004-01-30  34.0  34.9  33.7   34.6  13490292  69.421116  33.046389   \n",
       "2004-02-02  34.6  34.9  34.1   34.5   8508249  68.576715  33.310682   \n",
       "2004-02-03  34.0  34.2  33.2   33.7  10515230  62.072015  33.381467   \n",
       "2004-02-04  34.0  35.5  33.8   34.9  26240545  67.111344  33.657564   \n",
       "2004-02-05  34.9  35.2  34.3   34.6  10116658  64.793578  33.828916   \n",
       "2004-02-06  34.6  34.8  34.1   34.6  10282120  64.793578  33.969113   \n",
       "2004-02-09  34.9  35.8  34.7   35.1  16864600  66.996750  34.174729   \n",
       "2004-02-10  35.0  35.1  34.4   35.1  11259383  66.996750  34.342960   \n",
       "2004-02-11  35.5  36.3  35.0   35.7  15527792  69.640788  34.589694   \n",
       "2004-02-12  35.7  35.9  34.7   34.7   8331471  60.885714  34.609750   \n",
       "2004-02-13  34.7  34.8  34.0   34.4   9454696  58.509274  34.571614   \n",
       "2004-02-16  34.4  34.8  34.4   34.4   5299651  58.509274  34.540411   \n",
       "2004-02-17  34.4  35.2  34.1   34.8  15428822  60.870943  34.587609   \n",
       "2004-02-18  35.1  35.6  34.7   35.0   9745667  62.034562  34.662589   \n",
       "2004-02-19  35.0  35.6  34.5   35.4  11532506  64.319909  34.796664   \n",
       "2004-02-20  35.6  36.2  34.8   35.0  10636955  60.404156  34.833634   \n",
       "2004-02-23  34.9  35.8  34.6   35.0   9678899  60.404156  34.863882   \n",
       "2004-02-24  35.0  35.5  34.7   34.7   6552395  57.366366  34.834086   \n",
       "2004-02-25  34.7  35.4  34.4   35.1   6650045  60.237713  34.882434   \n",
       "2004-02-26  35.3  35.7  34.8   35.0  10721519  59.164905  34.903809   \n",
       "2004-02-27  35.0  37.2  35.0   36.4  33625226  67.808709  35.175844   \n",
       "2004-03-01  36.6  37.8  36.6   37.5  34229345  72.698661  35.598418   \n",
       "2004-03-02  38.0  38.0  36.7   37.4  11839977  71.633357  35.925978   \n",
       "2004-03-03  37.4  39.0  37.4   37.5  16984597  72.074054  36.212164   \n",
       "2004-03-04  37.5  38.2  37.1   37.3   9858220  69.740429  36.409952   \n",
       "2004-03-05  37.3  38.0  36.6   36.7  14343633  63.136002  36.462688   \n",
       "2004-03-08  36.7  37.1  36.4   36.9   8178644  64.347989  36.542200   \n",
       "2004-03-09  36.9  37.9  36.9   37.8  12136541  69.247699  36.770891   \n",
       "2004-03-10  37.6  38.7  37.1   37.8  18044791  69.247699  36.958001   \n",
       "2004-03-11  37.3  37.7  37.1   37.5   9128124  65.754221  37.056547   \n",
       "2004-03-12  36.5  37.0  36.5   36.8   7013231  58.356417  37.009902   \n",
       "2004-03-15  36.5  38.5  36.5   37.3  34814673  61.673350  37.062647   \n",
       "2004-03-16  37.3  37.4  36.6   36.8  18322903  56.801095  37.014893   \n",
       "2004-03-17  37.0  37.9  37.0   37.6  15264533  61.976971  37.121276   \n",
       "2004-03-18  37.8  40.0  36.8   39.7  33785117  71.597213  37.590135   \n",
       "2004-03-19  39.8  40.7  39.5   40.2  40270357  73.327576  38.064656   \n",
       "2004-03-22  37.4  37.4  37.4   37.4   1703633  53.625224  37.943809   \n",
       "2004-03-23  34.8  34.8  34.8   34.8   5949478  42.268201  37.372208   \n",
       "2004-03-24  33.8  34.8  32.4   33.0  48693456  36.504223  36.577261   \n",
       "2004-03-25  33.0  33.7  31.5   32.5  23726028  35.073455  35.835941   \n",
       "2004-03-26  32.5  33.0  30.3   30.5  20230145  30.007107  34.865770   \n",
       "2004-03-29  32.5  32.6  32.0   32.6   9481951  39.834493  34.453812   \n",
       "2004-03-30  33.3  33.4  32.5   33.3  20752490  42.721445  34.244028   \n",
       "2004-03-31  33.4  33.7  32.7   33.3  20958403  42.721445  34.072386   \n",
       "2004-04-01  33.2  33.3  32.1   32.1   7323285  39.000801  33.713771   \n",
       "\n",
       "                     OBV  \n",
       "Date                      \n",
       "2004-01-02  1.884618e+09  \n",
       "2004-01-05  1.907082e+09  \n",
       "2004-01-06  1.932354e+09  \n",
       "2004-01-07  1.952474e+09  \n",
       "2004-01-08  1.942035e+09  \n",
       "2004-01-09  1.958725e+09  \n",
       "2004-01-12  1.950700e+09  \n",
       "2004-01-13  1.941074e+09  \n",
       "2004-01-14  1.957224e+09  \n",
       "2004-01-15  1.952677e+09  \n",
       "2004-01-16  1.973191e+09  \n",
       "2004-01-27  1.996882e+09  \n",
       "2004-01-28  1.985188e+09  \n",
       "2004-01-29  1.985188e+09  \n",
       "2004-01-30  1.998678e+09  \n",
       "2004-02-02  1.990170e+09  \n",
       "2004-02-03  1.979655e+09  \n",
       "2004-02-04  2.005895e+09  \n",
       "2004-02-05  1.995779e+09  \n",
       "2004-02-06  1.995779e+09  \n",
       "2004-02-09  2.012643e+09  \n",
       "2004-02-10  2.012643e+09  \n",
       "2004-02-11  2.028171e+09  \n",
       "2004-02-12  2.019839e+09  \n",
       "2004-02-13  2.010385e+09  \n",
       "2004-02-16  2.010385e+09  \n",
       "2004-02-17  2.025814e+09  \n",
       "2004-02-18  2.035559e+09  \n",
       "2004-02-19  2.047092e+09  \n",
       "2004-02-20  2.036455e+09  \n",
       "2004-02-23  2.036455e+09  \n",
       "2004-02-24  2.029902e+09  \n",
       "2004-02-25  2.036552e+09  \n",
       "2004-02-26  2.025831e+09  \n",
       "2004-02-27  2.059456e+09  \n",
       "2004-03-01  2.093686e+09  \n",
       "2004-03-02  2.081846e+09  \n",
       "2004-03-03  2.098830e+09  \n",
       "2004-03-04  2.088972e+09  \n",
       "2004-03-05  2.074628e+09  \n",
       "2004-03-08  2.082807e+09  \n",
       "2004-03-09  2.094943e+09  \n",
       "2004-03-10  2.094943e+09  \n",
       "2004-03-11  2.085815e+09  \n",
       "2004-03-12  2.078802e+09  \n",
       "2004-03-15  2.113617e+09  \n",
       "2004-03-16  2.095294e+09  \n",
       "2004-03-17  2.110558e+09  \n",
       "2004-03-18  2.144344e+09  \n",
       "2004-03-19  2.184614e+09  \n",
       "2004-03-22  2.182910e+09  \n",
       "2004-03-23  2.176961e+09  \n",
       "2004-03-24  2.128267e+09  \n",
       "2004-03-25  2.104541e+09  \n",
       "2004-03-26  2.084311e+09  \n",
       "2004-03-29  2.093793e+09  \n",
       "2004-03-30  2.114546e+09  \n",
       "2004-03-31  2.114546e+09  \n",
       "2004-04-01  2.107222e+09  "
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[test_start_idx:test_end_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_maker = lambda: gym.make('stocks-v0', df=df, frame_bound=(100,200), window_size=5)\n",
    "#env_maker = lambda: gym.make('stocks-v0', df=df, frame_bound=(5,100), window_size=5)\n",
    "env = DummyVecEnv([env_maker]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: StocksEnv2(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=20)]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "env2 = MyCustomEnv(df=df, frame_bound=(train_start_idx,train_end_idx), window_size=12)\n",
    "#env2 = MyCustomEnv(df=df, frame_bound=(100,200), window_size=5)\n",
    "#print(env2.signal_features[:6])\n",
    "env_maker = lambda: env2\n",
    "env = DummyVecEnv([lambda: env2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:71: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=8000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=12000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=16000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=20000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=24000, episode_reward=8.72 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=28000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=32000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=36000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=40000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=44000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=48000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=52000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=56000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=60000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=64000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=68000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=72000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=76000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=80000, episode_reward=-26.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=84000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=88000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=92000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=96000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=100000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=104000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=108000, episode_reward=-9.53 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Stopping training because there was no new best model in the last 21 evaluations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7f1a250844d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from stable_baselines3.common.optimizers import Adam\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=20, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "model = A2C('MlpPolicy', env, verbose=0, ent_coef=0.1)\n",
    "model.learn(total_timesteps=600000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:71: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4000, episode_reward=0.07 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=8000, episode_reward=0.07 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=12000, episode_reward=-27.61 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=16000, episode_reward=-27.61 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=20000, episode_reward=-1.70 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=24000, episode_reward=-1.70 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=28000, episode_reward=0.03 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=32000, episode_reward=0.03 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=36000, episode_reward=0.03 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=40000, episode_reward=0.03 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=44000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=48000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=52000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=56000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=60000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=64000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=68000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=72000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=76000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=80000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=84000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=88000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=92000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=96000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=100000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Eval num_timesteps=104000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 739.00 +/- 0.00\n",
      "Stopping training because there was no new best model in the last 21 evaluations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f9eaef2b1d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=20, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=0, ent_coef=0.1, batch_size=64,learning_rate=0.0003,n_epochs=10)\n",
    "model.learn(total_timesteps=1000000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 11221    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1960     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 11715    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3920     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 11834    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5880     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 11883    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7840     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 11677    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9800     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 11728    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 11760    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 11714    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13720    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.752    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 11696    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 15680    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.721    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 11675    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17640    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.69     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 11666    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19600    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.659    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 11676    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 21560    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 11703    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 23520    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.597    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 11727    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25480    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.566    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 11749    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27440    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.534    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 11761    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29400    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.503    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 11765    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31360    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.472    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 11686    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33320    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.441    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 11653    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 35280    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.41     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 11669    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37240    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.379    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 11680    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 39200    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.348    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 11687    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 41160    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.317    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 11694    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 43120    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 11706    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 45080    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.255    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 11715    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 47040    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.224    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 11726    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 49000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.193    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 9239     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 50960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.42e+05 |\n",
      "|    n_updates        | 239      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.162    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 6617     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 52920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.65e+05 |\n",
      "|    n_updates        | 729      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.131    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 5245     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 54880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.49e+05 |\n",
      "|    n_updates        | 1219     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 4371     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 56840    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.33e+04 |\n",
      "|    n_updates        | 1709     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.069    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 3765     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 58800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.06e+05 |\n",
      "|    n_updates        | 2199     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 3330     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 60760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.93e+05 |\n",
      "|    n_updates        | 2689     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 3008     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 62720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.61e+04 |\n",
      "|    n_updates        | 3179     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 2768     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 64680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.32e+05 |\n",
      "|    n_updates        | 3669     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 2565     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 66640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13e+05 |\n",
      "|    n_updates        | 4159     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 2398     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 68600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.43e+04 |\n",
      "|    n_updates        | 4649     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 2261     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 70560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.43e+04 |\n",
      "|    n_updates        | 5139     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 2147     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 72520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57e+05 |\n",
      "|    n_updates        | 5629     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 2042     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 74480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.49e+04 |\n",
      "|    n_updates        | 6119     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 1952     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 76440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.53e+05 |\n",
      "|    n_updates        | 6609     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 1874     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 78400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.52e+04 |\n",
      "|    n_updates        | 7099     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 1807     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 80360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.02e+05 |\n",
      "|    n_updates        | 7589     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 1744     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 82320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.07e+05 |\n",
      "|    n_updates        | 8079     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 1689     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 84280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.01e+04 |\n",
      "|    n_updates        | 8569     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 1642     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 86240    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.15e+04 |\n",
      "|    n_updates        | 9059     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 1599     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 88200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.94e+04 |\n",
      "|    n_updates        | 9549     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 1559     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 90160    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48e+05 |\n",
      "|    n_updates        | 10039    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 1523     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 92120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.7e+05  |\n",
      "|    n_updates        | 10529    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 1490     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 94080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.99e+04 |\n",
      "|    n_updates        | 11019    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 1461     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 96040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.63e+04 |\n",
      "|    n_updates        | 11509    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 1433     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 98000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.6e+04  |\n",
      "|    n_updates        | 11999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 1404     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 99960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.37e+04 |\n",
      "|    n_updates        | 12489    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 1378     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 101920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.26e+05 |\n",
      "|    n_updates        | 12979    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 1356     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 103880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.57e+04 |\n",
      "|    n_updates        | 13469    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 1336     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 105840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.47e+05 |\n",
      "|    n_updates        | 13959    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 1315     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 107800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.71e+04 |\n",
      "|    n_updates        | 14449    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 1296     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 109760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.95e+04 |\n",
      "|    n_updates        | 14939    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 1290     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 111720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.71e+04 |\n",
      "|    n_updates        | 15429    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 1285     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 113680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.55e+04 |\n",
      "|    n_updates        | 15919    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 1281     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 115640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.91e+04 |\n",
      "|    n_updates        | 16409    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 1276     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 117600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.35e+05 |\n",
      "|    n_updates        | 16899    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 1272     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 119560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.47e+04 |\n",
      "|    n_updates        | 17389    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 1268     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 121520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.24e+05 |\n",
      "|    n_updates        | 17879    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 1264     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 123480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.39e+05 |\n",
      "|    n_updates        | 18369    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 1260     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 125440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.55e+05 |\n",
      "|    n_updates        | 18859    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 1257     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 127400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.42e+05 |\n",
      "|    n_updates        | 19349    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 1253     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 129360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27e+05 |\n",
      "|    n_updates        | 19839    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 1251     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 131320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.89e+05 |\n",
      "|    n_updates        | 20329    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 1248     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 133280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.89e+05 |\n",
      "|    n_updates        | 20819    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 1246     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 135240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.39e+05 |\n",
      "|    n_updates        | 21309    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 1243     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 137200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.77e+05 |\n",
      "|    n_updates        | 21799    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 1241     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 139160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.63e+05 |\n",
      "|    n_updates        | 22289    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 1239     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 141120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48e+05 |\n",
      "|    n_updates        | 22779    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 1236     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 143080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.17e+05 |\n",
      "|    n_updates        | 23269    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 1235     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 145040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.82e+05 |\n",
      "|    n_updates        | 23759    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 1232     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 147000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.36e+05 |\n",
      "|    n_updates        | 24249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 1230     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 148960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.47e+04 |\n",
      "|    n_updates        | 24739    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 1228     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 150920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57e+05 |\n",
      "|    n_updates        | 25229    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 1225     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 152880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01e+05 |\n",
      "|    n_updates        | 25719    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 1224     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 154840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13e+05 |\n",
      "|    n_updates        | 26209    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 1222     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 156800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.6e+05  |\n",
      "|    n_updates        | 26699    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 1220     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 158760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.45e+05 |\n",
      "|    n_updates        | 27189    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 1219     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 160720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.14e+05 |\n",
      "|    n_updates        | 27679    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 1217     |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 162680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.69e+05 |\n",
      "|    n_updates        | 28169    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 1215     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 164640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.6e+04  |\n",
      "|    n_updates        | 28659    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 1214     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 166600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.42e+05 |\n",
      "|    n_updates        | 29149    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 1213     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 168560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.36e+05 |\n",
      "|    n_updates        | 29639    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 1211     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 170520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.07e+05 |\n",
      "|    n_updates        | 30129    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 1210     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 172480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13e+05 |\n",
      "|    n_updates        | 30619    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 1208     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 174440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.14e+05 |\n",
      "|    n_updates        | 31109    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 1207     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 176400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.07e+05 |\n",
      "|    n_updates        | 31599    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 1205     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 178360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11e+05 |\n",
      "|    n_updates        | 32089    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 1203     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 180320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.3e+04  |\n",
      "|    n_updates        | 32579    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 1202     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 182280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.64e+05 |\n",
      "|    n_updates        | 33069    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 1201     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 184240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.31e+04 |\n",
      "|    n_updates        | 33559    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 1200     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 186200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23e+05 |\n",
      "|    n_updates        | 34049    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 1199     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 188160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.52e+04 |\n",
      "|    n_updates        | 34539    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 1198     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 190120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09e+05 |\n",
      "|    n_updates        | 35029    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 1197     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 192080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1e+05  |\n",
      "|    n_updates        | 35519    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 1196     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 194040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1e+05  |\n",
      "|    n_updates        | 36009    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 1195     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 196000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.85e+04 |\n",
      "|    n_updates        | 36499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 1195     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 197960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22e+05 |\n",
      "|    n_updates        | 36989    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 1194     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 199920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.77e+04 |\n",
      "|    n_updates        | 37479    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 1193     |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 201880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01e+05 |\n",
      "|    n_updates        | 37969    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 1192     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 203840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.81e+05 |\n",
      "|    n_updates        | 38459    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 1191     |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 205800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.26e+05 |\n",
      "|    n_updates        | 38949    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 1190     |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 207760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.63e+04 |\n",
      "|    n_updates        | 39439    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 1189     |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 209720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03e+05 |\n",
      "|    n_updates        | 39929    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 1188     |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 211680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.74e+04 |\n",
      "|    n_updates        | 40419    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 1188     |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 213640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.26e+05 |\n",
      "|    n_updates        | 40909    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 1186     |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 215600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.17e+04 |\n",
      "|    n_updates        | 41399    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 1186     |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 217560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.96e+04 |\n",
      "|    n_updates        | 41889    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 1185     |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 219520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.18e+04 |\n",
      "|    n_updates        | 42379    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 1184     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 221480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.9e+04  |\n",
      "|    n_updates        | 42869    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 1184     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 223440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.15e+05 |\n",
      "|    n_updates        | 43359    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 1183     |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 225400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.1e+04  |\n",
      "|    n_updates        | 43849    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 1182     |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 227360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.94e+04 |\n",
      "|    n_updates        | 44339    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 1181     |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 229320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.73e+04 |\n",
      "|    n_updates        | 44829    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 1179     |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 231280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.81e+04 |\n",
      "|    n_updates        | 45319    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 1178     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 233240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.07e+05 |\n",
      "|    n_updates        | 45809    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 1177     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 235200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.79e+05 |\n",
      "|    n_updates        | 46299    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 1177     |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 237160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.32e+04 |\n",
      "|    n_updates        | 46789    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 1176     |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 239120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.1e+04  |\n",
      "|    n_updates        | 47279    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 1176     |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 241080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.98e+04 |\n",
      "|    n_updates        | 47769    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 1175     |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 243040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.06e+05 |\n",
      "|    n_updates        | 48259    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 1174     |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 245000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.89e+04 |\n",
      "|    n_updates        | 48749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 1174     |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 246960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.47e+04 |\n",
      "|    n_updates        | 49239    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 1173     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 248920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.5e+04  |\n",
      "|    n_updates        | 49729    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 1173     |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 250880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.67e+04 |\n",
      "|    n_updates        | 50219    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 1172     |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 252840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.98e+04 |\n",
      "|    n_updates        | 50709    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 1172     |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 254800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.16e+04 |\n",
      "|    n_updates        | 51199    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 1172     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 256760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.93e+04 |\n",
      "|    n_updates        | 51689    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 1171     |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 258720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.93e+04 |\n",
      "|    n_updates        | 52179    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 1170     |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 260680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.18e+04 |\n",
      "|    n_updates        | 52669    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 1169     |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 262640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.71e+04 |\n",
      "|    n_updates        | 53159    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 1169     |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 264600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.29e+04 |\n",
      "|    n_updates        | 53649    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 1168     |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 266560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.73e+04 |\n",
      "|    n_updates        | 54139    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 1167     |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 268520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.23e+04 |\n",
      "|    n_updates        | 54629    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 1167     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 270480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.73e+04 |\n",
      "|    n_updates        | 55119    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 1166     |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 272440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.38e+04 |\n",
      "|    n_updates        | 55609    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 1165     |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 274400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.87e+04 |\n",
      "|    n_updates        | 56099    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 1163     |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 276360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.23e+04 |\n",
      "|    n_updates        | 56589    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 1159     |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 278320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.47e+04 |\n",
      "|    n_updates        | 57079    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 1154     |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 280280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.63e+04 |\n",
      "|    n_updates        | 57569    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 1150     |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 282240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.21e+04 |\n",
      "|    n_updates        | 58059    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 1146     |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 284200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.45e+05 |\n",
      "|    n_updates        | 58549    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 1142     |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 286160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.45e+04 |\n",
      "|    n_updates        | 59039    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 1138     |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 288120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.83e+04 |\n",
      "|    n_updates        | 59529    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 1133     |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 290080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.06e+05 |\n",
      "|    n_updates        | 60019    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 1129     |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 292040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.56e+04 |\n",
      "|    n_updates        | 60509    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 1125     |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 294000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.38e+04 |\n",
      "|    n_updates        | 60999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 1121     |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 295960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.46e+04 |\n",
      "|    n_updates        | 61489    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 1117     |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 297920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.07e+05 |\n",
      "|    n_updates        | 61979    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 1114     |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 299880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.27e+04 |\n",
      "|    n_updates        | 62469    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 1110     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 301840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09e+05 |\n",
      "|    n_updates        | 62959    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 1106     |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 303800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.02e+04 |\n",
      "|    n_updates        | 63449    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 1103     |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 305760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.63e+04 |\n",
      "|    n_updates        | 63939    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 1100     |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total_timesteps  | 307720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.42e+04 |\n",
      "|    n_updates        | 64429    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 1096     |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 309680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.89e+04 |\n",
      "|    n_updates        | 64919    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 1093     |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total_timesteps  | 311640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.76e+04 |\n",
      "|    n_updates        | 65409    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 1089     |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 313600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.15e+04 |\n",
      "|    n_updates        | 65899    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 1085     |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 315560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.26e+05 |\n",
      "|    n_updates        | 66389    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 1082     |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 317520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.2e+04  |\n",
      "|    n_updates        | 66879    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 1079     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 319480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.97e+05 |\n",
      "|    n_updates        | 67369    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 1076     |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total_timesteps  | 321440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.06e+05 |\n",
      "|    n_updates        | 67859    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 1073     |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 323400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.13e+04 |\n",
      "|    n_updates        | 68349    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 1070     |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 325360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.55e+04 |\n",
      "|    n_updates        | 68839    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 1067     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 327320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.26e+04 |\n",
      "|    n_updates        | 69329    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 1064     |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 329280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.19e+04 |\n",
      "|    n_updates        | 69819    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 1062     |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 331240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.34e+04 |\n",
      "|    n_updates        | 70309    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 1059     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 333200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.13e+04 |\n",
      "|    n_updates        | 70799    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 1057     |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total_timesteps  | 335160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.36e+05 |\n",
      "|    n_updates        | 71289    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 1054     |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 337120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.35e+04 |\n",
      "|    n_updates        | 71779    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 1051     |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 339080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.92e+04 |\n",
      "|    n_updates        | 72269    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 1048     |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 341040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.57e+04 |\n",
      "|    n_updates        | 72759    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 1045     |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 343000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.81e+04 |\n",
      "|    n_updates        | 73249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 1042     |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total_timesteps  | 344960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.02e+04 |\n",
      "|    n_updates        | 73739    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 1040     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 346920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.33e+04 |\n",
      "|    n_updates        | 74229    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 1037     |\n",
      "|    time_elapsed     | 336      |\n",
      "|    total_timesteps  | 348880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.84e+04 |\n",
      "|    n_updates        | 74719    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 1035     |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 350840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.46e+04 |\n",
      "|    n_updates        | 75209    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 1032     |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 352800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.04e+04 |\n",
      "|    n_updates        | 75699    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 1030     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 354760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.56e+04 |\n",
      "|    n_updates        | 76189    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 1028     |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 356720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.46e+04 |\n",
      "|    n_updates        | 76679    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 1026     |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 358680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.9e+04  |\n",
      "|    n_updates        | 77169    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 1024     |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 360640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.4e+04  |\n",
      "|    n_updates        | 77659    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 1021     |\n",
      "|    time_elapsed     | 354      |\n",
      "|    total_timesteps  | 362600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.05e+05 |\n",
      "|    n_updates        | 78149    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 1020     |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total_timesteps  | 364560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.46e+04 |\n",
      "|    n_updates        | 78639    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 1018     |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total_timesteps  | 366520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.73e+04 |\n",
      "|    n_updates        | 79129    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 1015     |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total_timesteps  | 368480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.28e+05 |\n",
      "|    n_updates        | 79619    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 1013     |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total_timesteps  | 370440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.05e+04 |\n",
      "|    n_updates        | 80109    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 1011     |\n",
      "|    time_elapsed     | 368      |\n",
      "|    total_timesteps  | 372400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.55e+04 |\n",
      "|    n_updates        | 80599    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 1009     |\n",
      "|    time_elapsed     | 370      |\n",
      "|    total_timesteps  | 374360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04e+05 |\n",
      "|    n_updates        | 81089    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 1007     |\n",
      "|    time_elapsed     | 373      |\n",
      "|    total_timesteps  | 376320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.66e+04 |\n",
      "|    n_updates        | 81579    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 1005     |\n",
      "|    time_elapsed     | 376      |\n",
      "|    total_timesteps  | 378280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.44e+05 |\n",
      "|    n_updates        | 82069    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 1004     |\n",
      "|    time_elapsed     | 378      |\n",
      "|    total_timesteps  | 380240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.96e+04 |\n",
      "|    n_updates        | 82559    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 1002     |\n",
      "|    time_elapsed     | 381      |\n",
      "|    total_timesteps  | 382200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.89e+04 |\n",
      "|    n_updates        | 83049    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 1000     |\n",
      "|    time_elapsed     | 384      |\n",
      "|    total_timesteps  | 384160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.8e+04  |\n",
      "|    n_updates        | 83539    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 998      |\n",
      "|    time_elapsed     | 386      |\n",
      "|    total_timesteps  | 386120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.65e+05 |\n",
      "|    n_updates        | 84029    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 997      |\n",
      "|    time_elapsed     | 389      |\n",
      "|    total_timesteps  | 388080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.48e+04 |\n",
      "|    n_updates        | 84519    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 995      |\n",
      "|    time_elapsed     | 391      |\n",
      "|    total_timesteps  | 390040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17e+05 |\n",
      "|    n_updates        | 85009    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 993      |\n",
      "|    time_elapsed     | 394      |\n",
      "|    total_timesteps  | 392000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.18e+04 |\n",
      "|    n_updates        | 85499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 991      |\n",
      "|    time_elapsed     | 397      |\n",
      "|    total_timesteps  | 393960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.69e+04 |\n",
      "|    n_updates        | 85989    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 990      |\n",
      "|    time_elapsed     | 399      |\n",
      "|    total_timesteps  | 395920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.9e+04  |\n",
      "|    n_updates        | 86479    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 988      |\n",
      "|    time_elapsed     | 402      |\n",
      "|    total_timesteps  | 397880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.95e+04 |\n",
      "|    n_updates        | 86969    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 986      |\n",
      "|    time_elapsed     | 405      |\n",
      "|    total_timesteps  | 399840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.8e+05  |\n",
      "|    n_updates        | 87459    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 985      |\n",
      "|    time_elapsed     | 407      |\n",
      "|    total_timesteps  | 401800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.33e+04 |\n",
      "|    n_updates        | 87949    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 983      |\n",
      "|    time_elapsed     | 410      |\n",
      "|    total_timesteps  | 403760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.13e+04 |\n",
      "|    n_updates        | 88439    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 981      |\n",
      "|    time_elapsed     | 413      |\n",
      "|    total_timesteps  | 405720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09e+05 |\n",
      "|    n_updates        | 88929    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 980      |\n",
      "|    time_elapsed     | 415      |\n",
      "|    total_timesteps  | 407680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.35e+04 |\n",
      "|    n_updates        | 89419    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 978      |\n",
      "|    time_elapsed     | 418      |\n",
      "|    total_timesteps  | 409640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.84e+04 |\n",
      "|    n_updates        | 89909    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 976      |\n",
      "|    time_elapsed     | 421      |\n",
      "|    total_timesteps  | 411600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.99e+04 |\n",
      "|    n_updates        | 90399    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 974      |\n",
      "|    time_elapsed     | 424      |\n",
      "|    total_timesteps  | 413560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.8e+04  |\n",
      "|    n_updates        | 90889    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 972      |\n",
      "|    time_elapsed     | 427      |\n",
      "|    total_timesteps  | 415520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.55e+04 |\n",
      "|    n_updates        | 91379    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 971      |\n",
      "|    time_elapsed     | 429      |\n",
      "|    total_timesteps  | 417480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.7e+04  |\n",
      "|    n_updates        | 91869    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 970      |\n",
      "|    time_elapsed     | 432      |\n",
      "|    total_timesteps  | 419440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.05e+05 |\n",
      "|    n_updates        | 92359    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 968      |\n",
      "|    time_elapsed     | 435      |\n",
      "|    total_timesteps  | 421400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.09e+04 |\n",
      "|    n_updates        | 92849    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 437      |\n",
      "|    total_timesteps  | 423360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.65e+04 |\n",
      "|    n_updates        | 93339    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 440      |\n",
      "|    total_timesteps  | 425320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.63e+04 |\n",
      "|    n_updates        | 93829    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 443      |\n",
      "|    total_timesteps  | 427280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.04e+04 |\n",
      "|    n_updates        | 94319    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 446      |\n",
      "|    total_timesteps  | 429240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.37e+04 |\n",
      "|    n_updates        | 94809    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 448      |\n",
      "|    total_timesteps  | 431200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.72e+04 |\n",
      "|    n_updates        | 95299    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 451      |\n",
      "|    total_timesteps  | 433160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.73e+04 |\n",
      "|    n_updates        | 95789    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 454      |\n",
      "|    total_timesteps  | 435120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.78e+04 |\n",
      "|    n_updates        | 96279    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 456      |\n",
      "|    total_timesteps  | 437080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.06e+04 |\n",
      "|    n_updates        | 96769    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 459      |\n",
      "|    total_timesteps  | 439040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.62e+04 |\n",
      "|    n_updates        | 97259    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 954      |\n",
      "|    time_elapsed     | 461      |\n",
      "|    total_timesteps  | 441000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.11e+04 |\n",
      "|    n_updates        | 97749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 953      |\n",
      "|    time_elapsed     | 464      |\n",
      "|    total_timesteps  | 442960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.9e+04  |\n",
      "|    n_updates        | 98239    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 466      |\n",
      "|    total_timesteps  | 444920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.55e+04 |\n",
      "|    n_updates        | 98729    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 469      |\n",
      "|    total_timesteps  | 446880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.35e+04 |\n",
      "|    n_updates        | 99219    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 472      |\n",
      "|    total_timesteps  | 448840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.95e+04 |\n",
      "|    n_updates        | 99709    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 474      |\n",
      "|    total_timesteps  | 450800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.75e+04 |\n",
      "|    n_updates        | 100199   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 476      |\n",
      "|    total_timesteps  | 452760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.33e+04 |\n",
      "|    n_updates        | 100689   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 948      |\n",
      "|    time_elapsed     | 479      |\n",
      "|    total_timesteps  | 454720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.12e+04 |\n",
      "|    n_updates        | 101179   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 945      |\n",
      "|    time_elapsed     | 483      |\n",
      "|    total_timesteps  | 456680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.77e+05 |\n",
      "|    n_updates        | 101669   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 942      |\n",
      "|    time_elapsed     | 486      |\n",
      "|    total_timesteps  | 458640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.15e+04 |\n",
      "|    n_updates        | 102159   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 939      |\n",
      "|    time_elapsed     | 490      |\n",
      "|    total_timesteps  | 460600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.51e+05 |\n",
      "|    n_updates        | 102649   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 936      |\n",
      "|    time_elapsed     | 494      |\n",
      "|    total_timesteps  | 462560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.22e+04 |\n",
      "|    n_updates        | 103139   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 933      |\n",
      "|    time_elapsed     | 497      |\n",
      "|    total_timesteps  | 464520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.06e+04 |\n",
      "|    n_updates        | 103629   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 930      |\n",
      "|    time_elapsed     | 501      |\n",
      "|    total_timesteps  | 466480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.53e+04 |\n",
      "|    n_updates        | 104119   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 928      |\n",
      "|    time_elapsed     | 504      |\n",
      "|    total_timesteps  | 468440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.28e+04 |\n",
      "|    n_updates        | 104609   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 925      |\n",
      "|    time_elapsed     | 508      |\n",
      "|    total_timesteps  | 470400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.22e+04 |\n",
      "|    n_updates        | 105099   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 922      |\n",
      "|    time_elapsed     | 511      |\n",
      "|    total_timesteps  | 472360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.33e+04 |\n",
      "|    n_updates        | 105589   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 920      |\n",
      "|    time_elapsed     | 515      |\n",
      "|    total_timesteps  | 474320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.85e+04 |\n",
      "|    n_updates        | 106079   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 917      |\n",
      "|    time_elapsed     | 518      |\n",
      "|    total_timesteps  | 476280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.56e+04 |\n",
      "|    n_updates        | 106569   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 916      |\n",
      "|    time_elapsed     | 521      |\n",
      "|    total_timesteps  | 478240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.97e+04 |\n",
      "|    n_updates        | 107059   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 915      |\n",
      "|    time_elapsed     | 524      |\n",
      "|    total_timesteps  | 480200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.08e+04 |\n",
      "|    n_updates        | 107549   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 913      |\n",
      "|    time_elapsed     | 528      |\n",
      "|    total_timesteps  | 482160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.92e+04 |\n",
      "|    n_updates        | 108039   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 912      |\n",
      "|    time_elapsed     | 530      |\n",
      "|    total_timesteps  | 484120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.67e+04 |\n",
      "|    n_updates        | 108529   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 910      |\n",
      "|    time_elapsed     | 533      |\n",
      "|    total_timesteps  | 486080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.67e+04 |\n",
      "|    n_updates        | 109019   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 909      |\n",
      "|    time_elapsed     | 536      |\n",
      "|    total_timesteps  | 488040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.55e+04 |\n",
      "|    n_updates        | 109509   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 909      |\n",
      "|    time_elapsed     | 539      |\n",
      "|    total_timesteps  | 490000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.27e+04 |\n",
      "|    n_updates        | 109999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 907      |\n",
      "|    time_elapsed     | 541      |\n",
      "|    total_timesteps  | 491960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.7e+04  |\n",
      "|    n_updates        | 110489   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 906      |\n",
      "|    time_elapsed     | 544      |\n",
      "|    total_timesteps  | 493920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.78e+04 |\n",
      "|    n_updates        | 110979   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 906      |\n",
      "|    time_elapsed     | 547      |\n",
      "|    total_timesteps  | 495880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.96e+04 |\n",
      "|    n_updates        | 111469   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 549      |\n",
      "|    total_timesteps  | 497840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.36e+04 |\n",
      "|    n_updates        | 111959   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 904      |\n",
      "|    time_elapsed     | 552      |\n",
      "|    total_timesteps  | 499800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.29e+05 |\n",
      "|    n_updates        | 112449   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 903      |\n",
      "|    time_elapsed     | 555      |\n",
      "|    total_timesteps  | 501760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.08e+04 |\n",
      "|    n_updates        | 112939   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 902      |\n",
      "|    time_elapsed     | 558      |\n",
      "|    total_timesteps  | 503720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.33e+04 |\n",
      "|    n_updates        | 113429   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 901      |\n",
      "|    time_elapsed     | 560      |\n",
      "|    total_timesteps  | 505680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.53e+04 |\n",
      "|    n_updates        | 113919   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 900      |\n",
      "|    time_elapsed     | 563      |\n",
      "|    total_timesteps  | 507640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.68e+04 |\n",
      "|    n_updates        | 114409   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 566      |\n",
      "|    total_timesteps  | 509600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.73e+04 |\n",
      "|    n_updates        | 114899   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 569      |\n",
      "|    total_timesteps  | 511560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.51e+04 |\n",
      "|    n_updates        | 115389   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 898      |\n",
      "|    time_elapsed     | 571      |\n",
      "|    total_timesteps  | 513520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.96e+04 |\n",
      "|    n_updates        | 115879   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1052     |\n",
      "|    fps              | 897      |\n",
      "|    time_elapsed     | 574      |\n",
      "|    total_timesteps  | 515480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.65e+04 |\n",
      "|    n_updates        | 116369   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1056     |\n",
      "|    fps              | 896      |\n",
      "|    time_elapsed     | 576      |\n",
      "|    total_timesteps  | 517440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.34e+04 |\n",
      "|    n_updates        | 116859   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 896      |\n",
      "|    time_elapsed     | 579      |\n",
      "|    total_timesteps  | 519400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.32e+04 |\n",
      "|    n_updates        | 117349   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1064     |\n",
      "|    fps              | 895      |\n",
      "|    time_elapsed     | 582      |\n",
      "|    total_timesteps  | 521360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.4e+05  |\n",
      "|    n_updates        | 117839   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1068     |\n",
      "|    fps              | 894      |\n",
      "|    time_elapsed     | 585      |\n",
      "|    total_timesteps  | 523320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.82e+04 |\n",
      "|    n_updates        | 118329   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1072     |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 588      |\n",
      "|    total_timesteps  | 525280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.03e+04 |\n",
      "|    n_updates        | 118819   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1076     |\n",
      "|    fps              | 892      |\n",
      "|    time_elapsed     | 590      |\n",
      "|    total_timesteps  | 527240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.71e+04 |\n",
      "|    n_updates        | 119309   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 891      |\n",
      "|    time_elapsed     | 593      |\n",
      "|    total_timesteps  | 529200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.56e+04 |\n",
      "|    n_updates        | 119799   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1084     |\n",
      "|    fps              | 891      |\n",
      "|    time_elapsed     | 596      |\n",
      "|    total_timesteps  | 531160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11e+05 |\n",
      "|    n_updates        | 120289   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1088     |\n",
      "|    fps              | 890      |\n",
      "|    time_elapsed     | 598      |\n",
      "|    total_timesteps  | 533120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8e+04    |\n",
      "|    n_updates        | 120779   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1092     |\n",
      "|    fps              | 889      |\n",
      "|    time_elapsed     | 601      |\n",
      "|    total_timesteps  | 535080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.44e+04 |\n",
      "|    n_updates        | 121269   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1096     |\n",
      "|    fps              | 888      |\n",
      "|    time_elapsed     | 604      |\n",
      "|    total_timesteps  | 537040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.34e+04 |\n",
      "|    n_updates        | 121759   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 887      |\n",
      "|    time_elapsed     | 606      |\n",
      "|    total_timesteps  | 539000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.48e+04 |\n",
      "|    n_updates        | 122249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1104     |\n",
      "|    fps              | 887      |\n",
      "|    time_elapsed     | 609      |\n",
      "|    total_timesteps  | 540960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.95e+04 |\n",
      "|    n_updates        | 122739   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1108     |\n",
      "|    fps              | 886      |\n",
      "|    time_elapsed     | 612      |\n",
      "|    total_timesteps  | 542920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.75e+04 |\n",
      "|    n_updates        | 123229   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1112     |\n",
      "|    fps              | 885      |\n",
      "|    time_elapsed     | 615      |\n",
      "|    total_timesteps  | 544880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.85e+05 |\n",
      "|    n_updates        | 123719   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1116     |\n",
      "|    fps              | 885      |\n",
      "|    time_elapsed     | 617      |\n",
      "|    total_timesteps  | 546840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.15e+04 |\n",
      "|    n_updates        | 124209   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 884      |\n",
      "|    time_elapsed     | 620      |\n",
      "|    total_timesteps  | 548800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.71e+04 |\n",
      "|    n_updates        | 124699   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1124     |\n",
      "|    fps              | 883      |\n",
      "|    time_elapsed     | 623      |\n",
      "|    total_timesteps  | 550760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.92e+05 |\n",
      "|    n_updates        | 125189   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1128     |\n",
      "|    fps              | 882      |\n",
      "|    time_elapsed     | 625      |\n",
      "|    total_timesteps  | 552720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.54e+04 |\n",
      "|    n_updates        | 125679   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1132     |\n",
      "|    fps              | 882      |\n",
      "|    time_elapsed     | 628      |\n",
      "|    total_timesteps  | 554680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.5e+05  |\n",
      "|    n_updates        | 126169   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1136     |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 631      |\n",
      "|    total_timesteps  | 556640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.63e+04 |\n",
      "|    n_updates        | 126659   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 880      |\n",
      "|    time_elapsed     | 634      |\n",
      "|    total_timesteps  | 558600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23e+05 |\n",
      "|    n_updates        | 127149   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1144     |\n",
      "|    fps              | 880      |\n",
      "|    time_elapsed     | 636      |\n",
      "|    total_timesteps  | 560560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.08e+05 |\n",
      "|    n_updates        | 127639   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1148     |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 639      |\n",
      "|    total_timesteps  | 562520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.14e+04 |\n",
      "|    n_updates        | 128129   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1152     |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 642      |\n",
      "|    total_timesteps  | 564480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.34e+04 |\n",
      "|    n_updates        | 128619   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1156     |\n",
      "|    fps              | 878      |\n",
      "|    time_elapsed     | 644      |\n",
      "|    total_timesteps  | 566440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.89e+04 |\n",
      "|    n_updates        | 129109   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 877      |\n",
      "|    time_elapsed     | 647      |\n",
      "|    total_timesteps  | 568400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.31e+04 |\n",
      "|    n_updates        | 129599   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1164     |\n",
      "|    fps              | 877      |\n",
      "|    time_elapsed     | 650      |\n",
      "|    total_timesteps  | 570360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.06e+04 |\n",
      "|    n_updates        | 130089   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1168     |\n",
      "|    fps              | 876      |\n",
      "|    time_elapsed     | 653      |\n",
      "|    total_timesteps  | 572320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.45e+04 |\n",
      "|    n_updates        | 130579   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1172     |\n",
      "|    fps              | 875      |\n",
      "|    time_elapsed     | 655      |\n",
      "|    total_timesteps  | 574280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.72e+04 |\n",
      "|    n_updates        | 131069   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1176     |\n",
      "|    fps              | 874      |\n",
      "|    time_elapsed     | 658      |\n",
      "|    total_timesteps  | 576240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.94e+04 |\n",
      "|    n_updates        | 131559   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 874      |\n",
      "|    time_elapsed     | 661      |\n",
      "|    total_timesteps  | 578200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.08e+04 |\n",
      "|    n_updates        | 132049   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1184     |\n",
      "|    fps              | 873      |\n",
      "|    time_elapsed     | 664      |\n",
      "|    total_timesteps  | 580160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.22e+04 |\n",
      "|    n_updates        | 132539   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1188     |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 666      |\n",
      "|    total_timesteps  | 582120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.16e+05 |\n",
      "|    n_updates        | 133029   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1192     |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 669      |\n",
      "|    total_timesteps  | 584080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.8e+04  |\n",
      "|    n_updates        | 133519   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1196     |\n",
      "|    fps              | 871      |\n",
      "|    time_elapsed     | 672      |\n",
      "|    total_timesteps  | 586040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.61e+04 |\n",
      "|    n_updates        | 134009   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 871      |\n",
      "|    time_elapsed     | 674      |\n",
      "|    total_timesteps  | 588000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.98e+04 |\n",
      "|    n_updates        | 134499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1204     |\n",
      "|    fps              | 870      |\n",
      "|    time_elapsed     | 677      |\n",
      "|    total_timesteps  | 589960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.96e+04 |\n",
      "|    n_updates        | 134989   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1208     |\n",
      "|    fps              | 869      |\n",
      "|    time_elapsed     | 680      |\n",
      "|    total_timesteps  | 591920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.1e+04  |\n",
      "|    n_updates        | 135479   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1212     |\n",
      "|    fps              | 869      |\n",
      "|    time_elapsed     | 683      |\n",
      "|    total_timesteps  | 593880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.12e+04 |\n",
      "|    n_updates        | 135969   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1216     |\n",
      "|    fps              | 868      |\n",
      "|    time_elapsed     | 686      |\n",
      "|    total_timesteps  | 595840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.33e+04 |\n",
      "|    n_updates        | 136459   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 867      |\n",
      "|    time_elapsed     | 688      |\n",
      "|    total_timesteps  | 597800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.62e+04 |\n",
      "|    n_updates        | 136949   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1224     |\n",
      "|    fps              | 867      |\n",
      "|    time_elapsed     | 691      |\n",
      "|    total_timesteps  | 599760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.06e+04 |\n",
      "|    n_updates        | 137439   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7fe88dfcca90>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=20, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "model = DQN('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=600000, callback=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1000, episode_reward=-0.50 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2000, episode_reward=0.30 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=3000, episode_reward=0.15 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Eval num_timesteps=4000, episode_reward=8.65 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=5000, episode_reward=1.00 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Eval num_timesteps=6000, episode_reward=-0.35 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Eval num_timesteps=7000, episode_reward=5.55 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Eval num_timesteps=8000, episode_reward=7.10 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Eval num_timesteps=9000, episode_reward=-1.10 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Eval num_timesteps=10000, episode_reward=-6.45 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Eval num_timesteps=11000, episode_reward=8.05 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Eval num_timesteps=12000, episode_reward=2.65 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Eval num_timesteps=13000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Eval num_timesteps=14000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Eval num_timesteps=15000, episode_reward=1.90 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Eval num_timesteps=16000, episode_reward=1.40 +/- 0.00\n",
      "Episode length: 490.00 +/- 0.00\n",
      "Stopping training because there was no new best model in the last 11 evaluations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_recurrent.ppo_recurrent.RecurrentPPO at 0x7fe8a812c0d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=10, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "model = RecurrentPPO('MlpLstmPolicy', env, verbose=0, ent_coef=0.1,batch_size = 64)\n",
    "model.learn(total_timesteps=800000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:71: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4000, episode_reward=-16.74 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=8000, episode_reward=-16.74 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=12000, episode_reward=-4.46 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=16000, episode_reward=-4.46 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=20000, episode_reward=-22.14 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=24000, episode_reward=-22.14 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=28000, episode_reward=-3.78 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=32000, episode_reward=-3.78 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=36000, episode_reward=-4.86 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=40000, episode_reward=-4.86 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=44000, episode_reward=-0.52 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=48000, episode_reward=-0.52 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=52000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=56000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=60000, episode_reward=0.06 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=64000, episode_reward=0.06 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=68000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=72000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=76000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=80000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=84000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=88000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=92000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=96000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=100000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=104000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=108000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=112000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=116000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=120000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=124000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=128000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=132000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=136000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=140000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Eval num_timesteps=144000, episode_reward=0.01 +/- 0.00\n",
      "Episode length: 989.00 +/- 0.00\n",
      "Stopping training because there was no new best model in the last 21 evaluations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.trpo.trpo.TRPO at 0x7fbdabbc7650>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=20, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "model = TRPO('MlpPolicy', env, verbose=0,learning_rate=0.0003)\n",
    "\n",
    "model.learn(total_timesteps=1000000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy  0.31739130434782614\n",
      "sell  0.3145962732919255\n",
      "buy  0.3164596273291925\n",
      "sell  0.3024844720496895\n",
      "buy  0.30341614906832304\n",
      "sell  0.291304347826087\n",
      "buy  0.28944099378881993\n",
      "sell  0.28944099378881993\n",
      "buy  0.2950310559006211\n",
      "sell  0.2875776397515528\n",
      "buy  0.28664596273291926\n",
      "sell  0.2857142857142857\n",
      "buy  0.29037267080745344\n",
      "sell  0.29037267080745344\n",
      "buy  0.2857142857142857\n",
      "sell  0.2857142857142857\n",
      "buy  0.28944099378881993\n",
      "sell  0.2829192546583851\n",
      "buy  0.2754658385093168\n",
      "sell  0.2829192546583851\n",
      "buy  0.29782608695652174\n",
      "sell  0.29782608695652174\n",
      "buy  0.3099378881987578\n",
      "sell  0.3285714285714286\n",
      "buy  0.3099378881987578\n",
      "sell  0.3201863354037267\n",
      "buy  0.3341614906832298\n",
      "sell  0.3341614906832298\n",
      "buy  0.3341614906832298\n",
      "sell  0.3397515527950311\n",
      "buy  0.3518633540372671\n",
      "sell  0.38540372670807455\n",
      "buy  0.372360248447205\n",
      "sell  0.37142857142857144\n",
      "buy  0.35000000000000003\n",
      "sell  0.3285714285714286\n",
      "buy  0.3490683229813665\n",
      "sell  0.35931677018633545\n",
      "buy  0.34627329192546585\n",
      "sell  0.3490683229813665\n",
      "buy  0.3704968944099379\n",
      "sell  0.36956521739130443\n",
      "buy  0.3770186335403727\n",
      "sell  0.3686335403726708\n",
      "buy  0.3826086956521739\n",
      "sell  0.40124223602484477\n",
      "buy  0.41521739130434787\n",
      "sell  0.3928571428571429\n",
      "buy  0.3826086956521739\n",
      "sell  0.33229813664596275\n",
      "buy  0.3397515527950311\n",
      "sell  0.3509316770186336\n",
      "buy  0.3509316770186336\n",
      "sell  0.3537267080745342\n",
      "buy  0.37515527950310557\n",
      "sell  0.37329192546583856\n",
      "buy  0.3742236024844721\n",
      "sell  0.38540372670807455\n",
      "buy  0.3909937888198758\n",
      "sell  0.39658385093167703\n",
      "buy  0.41149068322981375\n",
      "sell  0.4161490683229814\n",
      "buy  0.408695652173913\n",
      "sell  0.4124223602484472\n",
      "buy  0.43385093167701866\n",
      "sell  0.4198757763975156\n",
      "buy  0.406832298136646\n",
      "sell  0.4180124223602485\n",
      "buy  0.42360248447204973\n",
      "sell  0.4161490683229814\n",
      "buy  0.4198757763975156\n",
      "sell  0.42453416149068324\n",
      "buy  0.4180124223602485\n",
      "sell  0.4142857142857143\n",
      "buy  0.408695652173913\n",
      "sell  0.4198757763975156\n",
      "buy  0.41521739130434787\n",
      "sell  0.42360248447204973\n",
      "buy  0.4208074534161491\n",
      "sell  0.4077639751552795\n",
      "buy  0.4170807453416149\n",
      "sell  0.431055900621118\n",
      "buy  0.4180124223602485\n",
      "sell  0.39192546583850935\n",
      "buy  0.3807453416149068\n",
      "sell  0.36397515527950314\n",
      "buy  0.36118012422360246\n",
      "sell  0.3798136645962733\n",
      "buy  0.3807453416149068\n",
      "sell  0.37795031055900624\n",
      "buy  0.3770186335403727\n",
      "sell  0.3788819875776398\n",
      "buy  0.36770186335403726\n",
      "sell  0.360248447204969\n",
      "buy  0.360248447204969\n",
      "sell  0.3537267080745342\n",
      "buy  0.34161490683229817\n",
      "sell  0.34534161490683235\n",
      "buy  0.34813664596273297\n",
      "sell  0.34813664596273297\n",
      "buy  0.35838509316770184\n",
      "sell  0.3546583850931677\n",
      "buy  0.3621118012422361\n",
      "sell  0.36397515527950314\n",
      "buy  0.3630434782608696\n",
      "sell  0.36118012422360246\n",
      "buy  0.35745341614906834\n",
      "sell  0.34347826086956523\n",
      "buy  0.3490683229813665\n",
      "sell  0.3537267080745342\n",
      "buy  0.3490683229813665\n",
      "sell  0.3537267080745342\n",
      "buy  0.3527950310559006\n",
      "sell  0.35000000000000003\n",
      "buy  0.3527950310559006\n",
      "sell  0.3555900621118013\n",
      "buy  0.3555900621118013\n",
      "sell  0.3565217391304348\n",
      "buy  0.36397515527950314\n",
      "info {'total_reward': -6.211246298864404, 'total_profit': 0.6104893513719851, 'position': 1}\n",
      "[-0.008806262230919763, -0.04416094210009796, -0.03991811668372574, 0.0, -0.025263157894736776, -0.003250270855904723, 0.0, 0.0, -0.022532188841201967, 0.02705749718151064, 0.0, 0.06012024048096203, 0.033066132264528994, 0.0, 0.01672862453531615, 0.09532215357458075, -0.0025020850708924597, -0.061224489795918303, 0.02935943060498231, 0.008071748878923765, -0.002514668901927663, -0.022240527182866555, 0.048701298701298794, -0.053851907255048605, -0.13149350649350647, 0.03290676416819012, 0.007964601769911503, -0.0049668874172183455, 0.029875518672199012, 0.014297061159650515, 0.01132075471698095, 0.009118541033434695, -0.03221188260558326, 0.027480916030534347, -0.017595307917888648, 0.011094674556212838, -0.008915304606240756, 0.027355623100304222, 0.020194465220643228, -0.030996309963099714, 0.03350707371556217, -0.06240713224368502, -0.04404567699836853, 0.05159071367153922, -0.007340946166394633, 0.004942339373970444, -0.020270270270270067, -0.018103448275862116, 0.01090909090909096, 0.0, -0.01039861351819747, 0.005145797598627735, -0.005132591958939366, -0.03909643788010425, 0.013345195729537471, 0.013345195729537471, -0.007922535211267448, 0.007922535211267763, 0.002620087336244437]\n",
      "59\n",
      "-0.03715325466119315\n",
      "-1.7347155084676626\n"
     ]
    }
   ],
   "source": [
    "#env_val = gym.make('stocks-v0', df=df, frame_bound=(400,420), window_size=5)\n",
    "#mid = int((val_start_idx+1+val_end_idx+1)/2)\n",
    "#env_val2 = MyCustomEnv(df=df, frame_bound=(val_start_idx,val_start_idx+30), window_size=12)\n",
    "env_val2 = StocksEnv2(df=df, frame_bound=(val_start_idx,val_end_idx), window_size=20)\n",
    "obs_val = env_val2.reset()\n",
    "\n",
    "#obs_val = env_val2.reset()\n",
    "sharpe ,sortino = DRL_validation(df=df,model=model,test_env=env_val2, test_obs=obs_val)\n",
    "\n",
    "print(sharpe)\n",
    "print(sortino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "env_val2.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awinlab/anaconda3/envs/stock/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:71: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -0.2685671248473227 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "info {'total_reward': 0.0, 'total_profit': 1.0399104579207923, 'position': 1}\n"
     ]
    }
   ],
   "source": [
    "env = MyCustomEnv(df=df, window_size=20, frame_bound=(val_start_idx,val_end_idx))\n",
    "obs = env.reset()\n",
    "while True: \n",
    "    obs = obs[np.newaxis, ...]\n",
    "    action, _states = model.predict(obs)\n",
    "    print(action)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    if done:\n",
    "        print(\"info\", info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stock_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-36d9493cd35a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2021-12-31'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m df2 = api.taiwan_stock_daily(\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mstock_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mstart_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stock_id' is not defined"
     ]
    }
   ],
   "source": [
    "start_date='2020-12-4'\n",
    "end_date='2021-12-31'\n",
    "df2 = api.taiwan_stock_daily(\n",
    "            stock_id = stock_id,\n",
    "            start_date = start_date,\n",
    "            end_date = end_date\n",
    ")\n",
    "print(df2[:50])\n",
    "df2 = df2.iloc[:][['date','open', 'max', 'min', 'close','Trading_Volume']]\n",
    "\n",
    "df2['date'] = pd.to_datetime(df2['date'])\n",
    "\n",
    "\n",
    "df2.rename(columns = {'date':'Date', 'open':'Open','max':'Max','min':'Min', 'close':'Close','Trading_Volume':'Volume'}, inplace = True)\n",
    "df2.set_index('Date', inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525\n",
      "774\n",
      "info {'total_reward': 0.007963334533939721, 'total_profit': 0.4942796283119741, 'position': 1}\n",
      "[0.02, -0.03599999999999994, 0.0, 0.055999999999999946, 0.08, 0.027999999999999973, 0.055999999999999946, 0.06400000000000006, -0.04400000000000006, -0.12, -0.16, -0.15599999999999994, -0.11200000000000003, -0.07200000000000002, -0.07599999999999994, -0.06799999999999998, -0.06, -0.07200000000000002, -0.2, -0.13200000000000003, -0.027999999999999973, 0.03200000000000003, 0.007999999999999972, 0.04, -0.024000000000000056, -0.055999999999999946, -0.027999999999999973, -0.03200000000000003, 0.06400000000000006, 0.03200000000000003, -0.03599999999999994, -0.055999999999999946, -0.04, -0.16400000000000006, -0.18, -0.11200000000000003, -0.08, -0.024000000000000056, -0.0040000000000000565, -0.04400000000000006, -0.03599999999999994, 0.012000000000000028, 0.0040000000000000565, 0.0040000000000000565, 0.04400000000000006, 0.055999999999999946, 0.03200000000000003, 0.02, 0.04, -0.024000000000000056, -0.024000000000000056, 0.0040000000000000565, 0.015999999999999945, -0.06, -0.055999999999999946, -0.02, -0.09599999999999995, -0.07200000000000002, -0.06400000000000006, -0.10799999999999997, -0.09599999999999995, -0.1, -0.06, -0.055999999999999946, -0.06400000000000006, -0.07200000000000002, -0.06799999999999998, -0.052000000000000025, -0.06400000000000006, -0.08799999999999997, -0.1, -0.07200000000000002, -0.02, -0.024000000000000056, 0.06, 0.18, 0.15599999999999994, 0.13599999999999995, 0.18, 0.18, 0.23200000000000004, 0.20400000000000007, 0.16, 0.16400000000000006, 0.12400000000000005, 0.12, 0.15200000000000002, 0.1, 0.06799999999999998, 0.16, 0.12, 0.13599999999999995, 0.15599999999999994, 0.18400000000000005, 0.16400000000000006, 0.16799999999999998]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#env_maker = lambda: gym.make('stocks-v0', df=df, frame_bound=(20,len(df)), window_size=20)\n",
    "print(val_start_idx)\n",
    "print(val_end_idx+1)\n",
    "#env = gym.make('stocks-v0', df=df, frame_bound=(val_start_idx,val_end_idx+1), window_size=20)\n",
    "env = MyCustomEnv(df=df, frame_bound=(val_start_idx+1,val_end_idx+1), window_size=5)\n",
    "action_list = []\n",
    "return_list = []\n",
    "hold = 0\n",
    "obs = env.reset()\n",
    "while True: \n",
    "    obs = obs[np.newaxis, ...]\n",
    "    #print(obs)\n",
    "    price = obs[0][-1][0]\n",
    "    #print(price)\n",
    "    action, _states = model.predict(obs)\n",
    "    if action[0] == 1:\n",
    "            if hold == 0:\n",
    "                buy_price = price\n",
    "                hold = 1\n",
    "    elif action[0] == 0:\n",
    "            if hold == 1:\n",
    "                return_list.append((price-buy_price)/buy_price)\n",
    "                hold = 1\n",
    "    action_list.append(action[0])\n",
    "    #print(action)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    if done:\n",
    "        print(\"info\", info)\n",
    "        break\n",
    "print(return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[67. ,  0.5],\n",
       "       [65. , -2. ],\n",
       "       [63.5, -1.5],\n",
       "       [64.5,  1. ],\n",
       "       [62. , -2.5],\n",
       "       [62.5,  0.5],\n",
       "       [62. , -0.5],\n",
       "       [63. ,  1. ],\n",
       "       [61. , -2. ],\n",
       "       [59.5, -1.5],\n",
       "       [60. ,  0.5],\n",
       "       [60. ,  0. ],\n",
       "       [61.5,  1.5],\n",
       "       [62. ,  0.5],\n",
       "       [61.5, -0.5],\n",
       "       [62. ,  0.5],\n",
       "       [62. ,  0. ],\n",
       "       [62. ,  0. ],\n",
       "       [63. ,  1. ],\n",
       "       [63.5,  0.5]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "2020-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(len(action_list))\n",
    "print(df.iloc[-1]['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_action = []\n",
    "hold = 0\n",
    "blist = []\n",
    "slist = []\n",
    "prices = []\n",
    "return_list = []\n",
    "b = 0\n",
    "for i in range(len(action_list)):\n",
    "    if action_list[i] == 1:\n",
    "        if hold == 0:\n",
    "            final_action.append(['buy',df.iloc[-(len(action_list)-i)]['Close']])\n",
    "            #blist.append([i,df.iloc[-(len(action_list)-i)]['Date']])\n",
    "            prices.append(df.iloc[-(len(action_list)-i)]['Close'])\n",
    "            b = df.iloc[-(len(action_list)-i)]['Close']\n",
    "            hold = 1\n",
    "        else:\n",
    "            final_action.append(['hold',df.iloc[-(len(action_list)-i)]['Close']])\n",
    "            prices.append(df.iloc[-(len(action_list)-i)]['Close'])\n",
    "    elif action_list[i] == 0:\n",
    "        if hold == 1:\n",
    "            final_action.append(['sell',df.iloc[-(len(action_list)-i)]['Close']])\n",
    "            prices.append(df.iloc[-(len(action_list)-i)]['Close'])\n",
    "            #slist.append([i,df.iloc[-(len(action_list)-i)]['Date']])\n",
    "            return_list.append((df.iloc[-(len(action_list)-i)]['Close']-b)/b)\n",
    "            hold = 0\n",
    "        else:\n",
    "            final_action.append(['hold',df.iloc[-(len(action_list)-i)]['Close']])\n",
    "            prices.append(df.iloc[-(len(action_list)-i)]['Close'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (89,) and (4222,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-5c7181e2f328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#plt.plot(slist, prices[slist], 'ro')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#plt.plot(blist, prices[blist], 'go')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2757\u001b[0m     return gca().plot(\n\u001b[1;32m   2758\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2759\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1630\u001b[0m         \"\"\"\n\u001b[1;32m   1631\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stock/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    499\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (89,) and (4222,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.cla()\n",
    "plt.plot(prices,df.iloc[:]['Date'])\n",
    "#plt.plot(slist, prices[slist], 'ro')\n",
    "#plt.plot(blist, prices[blist], 'go')\n",
    "\n",
    "for buy in blist:\n",
    "        plt.plot(buy[1], buy[0], 'g^', markersize='12')\n",
    "    \n",
    "for sell in slist:\n",
    "        plt.plot(sell[1], sell[0], 'rv', markersize='12')\n",
    "#env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.024193548387096687,\n",
       " -0.011538461538461565,\n",
       " -0.011406844106463905,\n",
       " -0.01694915254237297,\n",
       " -0.012552301255230007,\n",
       " 0.017316017316017254,\n",
       " -0.0128205128205127,\n",
       " -0.012658227848101297,\n",
       " -0.15135135135135133,\n",
       " -0.016666666666666684,\n",
       " -0.05894519131334026,\n",
       " 0.06107660455486541,\n",
       " 0.014705882352941213,\n",
       " -0.0407766990291262,\n",
       " 0.07793522267206472,\n",
       " 0.004739336492890894,\n",
       " -0.023255813953488372,\n",
       " 0.052631578947368494,\n",
       " 0.009302325581395316,\n",
       " 0.027522935779816415,\n",
       " 0.013333333333333365,\n",
       " -0.03524229074889871,\n",
       " -0.009216589861751119,\n",
       " -0.03999999999999994,\n",
       " -0.00896860986547082,\n",
       " 0.023148148148148147,\n",
       " 0.1312217194570135,\n",
       " -0.008032128514056196,\n",
       " 0.045454545454545525,\n",
       " -0.06329113924050632,\n",
       " 0.06472491909385114,\n",
       " 0.052147239263803546,\n",
       " 0.025714285714285672,\n",
       " 0.058659217877095014,\n",
       " 0.031250000000000076,\n",
       " 0.03917050691244246,\n",
       " 0.17278617710583155,\n",
       " -0.02716468590831921,\n",
       " 0.04067796610169489]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40205349640029714"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(return_list)*(4 ** 0.5)/np.std(return_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "sell\n",
      "buy\n",
      "11426.313546750003\n"
     ]
    }
   ],
   "source": [
    "fee = 0.001425\n",
    "tax = 0.003\n",
    "\n",
    "MAX_ACCOUNT_BALANCE = 10000\n",
    "\n",
    "balance = MAX_ACCOUNT_BALANCE\n",
    "net_worth = MAX_ACCOUNT_BALANCE\n",
    "stock_num = 0\n",
    "stock_value = 0\n",
    "\n",
    "for action in final_action:\n",
    "    #print(action[1])\n",
    "    if action[0] == 'buy':\n",
    "                    print('buy')\n",
    "                    stock_num = int(balance / float(action[1]))\n",
    "                    stock_value = stock_num * float(action[1])\n",
    "                    balance = balance - stock_value - stock_value * fee\n",
    "                    #print(\"Buy at\", trajectory[2])\n",
    "                    #print(balance+stock_value)\n",
    "                    #print()\n",
    "    elif action[0] == 'sell':\n",
    "                    print('sell')\n",
    "                    stock_value = stock_num * float(action[1])\n",
    "                    balance = balance + stock_value - stock_value * (fee + tax)\n",
    "                    stock_num = 0\n",
    "                    stock_value = 0\n",
    "                    #print(\"Sell at\", trajectory[2])\n",
    "                    #print(balance+stock_value)\n",
    "                    #print()\n",
    "\n",
    "print(balance+stock_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock",
   "language": "python",
   "name": "stock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
